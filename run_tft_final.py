#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TFTè‚¡ç¥¨é¢„æµ‹æ¨¡å‹æ¼”ç¤ºè„šæœ¬ - æœ€ç»ˆç‰ˆæœ¬
"""

import sys
import os
sys.path.append('src')

import torch
import numpy as np
import matplotlib.pyplot as plt
from src.model.model_module.tft_model_final import *

def main():
    """TFTæ¨¡å‹æ¼”ç¤º"""
    print("ğŸš€ TFTè‚¡ç¥¨æ”¶ç›Šç‡é¢„æµ‹æ¨¡å‹æ¼”ç¤º (æœ€ç»ˆç‰ˆæœ¬)")
    print("=" * 60)
    
    # è®¾ç½®å‚æ•°
    config = {
        'num_stocks': 50,
        'num_days': 200, 
        'seq_len': 20,
        'pred_len': 5,
        'num_industries': 10,
        'hidden_dim': 64,
        'num_heads': 4,
        'num_layers': 2,
        'batch_size': 32,
        'num_epochs': 30,
        'learning_rate': 1e-3
    }
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")
    
    # 1. ç”Ÿæˆæ•°æ®
    print("\nğŸ“Š ç”Ÿæˆåˆæˆè‚¡ç¥¨æ•°æ®...")
    data = generate_synthetic_data(
        config['num_stocks'], config['num_days'], 
        config['seq_len'], config['pred_len'], config['num_industries']
    )
    
    print(f"âœ… æ•°æ®å½¢çŠ¶:")
    print(f"  - ä»·æ ¼: {data['prices'].shape}")
    print(f"  - æˆäº¤é‡: {data['volumes'].shape}")
    print(f"  - æ—¥æ”¶ç›Šç‡: {data['returns'].shape}")
    print(f"  - æœªæ¥æ”¶ç›Šç‡: {data['future_returns'].shape}")
    print(f"  - è¡Œä¸šæ ‡ç­¾: {data['industries'].shape}")
    
    sequences = create_sequences(data, config['seq_len'], config['pred_len'])
    print(f"âœ… ç”Ÿæˆ {len(sequences)} ä¸ªè®­ç»ƒåºåˆ—")
    
    if len(sequences) == 0:
        print("âŒ é”™è¯¯ï¼šæ²¡æœ‰ç”Ÿæˆä»»ä½•è®­ç»ƒåºåˆ—ï¼")
        return
    
    # æ£€æŸ¥ç¬¬ä¸€ä¸ªåºåˆ—çš„å½¢çŠ¶
    first_seq = sequences[0]
    print(f"ğŸ“‹ åºåˆ—æ•°æ®å½¢çŠ¶:")
    print(f"  - é™æ€ç‰¹å¾: {first_seq['static'].shape}")
    print(f"  - å†å²ç‰¹å¾: {first_seq['historical'].shape}")
    print(f"  - æœªæ¥ç‰¹å¾: {first_seq['future'].shape}")
    print(f"  - ç›®æ ‡: {first_seq['target'].shape}")
    
    # 2. æ•°æ®åˆ’åˆ†
    split_idx = int(0.8 * len(sequences))
    train_data = sequences[:split_idx]
    val_data = sequences[split_idx:]
    print(f"ğŸ“ˆ è®­ç»ƒé›†: {len(train_data)} ä¸ªåºåˆ—")
    print(f"ğŸ“‰ éªŒè¯é›†: {len(val_data)} ä¸ªåºåˆ—")
    
    # 3. åˆ›å»ºæ¨¡å‹
    print("\nğŸ§  åˆ›å»ºTFTæ¨¡å‹...")
    model = TemporalFusionTransformer(
        static_dim=config['num_industries'],
        known_dynamic_dim=2,  # ä»·æ ¼ + æˆäº¤é‡
        unknown_dynamic_dim=1,  # å†å²æ”¶ç›Šç‡
        hidden_dim=config['hidden_dim'],
        num_heads=config['num_heads'],
        num_layers=config['num_layers'],
        seq_len=config['seq_len'],
        pred_len=config['pred_len'],
        quantiles=[0.1, 0.5, 0.9]
    )
    
    total_params = sum(p.numel() for p in model.parameters())
    print(f"ğŸ”¢ æ¨¡å‹å‚æ•°æ•°é‡: {total_params:,}")
    
    # 4. è®­ç»ƒæ¨¡å‹
    print(f"\nğŸ‹ï¸ å¼€å§‹è®­ç»ƒæ¨¡å‹ ({config['num_epochs']} epochs)...")
    train_losses, val_losses = train_model(
        model, train_data, val_data,
        num_epochs=config['num_epochs'],
        batch_size=config['batch_size'],
        learning_rate=config['learning_rate'],
        device=device
    )
    
    # 5. ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    plt.figure(figsize=(10, 6))
    plt.plot(train_losses, label='è®­ç»ƒæŸå¤±', color='blue')
    plt.plot(val_losses, label='éªŒè¯æŸå¤±', color='red')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('TFTæ¨¡å‹è®­ç»ƒæ›²çº¿')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.savefig('training_curves_final.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # 6. æµ‹è¯•æ¨ç†
    print("\nğŸ”® æµ‹è¯•æ¨¡å‹æ¨ç†...")
    test_samples = val_data[:5]
    
    print("\nğŸ“‹ é¢„æµ‹ç»“æœç¤ºä¾‹:")
    for i, sample in enumerate(test_samples):
        pred_result = predict(
            model, sample['static'], sample['historical'], 
            sample['future'], device
        )
        
        predictions = pred_result['predictions']
        target = sample['target']
        
        print(f"\næ ·æœ¬ {i+1}:")
        print("  é¢„æµ‹ vs çœŸå® (10%, 50%, 90%åˆ†ä½æ•°):")
        for day in range(config['pred_len']):
            pred_day = predictions[day]
            target_day = target[day]
            print(f"    ç¬¬{day+1}å¤©: [{pred_day[0]:.4f}, {pred_day[1]:.4f}, {pred_day[2]:.4f}] vs {target_day:.4f}")
    
    # 7. è¯„ä¼°æ¨¡å‹
    print("\nğŸ“Š æ¨¡å‹æ•´ä½“è¯„ä¼°:")
    all_predictions = []
    all_targets = []
    
    for sample in val_data[:20]:  # è¯„ä¼°å‰20ä¸ªæ ·æœ¬
        pred_result = predict(
            model, sample['static'], sample['historical'], 
            sample['future'], device
        )
        all_predictions.append(pred_result['predictions'])
        all_targets.append(sample['target'])
    
    all_predictions = np.array(all_predictions)
    all_targets = np.array(all_targets)
    
    # å±•å¹³ç”¨äºè¯„ä¼°
    pred_flat = all_predictions.reshape(-1, 3)
    target_flat = all_targets.reshape(-1)
    
    eval_results = evaluate_predictions(pred_flat, target_flat)
    
    for metric, value in eval_results.items():
        print(f"  {metric}: {value:.4f}")
    
    # 8. å¯è§†åŒ–é¢„æµ‹ç»“æœ
    sample_idx = 0
    sample_pred = all_predictions[sample_idx]
    sample_target = all_targets[sample_idx]
    
    plt.figure(figsize=(12, 8))
    days = range(1, config['pred_len'] + 1)
    
    plt.fill_between(days, sample_pred[:, 0], sample_pred[:, 2], 
                     alpha=0.3, color='blue', label='80%ç½®ä¿¡åŒºé—´')
    plt.plot(days, sample_pred[:, 1], 'b-', linewidth=2, label='ä¸­ä½æ•°é¢„æµ‹')
    plt.plot(days, sample_target, 'ro-', linewidth=2, label='çœŸå®å€¼')
    
    plt.xlabel('é¢„æµ‹å¤©æ•°')
    plt.ylabel('æ”¶ç›Šç‡')
    plt.title('TFTè‚¡ç¥¨æ”¶ç›Šç‡é¢„æµ‹ç»“æœç¤ºä¾‹')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.savefig('prediction_example_final.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("\nâœ… TFTæ¨¡å‹æ¼”ç¤ºå®Œæˆï¼")
    print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print("  - training_curves_final.png: è®­ç»ƒæ›²çº¿")
    print("  - prediction_example_final.png: é¢„æµ‹ç»“æœç¤ºä¾‹")

if __name__ == "__main__":
    main() 