{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization of PortfolioBuilderGroup(2 alphas , 1 benchmarks , 2 lags , 20 dates , (80 builds) start!\n",
      "Done Optimize    0th [factor1.none.lag0] at 20240102 , time cost (ms) : {'parse_input': 481.7, 'solve': 37.87, 'output': 11.01}\n",
      "Done Optimize    1th [factor1.none.lag1] at 20240102 , time cost (ms) : {'parse_input': 25.93, 'solve': 22.94, 'output': 10.97}\n",
      "Done Optimize    2th [factor2.none.lag0] at 20240102 , time cost (ms) : {'parse_input': 21.93, 'solve': 22.91, 'output': 10.01}\n",
      "Done Optimize    3th [factor2.none.lag1] at 20240102 , time cost (ms) : {'parse_input': 24.93, 'solve': 21.94, 'output': 9.99}\n",
      "Done Optimize    4th [factor1.none.lag0] at 20240109 , time cost (ms) : {'parse_input': 375.99, 'solve': 105.72, 'output': 19.95}\n",
      "Done Optimize    5th [factor1.none.lag1] at 20240109 , time cost (ms) : {'parse_input': 31.91, 'solve': 106.72, 'output': 17.95}\n",
      "Done Optimize    6th [factor2.none.lag0] at 20240109 , time cost (ms) : {'parse_input': 26.9, 'solve': 160.57, 'output': 16.95}\n",
      "Done Optimize    7th [factor2.none.lag1] at 20240109 , time cost (ms) : {'parse_input': 25.93, 'solve': 92.79, 'output': 13.96}\n",
      "Done Optimize    8th [factor1.none.lag0] at 20240116 , time cost (ms) : {'parse_input': 462.74, 'solve': 92.77, 'output': 14.98}\n",
      "Done Optimize    9th [factor1.none.lag1] at 20240116 , time cost (ms) : {'parse_input': 24.97, 'solve': 97.71, 'output': 14.99}\n",
      "Done Optimize   10th [factor2.none.lag0] at 20240116 , time cost (ms) : {'parse_input': 22.94, 'solve': 97.7, 'output': 15.99}\n",
      "Done Optimize   11th [factor2.none.lag1] at 20240116 , time cost (ms) : {'parse_input': 22.95, 'solve': 101.73, 'output': 14.95}\n",
      "Done Optimize   12th [factor1.none.lag0] at 20240123 , time cost (ms) : {'parse_input': 359.08, 'solve': 96.74, 'output': 14.94}\n",
      "Done Optimize   13th [factor1.none.lag1] at 20240123 , time cost (ms) : {'parse_input': 28.92, 'solve': 100.73, 'output': 15.96}\n",
      "Done Optimize   14th [factor2.none.lag0] at 20240123 , time cost (ms) : {'parse_input': 24.93, 'solve': 96.71, 'output': 13.96}\n",
      "Done Optimize   15th [factor2.none.lag1] at 20240123 , time cost (ms) : {'parse_input': 22.94, 'solve': 91.79, 'output': 14.95}\n",
      "Done Optimize   16th [factor1.none.lag0] at 20240130 , time cost (ms) : {'parse_input': 464.75, 'solve': 96.75, 'output': 14.93}\n",
      "Done Optimize   17th [factor1.none.lag1] at 20240130 , time cost (ms) : {'parse_input': 23.93, 'solve': 103.69, 'output': 14.01}\n",
      "Done Optimize   18th [factor2.none.lag0] at 20240130 , time cost (ms) : {'parse_input': 33.92, 'solve': 101.73, 'output': 14.97}\n",
      "Done Optimize   19th [factor2.none.lag1] at 20240130 , time cost (ms) : {'parse_input': 24.93, 'solve': 97.74, 'output': 12.92}\n",
      "Done Optimize   20th [factor1.none.lag0] at 20240206 , time cost (ms) : {'parse_input': 468.75, 'solve': 101.71, 'output': 14.96}\n",
      "Done Optimize   21th [factor1.none.lag1] at 20240206 , time cost (ms) : {'parse_input': 23.97, 'solve': 95.71, 'output': 15.0}\n",
      "Done Optimize   22th [factor2.none.lag0] at 20240206 , time cost (ms) : {'parse_input': 23.91, 'solve': 97.77, 'output': 14.97}\n",
      "Done Optimize   23th [factor2.none.lag1] at 20240206 , time cost (ms) : {'parse_input': 22.94, 'solve': 98.74, 'output': 13.96}\n",
      "Done Optimize   24th [factor1.none.lag0] at 20240221 , time cost (ms) : {'parse_input': 363.03, 'solve': 95.74, 'output': 14.96}\n",
      "Done Optimize   25th [factor1.none.lag1] at 20240221 , time cost (ms) : {'parse_input': 23.93, 'solve': 97.71, 'output': 14.0}\n",
      "Done Optimize   26th [factor2.none.lag0] at 20240221 , time cost (ms) : {'parse_input': 23.97, 'solve': 100.74, 'output': 14.95}\n",
      "Done Optimize   27th [factor2.none.lag1] at 20240221 , time cost (ms) : {'parse_input': 25.93, 'solve': 93.75, 'output': 13.0}\n",
      "Done Optimize   28th [factor1.none.lag0] at 20240228 , time cost (ms) : {'parse_input': 469.74, 'solve': 96.76, 'output': 13.95}\n",
      "Done Optimize   29th [factor1.none.lag1] at 20240228 , time cost (ms) : {'parse_input': 25.91, 'solve': 94.78, 'output': 14.92}\n",
      "Done Optimize   30th [factor2.none.lag0] at 20240228 , time cost (ms) : {'parse_input': 27.96, 'solve': 97.73, 'output': 14.96}\n",
      "Done Optimize   31th [factor2.none.lag1] at 20240228 , time cost (ms) : {'parse_input': 27.93, 'solve': 98.75, 'output': 13.96}\n",
      "Done Optimize   32th [factor1.none.lag0] at 20240306 , time cost (ms) : {'parse_input': 379.95, 'solve': 110.71, 'output': 20.98}\n",
      "Done Optimize   33th [factor1.none.lag1] at 20240306 , time cost (ms) : {'parse_input': 27.92, 'solve': 107.71, 'output': 26.89}\n",
      "Done Optimize   34th [factor2.none.lag0] at 20240306 , time cost (ms) : {'parse_input': 25.95, 'solve': 115.7, 'output': 17.92}\n",
      "Done Optimize   35th [factor2.none.lag1] at 20240306 , time cost (ms) : {'parse_input': 23.93, 'solve': 115.73, 'output': 14.95}\n",
      "Done Optimize   36th [factor1.none.lag0] at 20240313 , time cost (ms) : {'parse_input': 487.7, 'solve': 124.67, 'output': 13.96}\n",
      "Done Optimize   37th [factor1.none.lag1] at 20240313 , time cost (ms) : {'parse_input': 26.93, 'solve': 94.75, 'output': 14.96}\n",
      "Done Optimize   38th [factor2.none.lag0] at 20240313 , time cost (ms) : {'parse_input': 29.92, 'solve': 99.73, 'output': 16.96}\n",
      "Done Optimize   39th [factor2.none.lag1] at 20240313 , time cost (ms) : {'parse_input': 29.92, 'solve': 106.71, 'output': 22.94}\n",
      "Done Optimize   40th [factor1.none.lag0] at 20240320 , time cost (ms) : {'parse_input': 397.94, 'solve': 107.71, 'output': 14.96}\n",
      "Done Optimize   41th [factor1.none.lag1] at 20240320 , time cost (ms) : {'parse_input': 26.93, 'solve': 118.68, 'output': 17.95}\n",
      "Done Optimize   42th [factor2.none.lag0] at 20240320 , time cost (ms) : {'parse_input': 32.91, 'solve': 119.68, 'output': 18.95}\n",
      "Done Optimize   43th [factor2.none.lag1] at 20240320 , time cost (ms) : {'parse_input': 47.87, 'solve': 105.72, 'output': 15.96}\n",
      "Done Optimize   44th [factor1.none.lag0] at 20240327 , time cost (ms) : {'parse_input': 503.65, 'solve': 116.69, 'output': 14.96}\n",
      "Done Optimize   45th [factor1.none.lag1] at 20240327 , time cost (ms) : {'parse_input': 25.93, 'solve': 97.74, 'output': 14.96}\n",
      "Done Optimize   46th [factor2.none.lag0] at 20240327 , time cost (ms) : {'parse_input': 29.92, 'solve': 115.69, 'output': 15.96}\n",
      "Done Optimize   47th [factor2.none.lag1] at 20240327 , time cost (ms) : {'parse_input': 30.92, 'solve': 103.72, 'output': 13.96}\n",
      "Done Optimize   48th [factor1.none.lag0] at 20240403 , time cost (ms) : {'parse_input': 489.73, 'solve': 98.74, 'output': 15.95}\n",
      "Done Optimize   49th [factor1.none.lag1] at 20240403 , time cost (ms) : {'parse_input': 25.94, 'solve': 98.73, 'output': 13.98}\n",
      "Done Optimize   50th [factor2.none.lag0] at 20240403 , time cost (ms) : {'parse_input': 24.91, 'solve': 105.76, 'output': 13.95}\n",
      "Done Optimize   51th [factor2.none.lag1] at 20240403 , time cost (ms) : {'parse_input': 25.89, 'solve': 102.76, 'output': 13.93}\n",
      "Done Optimize   52th [factor1.none.lag0] at 20240412 , time cost (ms) : {'parse_input': 362.03, 'solve': 104.68, 'output': 14.99}\n",
      "Done Optimize   53th [factor1.none.lag1] at 20240412 , time cost (ms) : {'parse_input': 30.95, 'solve': 97.73, 'output': 14.97}\n",
      "Done Optimize   54th [factor2.none.lag0] at 20240412 , time cost (ms) : {'parse_input': 25.93, 'solve': 102.74, 'output': 13.96}\n",
      "Done Optimize   55th [factor2.none.lag1] at 20240412 , time cost (ms) : {'parse_input': 26.89, 'solve': 106.75, 'output': 15.95}\n",
      "Done Optimize   56th [factor1.none.lag0] at 20240419 , time cost (ms) : {'parse_input': 474.69, 'solve': 98.74, 'output': 14.96}\n",
      "Done Optimize   57th [factor1.none.lag1] at 20240419 , time cost (ms) : {'parse_input': 39.93, 'solve': 102.72, 'output': 14.96}\n",
      "Done Optimize   58th [factor2.none.lag0] at 20240419 , time cost (ms) : {'parse_input': 26.93, 'solve': 102.72, 'output': 14.93}\n",
      "Done Optimize   59th [factor2.none.lag1] at 20240419 , time cost (ms) : {'parse_input': 27.94, 'solve': 99.7, 'output': 15.0}\n",
      "Done Optimize   60th [factor1.none.lag0] at 20240426 , time cost (ms) : {'parse_input': 365.02, 'solve': 100.73, 'output': 14.95}\n",
      "Done Optimize   61th [factor1.none.lag1] at 20240426 , time cost (ms) : {'parse_input': 25.96, 'solve': 94.72, 'output': 13.96}\n",
      "Done Optimize   62th [factor2.none.lag0] at 20240426 , time cost (ms) : {'parse_input': 24.93, 'solve': 100.73, 'output': 15.99}\n",
      "Done Optimize   63th [factor2.none.lag1] at 20240426 , time cost (ms) : {'parse_input': 23.93, 'solve': 101.72, 'output': 16.97}\n",
      "Done Optimize   64th [factor1.none.lag0] at 20240508 , time cost (ms) : {'parse_input': 467.75, 'solve': 101.72, 'output': 13.93}\n",
      "Done Optimize   65th [factor1.none.lag1] at 20240508 , time cost (ms) : {'parse_input': 26.93, 'solve': 101.7, 'output': 13.96}\n",
      "Done Optimize   66th [factor2.none.lag0] at 20240508 , time cost (ms) : {'parse_input': 25.93, 'solve': 94.74, 'output': 15.0}\n",
      "Done Optimize   67th [factor2.none.lag1] at 20240508 , time cost (ms) : {'parse_input': 23.97, 'solve': 98.74, 'output': 14.92}\n",
      "Done Optimize   68th [factor1.none.lag0] at 20240515 , time cost (ms) : {'parse_input': 361.05, 'solve': 97.74, 'output': 14.96}\n",
      "Done Optimize   69th [factor1.none.lag1] at 20240515 , time cost (ms) : {'parse_input': 24.93, 'solve': 98.74, 'output': 13.96}\n",
      "Done Optimize   70th [factor2.none.lag0] at 20240515 , time cost (ms) : {'parse_input': 36.9, 'solve': 101.74, 'output': 14.96}\n",
      "Done Optimize   71th [factor2.none.lag1] at 20240515 , time cost (ms) : {'parse_input': 23.97, 'solve': 97.73, 'output': 13.97}\n",
      "Done Optimize   72th [factor1.none.lag0] at 20240522 , time cost (ms) : {'parse_input': 471.74, 'solve': 100.72, 'output': 14.93}\n",
      "Done Optimize   73th [factor1.none.lag1] at 20240522 , time cost (ms) : {'parse_input': 24.93, 'solve': 93.72, 'output': 15.99}\n",
      "Done Optimize   74th [factor2.none.lag0] at 20240522 , time cost (ms) : {'parse_input': 24.93, 'solve': 96.74, 'output': 14.92}\n",
      "Done Optimize   75th [factor2.none.lag1] at 20240522 , time cost (ms) : {'parse_input': 24.94, 'solve': 99.71, 'output': 14.97}\n",
      "Done Optimize   76th [factor1.none.lag0] at 20240529 , time cost (ms) : {'parse_input': 351.1, 'solve': 91.75, 'output': 14.96}\n",
      "Done Optimize   77th [factor1.none.lag1] at 20240529 , time cost (ms) : {'parse_input': 23.94, 'solve': 99.73, 'output': 14.96}\n",
      "Done Optimize   78th [factor2.none.lag0] at 20240529 , time cost (ms) : {'parse_input': 24.93, 'solve': 99.75, 'output': 14.96}\n",
      "Done Optimize   79th [factor2.none.lag1] at 20240529 , time cost (ms) : {'parse_input': 26.93, 'solve': 98.73, 'output': 12.98}\n",
      "Group optimization Finished , Total time: 19.79 secs, each optim time: 0.25\n",
      "factor1.none.lag0 accounting...... finished! Cost 1.80 secs\n",
      "factor1.none.lag1 accounting...... finished! Cost 0.36 secs\n",
      "factor2.none.lag0 accounting...... finished! Cost 1.02 secs\n",
      "factor2.none.lag1 accounting...... finished! Cost 0.41 secs\n",
      "FmpManager calc of prefix Finished!\n",
      "FmpManager calc of perf_curve Finished!\n",
      "FmpManager calc of perf_drawdown Finished!\n",
      "FmpManager calc of perf_year Finished!\n",
      "FmpManager calc of perf_month Finished!\n",
      "FmpManager calc of perf_lag Finished!\n",
      "FmpManager calc of exp_style Finished!\n",
      "FmpManager calc of exp_indus Finished!\n",
      "FmpManager calc of attrib_source Finished!\n",
      "FmpManager calc of attrib_style Finished!\n",
      "FmpManager calc Finished!\n",
      "FmpManager plot of prefix Finished!\n",
      "FmpManager plot of perf_curve Finished!\n",
      "FmpManager plot of perf_drawdown Finished!\n",
      "FmpManager plot of perf_year Finished!\n",
      "FmpManager plot of perf_month Finished!\n",
      "FmpManager plot of perf_lag Finished!\n",
      "FmpManager plot of exp_style Finished!\n",
      "FmpManager plot of exp_indus Finished!\n",
      "FmpManager plot of attrib_source Finished!\n",
      "FmpManager plot of attrib_style Finished!\n",
      "FmpManager plot Finished!\n",
      "Model Portfolio datas are saved to D:\\Coding\\learndl\\learndl\\results\\fmp_test_20241119005648\\data.xlsx\n",
      "Model Portfolio plots are saved to D:\\Coding\\learndl\\learndl\\results\\fmp_test_20241119005648\\plot.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.factor.analytic.fmp.api.FmpManager at 0x143f0eb4050>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.api.factor import fmp_test , perf_test\n",
    "\n",
    "fmp_test(benchmark = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PerfManager calc of ic_curve Finished!\n",
      "PerfManager calc of ic_decay Finished!\n",
      "PerfManager calc of ic_indus Finished!\n",
      "PerfManager calc of ic_year Finished!\n",
      "PerfManager calc of ic_mono Finished!\n",
      "PerfManager calc of pnl_curve Finished!\n",
      "PerfManager calc of style_corr Finished!\n",
      "PerfManager calc of grp_curve Finished!\n",
      "PerfManager calc of grp_decay_ir Finished!\n",
      "PerfManager calc of grp_year Finished!\n",
      "PerfManager calc of distr_curve Finished!\n",
      "PerfManager plot of ic_curve Finished!\n",
      "PerfManager plot of ic_decay Finished!\n",
      "PerfManager plot of ic_indus Finished!\n",
      "PerfManager plot of ic_year Finished!\n",
      "PerfManager plot of ic_mono Finished!\n",
      "PerfManager plot of pnl_curve Finished!\n",
      "PerfManager plot of style_corr Finished!\n",
      "PerfManager plot of grp_curve Finished!\n",
      "PerfManager plot of grp_decay_ir Finished!\n",
      "PerfManager plot of grp_year Finished!\n",
      "PerfManager plot of distr_curve Finished!\n",
      "PerfManager plot Finished!\n",
      "Analytic datas are saved to D:\\Coding\\learndl\\learndl\\results\\perf_test_20241119005238\\data.xlsx\n",
      "Analytic plots are saved to D:\\Coding\\learndl\\learndl\\results\\perf_test_20241119005238\\plot.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.factor.analytic.perf.api.PerfManager at 0x279b11e65d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.api.factor import fmp_test , perf_test\n",
    "\n",
    "perf_test(benchmark = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device name: NVIDIA GeForce RTX 4090\n",
      "update data: ********************\n",
      "Unpack Update Files\n",
      "Sat Nov 16 13:39:25 2024 : download since!\n",
      "Connection and Factor preparation finished!\n",
      "Sat Nov 16 13:39:25 2024 : All Updates Done! Cost 0.50 Secs\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "process other min bars:\n",
      "--------------------------------------------------------------------------------\n",
      "process other min bars:\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "prepare predict data: ********************\n",
      "predict is True , Data Processing start!\n",
      "6 datas :['y', 'day', '30m', 'style', 'indus', 'week']\n",
      "y is up to 20241116 already!\n",
      "day is up to 20241116 already!\n",
      "30m is up to 20241116 already!\n",
      "style is up to 20241116 already!\n",
      "indus is up to 20241116 already!\n",
      "week is up to 20241116 already!\n",
      "Data Processing Finished! Cost 0.00 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "update_hidden: ********************\n",
      "model_name is None, update all hidden models\n",
      "  -->  update hidden feature for HiddenExtractingModel(name=gru_day)\n",
      "try using /home/mengkjin/Workspace/learndl/data/Interim/DataSet/day.20240703.pt , success!\n",
      "Load  2 DataBlocks...... finished! Cost 0.12 secs\n",
      "Align 2 DataBlocks...... finished! Cost 0.14 secs\n",
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 333/333 [00:00<00:00, 5008.12it/s]\n",
      "100%|██████████| 333/333 [00:00<00:00, 3737.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "update_factors: ********************\n",
      "Finish model [gru_day] predicting!\n",
      "Finish model [gruRTN_day] predicting!\n",
      "Finish model [gru_avg] predicting!\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "sending email success\n"
     ]
    }
   ],
   "source": [
    "%run src_runs/autorun/daily_update.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.fetch.fetcher_sql import SQLFetcher\n",
    "from src.basic import PATH , CALENDAR\n",
    "trace = 0\n",
    "end_dt = 99991231\n",
    "\n",
    "\n",
    "DB_SRC = 'sellside'\n",
    "db_key = 'dongfang.factorvae'\n",
    "\n",
    "\n",
    "start_dt = 20000101\n",
    "           \n",
    "old_dates = PATH.db_dates(DB_SRC , db_key)\n",
    "if trace > 0 and len(old_dates) > trace: old_dates = old_dates[:-trace]\n",
    "if len(old_dates): \n",
    "    last1_dt = min(SQLFetcher.date_offset(old_dates[-1],1,astype=int))\n",
    "    start_dt = max(start_dt , last1_dt)\n",
    "\n",
    "end_dt = CALENDAR.td(min(end_dt , CALENDAR.update_to()))\n",
    "date_intervals = SQLFetcher.date_seg(start_dt , end_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20241116, 20241118)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_dt , end_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(20240101, 20240331),\n",
       " (20240401, 20240630),\n",
       " (20240701, 20240930),\n",
       " (20241001, 20241231)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "from collections.abc import Iterable\n",
    "\n",
    "start_dt = 20240101\n",
    "end_dt = 20241231\n",
    "FREQ = 'QE'\n",
    "\n",
    "def date_offset(date : Any , offset : int = 0 , astype = int):\n",
    "    date = pd.DatetimeIndex(np.array(date).astype(str)) if isinstance(date , Iterable) else pd.DatetimeIndex([str(date)])\n",
    "    dseries : pd.DatetimeIndex = (date + pd.DateOffset(n=offset))\n",
    "    new_date = dseries.strftime('%Y%m%d').astype(astype).to_numpy()\n",
    "    return new_date if isinstance(date , Iterable) else new_date[0]\n",
    "\n",
    "dt_list = pd.date_range(str(start_dt) , str(end_dt) , freq=FREQ).strftime('%Y%m%d').astype(int)\n",
    "dt_starts = [date_offset(start_dt) , *date_offset(dt_list[:-1],1)]\n",
    "dt_ends = [*dt_list[:-1] , date_offset(end_dt)]\n",
    "[(int(s),int(e)) for s,e in zip(dt_starts , dt_ends)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_date = pd.DatetimeIndex([str(20241113)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['20241113'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_date.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([20240101]), 20240401, 20240701, 20241001]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(20241116, 20241118)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update data: ********************\n",
      "Update Files\n",
      "Tue Nov 19 01:03:23 2024 : Updated ~ DB_information_js\\calendar.feather Done! Cost 0.03 Secs\n",
      "Tue Nov 19 01:03:24 2024 : Updated ~ DB_information_js\\description.feather Done! Cost 0.12 Secs\n",
      "Tue Nov 19 01:03:24 2024 : Updated ~ DB_information_js\\st.feather Done! Cost 0.03 Secs\n",
      "Tue Nov 19 01:03:27 2024 : Updated ~ DB_information_js\\industry.feather Done! Cost 3.03 Secs\n",
      "Tue Nov 19 01:03:34 2024 : Updated ~ DB_information_js\\concepts.feather Done! Cost 7.64 Secs\n",
      "Tue Nov 19 01:03:36 2024 : Updated ~ DB_models\\risk_exp\\2024\\risk_exp.20241118.feather Done! Cost 0.05 Secs\n",
      "Tue Nov 19 01:03:36 2024 : Updated ~ DB_models\\risk_cov\\2024\\risk_cov.20241118.feather Done! Cost 0.03 Secs\n",
      "Tue Nov 19 01:03:36 2024 : Updated ~ DB_models\\risk_spec\\2024\\risk_spec.20241118.feather Done! Cost 0.02 Secs\n",
      "Tue Nov 19 01:03:38 2024 : Updated ~ DB_trade_js\\day\\2024\\day.20241118.feather Done! Cost 0.06 Secs\n",
      "Tue Nov 19 01:03:39 2024 : Updated ~ DB_trade_js\\5day\\2024\\5day.20241118.feather Done! Cost 0.28 Secs\n",
      "Tue Nov 19 01:03:39 2024 : Updated ~ DB_trade_js\\10day\\2024\\10day.20241118.feather Done! Cost 0.50 Secs\n",
      "Tue Nov 19 01:03:40 2024 : Updated ~ DB_trade_js\\20day\\2024\\20day.20241118.feather Done! Cost 0.90 Secs\n",
      "Tue Nov 19 01:03:44 2024 : Updated ~ DB_trade_js\\min\\2024\\min.20241118.feather Done! Cost 3.64 Secs\n",
      "Tue Nov 19 01:03:44 2024 : Updated ~ DB_trade_js\\5min\\2024\\5min.20241118.feather Done! Cost 0.64 Secs\n",
      "Tue Nov 19 01:03:45 2024 : Updated ~ DB_trade_js\\10min\\2024\\10min.20241118.feather Done! Cost 0.57 Secs\n",
      "Tue Nov 19 01:03:45 2024 : Updated ~ DB_trade_js\\15min\\2024\\15min.20241118.feather Done! Cost 0.55 Secs\n",
      "Tue Nov 19 01:03:46 2024 : Updated ~ DB_trade_js\\30min\\2024\\30min.20241118.feather Done! Cost 0.49 Secs\n",
      "Tue Nov 19 01:03:46 2024 : Updated ~ DB_trade_js\\60min\\2024\\60min.20241118.feather Done! Cost 0.52 Secs\n",
      "Tue Nov 19 01:03:49 2024 : Updated ~ DB_labels_js\\ret20_lag\\2024\\ret20_lag.20241018.feather Done! Cost 0.91 Secs\n",
      "Tue Nov 19 01:03:50 2024 : Updated ~ DB_labels_js\\ret20\\2024\\ret20.20241021.feather Done! Cost 0.75 Secs\n",
      "Tue Nov 19 01:03:59 2024 : Updated ~ DB_labels_js\\ret10_lag\\2024\\ret10_lag.20241101.feather Done! Cost 0.75 Secs\n",
      "Tue Nov 19 01:04:01 2024 : Updated ~ DB_labels_js\\ret10\\2024\\ret10.20241104.feather Done! Cost 0.71 Secs\n",
      "Tue Nov 19 01:04:09 2024 : Updated ~ DB_labels_js\\ret5_lag\\2024\\ret5_lag.20241108.feather Done! Cost 0.38 Secs\n",
      "Tue Nov 19 01:04:12 2024 : Updated ~ DB_labels_js\\ret5\\2024\\ret5.20241111.feather Done! Cost 0.66 Secs\n",
      "Tue Nov 19 01:04:27 2024 : download since!\n",
      "Connection and Factor preparation finished!\n",
      "Tue Nov 19 01:04:27 2024 : sellside/dongfang.hfq_chars from 20241116 to 20241118, total 1 periods\n",
      "Start sellside/dongfang.hfq_chars:20241116-20241118 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding\\learndl\\learndl\\src\\data\\fetch\\fetcher_sql.py:273: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return [(int(s),int(e)) for s,e in zip(dt_starts , dt_ends)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBase object [sellside],[dongfang.hfq_chars],[20241118] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_sellside\\dongfang.hfq_chars\\2024\\dongfang.hfq_chars.20241118.feather successfully\n",
      "Done sellside/dongfang.hfq_chars:20241116-20241118, cost 2.3 Secs\n",
      "Tue Nov 19 01:04:29 2024 : sellside/dongfang.l2_chars from 20241116 to 20241118, total 1 periods\n",
      "Start sellside/dongfang.l2_chars:20241116-20241118 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding\\learndl\\learndl\\src\\data\\fetch\\fetcher_sql.py:273: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return [(int(s),int(e)) for s,e in zip(dt_starts , dt_ends)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBase object [sellside],[dongfang.l2_chars],[20241118] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_sellside\\dongfang.l2_chars\\2024\\dongfang.l2_chars.20241118.feather successfully\n",
      "Done sellside/dongfang.l2_chars:20241116-20241118, cost 29.7 Secs\n",
      "Tue Nov 19 01:04:59 2024 : sellside/dongfang.ms_chars from 20241116 to 20241118, total 1 periods\n",
      "Start sellside/dongfang.ms_chars:20241116-20241118 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding\\learndl\\learndl\\src\\data\\fetch\\fetcher_sql.py:273: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return [(int(s),int(e)) for s,e in zip(dt_starts , dt_ends)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBase object [sellside],[dongfang.ms_chars],[20241118] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_sellside\\dongfang.ms_chars\\2024\\dongfang.ms_chars.20241118.feather successfully\n",
      "Done sellside/dongfang.ms_chars:20241116-20241118, cost 49.9 Secs\n",
      "Tue Nov 19 01:05:49 2024 : sellside/dongfang.order_flow from 20241116 to 20241118, total 1 periods\n",
      "Start sellside/dongfang.order_flow:20241116-20241118 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding\\learndl\\learndl\\src\\data\\fetch\\fetcher_sql.py:273: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return [(int(s),int(e)) for s,e in zip(dt_starts , dt_ends)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBase object [sellside],[dongfang.order_flow],[20241118] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_sellside\\dongfang.order_flow\\2024\\dongfang.order_flow.20241118.feather successfully\n",
      "Done sellside/dongfang.order_flow:20241116-20241118, cost 1.0 Secs\n",
      "Tue Nov 19 01:05:50 2024 : sellside/dongfang.gp from 20241116 to 20241118, total 1 periods\n",
      "Start sellside/dongfang.gp:20241116-20241118 \n",
      "Done sellside/dongfang.gp:20241116-20241118, cost 0.1 Secs\n",
      "Tue Nov 19 01:05:50 2024 : sellside/dongfang.tra from 20241116 to 20241118, total 1 periods\n",
      "Start sellside/dongfang.tra:20241116-20241118 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding\\learndl\\learndl\\src\\data\\fetch\\fetcher_sql.py:273: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return [(int(s),int(e)) for s,e in zip(dt_starts , dt_ends)]\n",
      "d:\\Coding\\learndl\\learndl\\src\\data\\fetch\\fetcher_sql.py:273: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return [(int(s),int(e)) for s,e in zip(dt_starts , dt_ends)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done sellside/dongfang.tra:20241116-20241118, cost 0.1 Secs\n",
      "Tue Nov 19 01:05:50 2024 : sellside/dongfang.hist from 20241116 to 20241118, total 1 periods\n",
      "Start sellside/dongfang.hist:20241116-20241118 \n",
      "Done sellside/dongfang.hist:20241116-20241118, cost 0.1 Secs\n",
      "Tue Nov 19 01:05:51 2024 : sellside/dongfang.scores_v0 from 20241116 to 20241118, total 1 periods\n",
      "Start sellside/dongfang.scores_v0:20241116-20241118 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding\\learndl\\learndl\\src\\data\\fetch\\fetcher_sql.py:273: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return [(int(s),int(e)) for s,e in zip(dt_starts , dt_ends)]\n",
      "d:\\Coding\\learndl\\learndl\\src\\data\\fetch\\fetcher_sql.py:273: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return [(int(s),int(e)) for s,e in zip(dt_starts , dt_ends)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBase object [sellside],[dongfang.scores_v0],[20241118] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_sellside\\dongfang.scores_v0\\2024\\dongfang.scores_v0.20241118.feather successfully\n",
      "Done sellside/dongfang.scores_v0:20241116-20241118, cost 0.3 Secs\n",
      "Tue Nov 19 01:05:51 2024 : sellside/dongfang.factorvae from 20241116 to 20241118, total 1 periods\n",
      "Start sellside/dongfang.factorvae:20241116-20241118 \n",
      "Done sellside/dongfang.factorvae:20241116-20241118, cost 0.1 Secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding\\learndl\\learndl\\src\\data\\fetch\\fetcher_sql.py:273: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return [(int(s),int(e)) for s,e in zip(dt_starts , dt_ends)]\n",
      "d:\\Coding\\learndl\\learndl\\src\\data\\fetch\\fetcher_sql.py:273: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return [(int(s),int(e)) for s,e in zip(dt_starts , dt_ends)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 19 01:05:51 2024 : sellside/huatai.dl_factors from 20241116 to 20241118, total 1 periods\n",
      "Start sellside/huatai.dl_factors:20241116-20241118 \n",
      "DataBase object [sellside],[huatai.dl_factors],[20241118] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_sellside\\huatai.dl_factors\\2024\\huatai.dl_factors.20241118.feather successfully\n",
      "Done sellside/huatai.dl_factors:20241116-20241118, cost 1.1 Secs\n",
      "Tue Nov 19 01:05:52 2024 : All Updates Done! Cost 148.72 Secs\n",
      "--------------------------------------------------------------------------------\n",
      "DataBase object [information_ts],[calendar],[20241119] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_information_ts\\calendar.feather successfully\n",
      "DataBase object [information_ts],[change_name],[20241119] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_information_ts\\change_name.feather successfully\n",
      "DataBase object [information_ts],[description],[20241119] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_information_ts\\description.feather successfully\n",
      "DataBase object [information_ts],[industry],[20241119] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_information_ts\\industry.feather successfully\n",
      "CSI1000Weight Updating benchmark_ts/csi1000 from 20241023 to 20241119\n",
      "DataBase object [benchmark_ts],[csi1000],[20241031] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_benchmark_ts\\csi1000\\2024\\csi1000.20241031.feather successfully\n",
      "CSI2000Weight Updating benchmark_ts/csi2000 from 20241023 to 20241119\n",
      "DataBase object [benchmark_ts],[csi2000],[20241031] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_benchmark_ts\\csi2000\\2024\\csi2000.20241031.feather successfully\n",
      "CSI300Weight Updating benchmark_ts/csi300 from 20241024 to 20241119\n",
      "DataBase object [benchmark_ts],[csi300],[20241101] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_benchmark_ts\\csi300\\2024\\csi300.20241101.feather successfully\n",
      "DataBase object [benchmark_ts],[csi300],[20241031] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_benchmark_ts\\csi300\\2024\\csi300.20241031.feather successfully\n",
      "CSI500Weight Updating benchmark_ts/csi500 from 20241023 to 20241119\n",
      "DataBase object [benchmark_ts],[csi500],[20241031] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_benchmark_ts\\csi500\\2024\\csi500.20241031.feather successfully\n",
      "CSI800Weight Updating benchmark_ts/csi800 from 20241023 to 20241119\n",
      "DataBase object [benchmark_ts],[csi800],[20241031] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_benchmark_ts\\csi800\\2024\\csi800.20241031.feather successfully\n",
      "DataBase object [trade_ts],[day_limit],[20241118] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_trade_ts\\day_limit\\2024\\day_limit.20241118.feather successfully\n",
      "DataBase object [trade_ts],[day_moneyflow],[20241118] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_trade_ts\\day_moneyflow\\2024\\day_moneyflow.20241118.feather successfully\n",
      "DataBase object [trade_ts],[day],[20241118] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_trade_ts\\day\\2024\\day.20241118.feather successfully\n",
      "DataBase object [trade_ts],[day_val],[20241118] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_trade_ts\\day_val\\2024\\day_val.20241118.feather successfully\n",
      "DataBase object [financial_ts],[dividend],[20240331] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_financial_ts\\dividend\\2024\\dividend.20240331.feather successfully\n",
      "DataBase object [financial_ts],[dividend],[20240630] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_financial_ts\\dividend\\2024\\dividend.20240630.feather successfully\n",
      "DataBase object [financial_ts],[dividend],[20240930] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_financial_ts\\dividend\\2024\\dividend.20240930.feather successfully\n",
      "AnalystReport Updating analyst_ts/report from 20241020 to 20241118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding\\learndl\\learndl\\src\\data\\fetch\\tushare\\download\\abstract_fetcher.py:94: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat(dfs).reset_index(drop = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBase object [analyst_ts],[report],[20241118] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241118.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241117] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241117.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241116] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241116.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241115] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241115.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241114] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241114.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241113] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241113.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241112] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241112.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241111] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241111.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241110] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241110.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241109] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241109.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241108] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241108.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241107] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241107.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241106] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241106.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241105] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241105.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241104] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241104.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241103] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241103.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241102] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241102.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241101] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241101.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241031] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241031.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241030] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241030.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241029] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241029.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241028] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241028.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241027] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241027.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241026] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241026.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241025] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241025.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241024] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241024.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241023] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241023.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241022] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241022.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241021] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241021.feather successfully\n",
      "DataBase object [analyst_ts],[report],[20241020] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_analyst_ts\\report\\2024\\report.20241020.feather successfully\n",
      "AnalystReport Updating analyst_ts/report from 20241119 to 20241119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jinmeng\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rqdatac\\client.py:257: UserWarning: Your account will be expired after  16 days. Please call us at 0755-22676337 to upgrade or purchase or renew your contract.\n",
      "  warnings.warn(\"Your account will be expired after  {} days. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBase object [trade_ts],[min],[20241118] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_trade_ts\\min\\2024\\min.20241118.feather successfully\n",
      "rcquant bar min 20241118 success\n",
      "--------------------------------------------------------------------------------\n",
      "process other min bars:\n",
      "DataBase object [trade_ts],[5min],[20241118] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_trade_ts\\5min\\2024\\5min.20241118.feather successfully\n",
      "DataBase object [trade_ts],[10min],[20241118] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_trade_ts\\10min\\2024\\10min.20241118.feather successfully\n",
      "DataBase object [trade_ts],[15min],[20241118] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_trade_ts\\15min\\2024\\15min.20241118.feather successfully\n",
      "DataBase object [trade_ts],[30min],[20241118] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_trade_ts\\30min\\2024\\30min.20241118.feather successfully\n",
      "DataBase object [trade_ts],[60min],[20241118] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_trade_ts\\60min\\2024\\60min.20241118.feather successfully\n",
      "--------------------------------------------------------------------------------\n",
      "process other min bars:\n",
      "--------------------------------------------------------------------------------\n",
      "DataBase object [models],[tushare_cne5_exp],[20241118] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_models\\tushare_cne5_exp\\2024\\tushare_cne5_exp.20241118.feather successfully\n",
      "DataBase object [models],[tushare_cne5_coef],[20241118] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_models\\tushare_cne5_coef\\2024\\tushare_cne5_coef.20241118.feather successfully\n",
      "DataBase object [models],[tushare_cne5_res],[20241118] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_models\\tushare_cne5_res\\2024\\tushare_cne5_res.20241118.feather successfully\n",
      "DataBase object [models],[tushare_cne5_cov],[20241118] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_models\\tushare_cne5_cov\\2024\\tushare_cne5_cov.20241118.feather successfully\n",
      "DataBase object [models],[tushare_cne5_spec],[20241118] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_models\\tushare_cne5_spec\\2024\\tushare_cne5_spec.20241118.feather successfully\n",
      "--------------------------------------------------------------------------------\n",
      "DataBase object [labels_ts],[ret5],[20241111] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_labels_ts\\ret5\\2024\\ret5.20241111.feather successfully\n",
      "DataBase object [labels_ts],[ret5_lag],[20241108] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_labels_ts\\ret5_lag\\2024\\ret5_lag.20241108.feather successfully\n",
      "DataBase object [labels_ts],[ret10],[20241104] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_labels_ts\\ret10\\2024\\ret10.20241104.feather successfully\n",
      "DataBase object [labels_ts],[ret10_lag],[20241101] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_labels_ts\\ret10_lag\\2024\\ret10_lag.20241101.feather successfully\n",
      "DataBase object [labels_ts],[ret20],[20241021] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_labels_ts\\ret20\\2024\\ret20.20241021.feather successfully\n",
      "DataBase object [labels_ts],[ret20_lag],[20241018] save to D:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_labels_ts\\ret20_lag\\2024\\ret20_lag.20241018.feather successfully\n",
      "--------------------------------------------------------------------------------\n",
      "prepare predict data: ********************\n",
      "predict is True , Data Processing start!\n",
      "6 datas : ['y', 'day', '30m', 'style', 'indus', 'week'] , from -366 to None\n",
      "y blocks loading start!\n",
      " --> labels_ts blocks reading [ret10_lag] DataBase...... finished! Cost 0.85 secs\n",
      " --> labels_ts blocks reading [ret20_lag] DataBase...... finished! Cost 0.82 secs\n",
      " --> labels_ts blocks merging (2)...... finished! Cost 0.18 secs\n",
      " --> models blocks reading [tushare_cne5_exp] DataBase...... finished! Cost 3.06 secs\n",
      "y blocks loading finished! Cost 5.28 secs\n",
      "y blocks process...... finished! Cost 5.29 secs\n",
      "y blocks masking...... finished! Cost 0.10 secs\n",
      "y blocks saving ...... finished! Cost 0.27 secs\n",
      "y blocks norming...... finished! Cost 0.00 secs\n",
      "y finished! Cost 11.33 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "day blocks loading start!\n",
      " --> trade_ts blocks reading [day] DataBase...... finished! Cost 1.35 secs\n",
      "day blocks loading finished! Cost 1.38 secs\n",
      "day blocks process...... finished! Cost 0.29 secs\n",
      "day blocks masking...... finished! Cost 0.09 secs\n",
      "day blocks saving ...... finished! Cost 0.25 secs\n",
      "day blocks norming...... finished! Cost 0.00 secs\n",
      "day finished! Cost 2.34 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "30m blocks loading start!\n",
      " --> trade_ts blocks reading [30min] DataBase...... finished! Cost 0.30 secs\n",
      " --> trade_ts blocks reading [day] DataBase...... finished! Cost 1.18 secs\n",
      "30m blocks loading finished! Cost 1.49 secs\n",
      "30m blocks process...... finished! Cost 0.11 secs\n",
      "30m blocks masking...... finished! Cost 0.07 secs\n",
      "30m blocks saving ...... finished! Cost 0.09 secs\n",
      "30m blocks norming...... finished! Cost 0.00 secs\n",
      "30m finished! Cost 2.10 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "style blocks loading start!\n",
      " --> models blocks reading [tushare_cne5_exp] DataBase...... finished! Cost 1.81 secs\n",
      "style blocks loading finished! Cost 1.81 secs\n",
      "style blocks process...... finished! Cost 0.00 secs\n",
      "style blocks masking...... finished! Cost 0.10 secs\n",
      "style blocks saving ...... finished! Cost 0.40 secs\n",
      "style blocks norming...... finished! Cost 0.00 secs\n",
      "style finished! Cost 2.68 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "indus blocks loading start!\n",
      " --> models blocks reading [tushare_cne5_exp] DataBase...... finished! Cost 2.71 secs\n",
      "indus blocks loading finished! Cost 2.72 secs\n",
      "indus blocks process...... finished! Cost 0.00 secs\n",
      "indus blocks masking...... finished! Cost 0.16 secs\n",
      "indus blocks saving ...... finished! Cost 1.50 secs\n",
      "indus blocks norming...... finished! Cost 0.00 secs\n",
      "indus finished! Cost 4.71 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "week blocks loading start!\n",
      " --> trade_ts blocks reading [day] DataBase...... finished! Cost 2.53 secs\n",
      "week blocks loading finished! Cost 2.56 secs\n",
      "week blocks process...... finished! Cost 2.12 secs\n",
      "week blocks masking...... finished! Cost 0.20 secs\n",
      "week blocks saving ...... finished! Cost 3.89 secs\n",
      "week blocks norming...... finished! Cost 0.00 secs\n",
      "week finished! Cost 9.11 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "Data Processing Finished! Cost 32.28 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "update_hidden: ********************\n",
      "model_name is None, update all hidden models\n",
      "  -->  update hidden feature for HiddenExtractingModel(name=gru_day)\n",
      "Beware! Should be at server or short_test, but short_test is False now!\n",
      "try using D:\\Coding\\learndl\\learndl\\data\\Interim\\DataSet/day.20240607.pt , success!\n",
      "Load  2 DataBlocks...... finished! Cost 0.19 secs\n",
      "Align 2 DataBlocks...... finished! Cost 0.29 secs\n",
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 316/316 [00:00<00:00, 2731.49it/s]\n",
      "100%|██████████| 316/316 [00:00<00:00, 3561.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "update_factors: ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish model [gru_day] predicting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish model [gruRTN_day] predicting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish model [gru_avg] predicting!\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.api import DataAPI , ModelAPI\n",
    "\n",
    "#print('update_data: ' + '*' * 20)\n",
    "DataAPI.update()\n",
    "\n",
    "ModelAPI.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Coding\\learndl\\learndl\\configs\\nn\\ts_mixer.yaml does not exist, trying default.yaml\n",
      "Load  2 DataBlocks...... finished! Cost 0.09 secs\n",
      "Align 2 DataBlocks...... finished! Cost 0.23 secs\n",
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 212/212 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape is torch.Size([5169, 30, 6])\n",
      "y shape is torch.Size([5169, 1])\n",
      "Test Forward Success\n",
      "x shape is torch.Size([5169, 30, 6])\n",
      "y shape is torch.Size([5169, 1])\n",
      "Test Forward Success\n",
      "score function of [spearman] calculated and success!\n",
      "loss function of [ccc] calculated and success!\n",
      "metrics :  Metrics(loss=ccc,metric=spearman,penalty=['hidden_corr'])\n",
      "Test Metrics Success\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelTestor(model=NNPredictor(model_full_name=ts_mixer_day_ShortTest@0@0@0)) , check [.model][.batch_data][.metrics]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.api import ModelAPI\n",
    "model = ModelAPI.Testor('ts_mixer')\n",
    "model.try_forward()\n",
    "model.try_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchMetric(score=0.06481771171092987, losses={'ccc': tensor([1.0014], grad_fn=<ExpBackward0>), 'hidden_corr': tensor([0.])})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics.output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
