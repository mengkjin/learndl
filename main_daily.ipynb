{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.boost import GeneralBooster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train':                  Amount_20D_Avg  Amount_240D_Avg  Asset_LR  Asset_LR_Gr  \\\n",
       " date     secid                                                            \n",
       " 20211029 1             0.875544         0.875703  0.375270     0.775000   \n",
       "          2             0.993958         0.994373  0.994009     0.516299   \n",
       "          4             0.755437         0.861125  0.301701     0.438971   \n",
       "          5             0.181489         0.158951  0.389648     0.067157   \n",
       "          6             0.166022         0.183120  0.246585     0.946078   \n",
       " ...                         ...              ...       ...          ...   \n",
       " 20230831 871970        0.010362         0.010567  0.030890     0.458824   \n",
       "          871981        0.028687         0.030800  0.077007     0.230937   \n",
       "          872925        0.029014         0.025629  0.018490     0.662309   \n",
       "          873169        0.025742         0.055755  0.021101     0.489107   \n",
       "          873223        0.029668         0.074978  0.037198     0.037473   \n",
       " \n",
       "                  Asset_LR_Ln  Bias_20D   Bias_5D  Bias_60D     BP_LR  \\\n",
       " date     secid                                                         \n",
       " 20211029 1          0.375270  0.775375  0.175523  0.776047  0.124611   \n",
       "          2          0.994009  0.039633  0.054220  0.183057  0.579679   \n",
       "          4          0.301701  0.079507  0.163982  0.112707  0.666906   \n",
       "          5          0.389648  0.840744  0.742486  0.784810  0.654086   \n",
       "          6          0.246585  0.404906  0.738278  0.309153  0.500120   \n",
       " ...                      ...       ...       ...       ...       ...   \n",
       " 20230831 871970     0.030890  0.113983  0.214348  0.177692  0.928975   \n",
       "          871981     0.077007  0.173320  0.052036  0.347692  0.810746   \n",
       "          872925     0.018490  0.023560  0.001089  0.063736  0.593213   \n",
       "          873169     0.021101  0.057155  0.129980  0.192967  0.979117   \n",
       "          873223     0.037198  0.108421  0.051600  0.225495  0.959321   \n",
       " \n",
       "                  BP_LR_Tangible  ...  TargetReturn  ThreeCosts2Revenue_TTM  \\\n",
       " date     secid                   ...                                         \n",
       " 20211029 1             0.124611  ...      0.826789                0.500124   \n",
       "          2             0.579679  ...      0.845155                0.154084   \n",
       "          4             0.158160  ...           NaN                0.369554   \n",
       "          5             0.808172  ...           NaN                0.755941   \n",
       "          6             0.532231  ...           NaN                0.476856   \n",
       " ...                         ...  ...           ...                     ...   \n",
       " 20230831 871970        0.928975  ...           NaN                0.867278   \n",
       "          871981        0.836198  ...           NaN                0.555058   \n",
       "          872925        0.666957  ...           NaN                0.375336   \n",
       "          873169        0.985860  ...           NaN                0.358102   \n",
       "          873223        0.966717  ...           NaN                0.691137   \n",
       " \n",
       "                  Turnover_20D_Avg  Turnover_240D_Avg  Turnover_Close_20D_Corr  \\\n",
       " date     secid                                                                  \n",
       " 20211029 1               0.824915           0.624808                 0.075278   \n",
       "          2               0.817545           0.642711                 0.087482   \n",
       "          4               0.825520           0.909207                 0.655631   \n",
       "          5               0.115273           0.229284                 0.181489   \n",
       "          6               0.387989           0.468031                 0.579749   \n",
       " ...                           ...                ...                      ...   \n",
       " 20230831 871970          0.032068           0.052158                 0.302029   \n",
       "          871981          0.021924           0.037995                 0.154123   \n",
       "          872925          0.039485           0.053058                 0.092932   \n",
       "          873169          0.025742           0.230216                 0.092059   \n",
       "          873223          0.037522           0.379946                 0.065227   \n",
       " \n",
       "                  Turnover_Close_5D_Corr  Turnover_Close_60D_Corr  \\\n",
       " date     secid                                                     \n",
       " 20211029 1                     0.924742                 0.074732   \n",
       "          2                     0.246213                 0.087634   \n",
       "          4                     0.334215                 0.836173   \n",
       "          5                     0.094253                 0.040409   \n",
       "          6                     0.452392                 0.626826   \n",
       " ...                                 ...                      ...   \n",
       " 20230831 871970                0.438711                 0.344286   \n",
       "          871981                0.239713                 0.606923   \n",
       "          872925                0.476159                 0.707473   \n",
       "          873169                0.129980                 0.003956   \n",
       "          873223                0.200305                 0.221758   \n",
       " \n",
       "                  Vol_20D_240D_Avg  Vol_20D_CV     label  \n",
       " date     secid                                           \n",
       " 20211029 1               0.875353    0.775375 -0.105641  \n",
       "          2               0.896384    0.642943  0.002746  \n",
       "          4               0.463452    0.420735  0.120905  \n",
       "          5               0.326494    0.555341  0.000000  \n",
       "          6               0.389459    0.674239 -0.016787  \n",
       " ...                           ...         ...       ...  \n",
       " 20230831 871970          0.521143    0.863765 -0.047478  \n",
       "          871981          0.038012    0.834097 -0.063205  \n",
       "          872925          0.567701    0.949825  0.350190  \n",
       "          873169          0.011134    0.954188 -0.008114  \n",
       "          873223          0.004948    0.805192 -0.014599  \n",
       " \n",
       " [101371 rows x 170 columns],\n",
       " 'valid':                  Amount_20D_Avg  Amount_240D_Avg  Asset_LR  Asset_LR_Gr  \\\n",
       " date     secid                                                            \n",
       " 20230928 1             0.775615         0.925224  0.374919     0.224880   \n",
       "          2             0.935066         0.991256  0.991430     0.268378   \n",
       "          4             0.760714         0.468834  0.046865     0.002066   \n",
       "          5             0.077877         0.072197  0.423085     0.685950   \n",
       "          6             0.657494         0.731390  0.286939     0.842105   \n",
       " ...                         ...              ...       ...          ...   \n",
       "          871970        0.010224         0.010538  0.031026     0.479556   \n",
       "          871981        0.034805         0.031726  0.076589     0.230100   \n",
       "          872925        0.039374         0.031166  0.018117     0.659091   \n",
       "          873169        0.003807         0.050897  0.021046     0.475642   \n",
       "          873223        0.025125         0.054709  0.037101     0.041975   \n",
       " \n",
       "                  Asset_LR_Ln  Bias_20D   Bias_5D  Bias_60D     BP_LR  \\\n",
       " date     secid                                                         \n",
       " 20230928 1          0.374919  0.124429  0.825043  0.074536  0.325125   \n",
       "          2          0.991430  0.306069  0.509666  0.657268  0.749946   \n",
       "          4          0.046865  0.411246  0.061034  0.140874  0.082013   \n",
       "          5          0.423085  0.894061  0.832537  0.966776  0.832285   \n",
       "          6          0.286939  0.379269  0.620873  0.231913  0.472337   \n",
       " ...                      ...       ...       ...       ...       ...   \n",
       "          871970     0.031026  0.091364  0.479800  0.113989  0.928835   \n",
       "          871981     0.076589  0.121057  0.873805  0.085683  0.873725   \n",
       "          872925     0.018117  0.993909  0.994027  0.981202  0.452484   \n",
       "          873169     0.021046  0.173700  0.338076  0.185574  0.979171   \n",
       "          873223     0.037101  0.169132  0.245004  0.208634  0.959427   \n",
       " \n",
       "                  BP_LR_Tangible  ...  TargetReturn  ThreeCosts2Revenue_TTM  \\\n",
       " date     secid                   ...                                         \n",
       " 20230928 1             0.325125  ...      0.874470                0.500112   \n",
       "          2             0.787481  ...      0.500265                0.120844   \n",
       "          4             0.001953  ...           NaN                0.832403   \n",
       "          5             0.914949  ...           NaN                0.851149   \n",
       "          6             0.527880  ...           NaN                0.657331   \n",
       " ...                         ...  ...           ...                     ...   \n",
       "          871970        0.928835  ...           NaN                0.867663   \n",
       "          871981        0.886309  ...           NaN                0.571747   \n",
       "          872925        0.500108  ...           NaN                0.367998   \n",
       "          873169        0.985897  ...           NaN                0.356728   \n",
       "          873223        0.963116  ...           NaN                0.692256   \n",
       " \n",
       "                  Turnover_20D_Avg  Turnover_240D_Avg  Turnover_Close_20D_Corr  \\\n",
       " date     secid                                                                  \n",
       " 20230928 1               0.775615           0.825000                 0.224603   \n",
       "          2               0.361540           0.416480                 0.713183   \n",
       "          4               0.775615           0.630045                 0.353491   \n",
       "          5               0.271481           0.148655                 0.472482   \n",
       "          6               0.805960           0.953139                 0.953557   \n",
       " ...                           ...                ...                      ...   \n",
       "          871970          0.030890           0.052466                 0.275615   \n",
       "          871981          0.065151           0.031726                 0.540570   \n",
       "          872925          0.231020           0.053139                 0.204699   \n",
       "          873169          0.009463           0.113453                 0.122362   \n",
       "          873223          0.033609           0.153587                 0.554601   \n",
       " \n",
       "                  Turnover_Close_5D_Corr  Turnover_Close_60D_Corr  \\\n",
       " date     secid                                                     \n",
       " 20230928 1                     0.975777                 0.675410   \n",
       "          2                     0.601890                 0.620328   \n",
       "          4                     0.597002                 0.593333   \n",
       "          5                     0.286118                 0.173552   \n",
       "          6                     0.528134                 0.991475   \n",
       " ...                                 ...                      ...   \n",
       "          871970                0.071475                 0.051475   \n",
       "          871981                0.070823                 0.293552   \n",
       "          872925                0.907886                 0.496393   \n",
       "          873169                0.940474                 0.081530   \n",
       "          873223                0.604388                 0.200219   \n",
       " \n",
       "                  Vol_20D_240D_Avg  Vol_20D_CV     label  \n",
       " date     secid                                           \n",
       " 20230928 1               0.024798    0.525234 -0.066071  \n",
       "          2               0.268402    0.694148 -0.133792  \n",
       "          4               0.842908    0.532739  0.082346  \n",
       "          5               0.630162    0.812486 -0.020690  \n",
       "          6               0.176167    0.953557 -0.048458  \n",
       " ...                           ...         ...       ...  \n",
       "          871970          0.839991    0.989993 -0.006231  \n",
       "          871981          0.705117    0.948662 -0.145382  \n",
       "          872925          0.993043    0.928432 -0.117978  \n",
       "          873169          0.000449    0.948336 -0.067485  \n",
       "          873223          0.065305    0.869589 -0.085185  \n",
       " \n",
       " [4609 rows x 170 columns],\n",
       " 'test':                  Amount_20D_Avg  Amount_240D_Avg  Asset_LR  Asset_LR_Gr  \\\n",
       " date     secid                                                            \n",
       " 20231031 1             0.726094         0.925343  0.375496     0.223964   \n",
       "          2             0.972259         0.991340  0.991120     0.360337   \n",
       "          4             0.963265         0.644734  0.059890     0.001936   \n",
       "          5             0.116455         0.123432  0.453240     0.665699   \n",
       "          6             0.435334         0.750050  0.306065     0.786585   \n",
       " ...                         ...              ...       ...          ...   \n",
       "          873339        0.036073         0.037627  0.107595     0.768002   \n",
       "          873527        0.009468         0.009954  0.067448     0.875629   \n",
       "          873576        0.055955              NaN  0.099849     0.964189   \n",
       "          873593        0.761693              NaN  0.151332     0.948703   \n",
       "          873665        0.212270              NaN  0.102399     0.912698   \n",
       " \n",
       "                  Asset_LR_Ln  Bias_20D   Bias_5D  Bias_60D     BP_LR  \\\n",
       " date     secid                                                         \n",
       " 20231031 1          0.375496  0.224673  0.824664  0.074529  0.474400   \n",
       "          2          0.991120  0.083128  0.102421  0.213783  0.768751   \n",
       "          4          0.059890  0.741905  0.786079  0.772892  0.048744   \n",
       "          5          0.453240  0.193524  0.365992  0.691034  0.866238   \n",
       "          6          0.306065  0.509373  0.397674  0.324005  0.490270   \n",
       " ...                      ...       ...       ...       ...       ...   \n",
       "          873339     0.107595  0.321814  0.440893  0.226156  0.868317   \n",
       "          873527     0.067448  0.144291  0.163798  0.240529  0.952012   \n",
       "          873576     0.099849  0.988260  0.966427  0.766324  0.188929   \n",
       "          873593     0.151332  0.006154  0.927747  0.000381  0.122804   \n",
       "          873665     0.102399  0.546298  0.857859       NaN  0.942188   \n",
       " \n",
       "                  BP_LR_Tangible  ...  TargetReturn  ThreeCosts2Revenue_TTM  \\\n",
       " date     secid                   ...                                         \n",
       " 20231031 1             0.474400  ...      0.816628                0.500097   \n",
       "          2             0.805970  ...      0.634642                0.176738   \n",
       "          4             0.001700  ...           NaN                0.838079   \n",
       "          5             0.935953  ...           NaN                0.887662   \n",
       "          6             0.490270  ...           NaN                0.657854   \n",
       " ...                         ...  ...           ...                     ...   \n",
       "          873339        0.868317  ...           NaN                0.297308   \n",
       "          873527        0.952012  ...           NaN                0.278520   \n",
       "          873576        0.277725  ...           NaN                0.077087   \n",
       "          873593        0.136596  ...      0.997229                0.705210   \n",
       "          873665        0.962592  ...           NaN                0.576022   \n",
       " \n",
       "                  Turnover_20D_Avg  Turnover_240D_Avg  Turnover_Close_20D_Corr  \\\n",
       " date     secid                                                                  \n",
       " 20231031 1               0.824560           0.824806                 0.124598   \n",
       "          2               0.472354           0.416783                 0.064571   \n",
       "          4               0.928612           0.734023                 0.967714   \n",
       "          5               0.237455           0.169819                 0.486650   \n",
       "          6               0.657641           0.935198                 0.306287   \n",
       " ...                           ...                ...                      ...   \n",
       "          873339          0.012308           0.037627                 0.155084   \n",
       "          873527          0.009468           0.009954                 0.106609   \n",
       "          873576          0.300227                NaN                 0.900303   \n",
       "          873593          0.816701                NaN                 0.029729   \n",
       "          873665          0.933725                NaN                 0.982579   \n",
       " \n",
       "                  Turnover_Close_5D_Corr  Turnover_Close_60D_Corr  \\\n",
       " date     secid                                                     \n",
       " 20231031 1                     0.624929                 0.575576   \n",
       "          2                     0.119822                 0.324005   \n",
       "          4                     0.951390                 0.864078   \n",
       "          5                     0.031398                 0.204074   \n",
       "          6                     0.750142                 0.953931   \n",
       " ...                                 ...                      ...   \n",
       "          873339                0.321260                 0.132115   \n",
       "          873527                0.606204                 0.470683   \n",
       "          873576                0.966427                 0.900628   \n",
       "          873593                0.740496                 0.051399   \n",
       "          873665                0.881502                      NaN   \n",
       " \n",
       "                  Vol_20D_240D_Avg  Vol_20D_CV     label  \n",
       " date     secid                                           \n",
       " 20231031 1               0.025209    0.375308 -0.074570  \n",
       "          2               0.471802    0.509373  0.009709  \n",
       "          4               0.952272    0.565423  0.000000  \n",
       "          5               0.638501    0.814618 -0.014085  \n",
       "          6               0.008868    0.213975  0.071759  \n",
       " ...                           ...         ...       ...  \n",
       "          873339          0.012754    0.559364  0.328084  \n",
       "          873527          0.068553    0.779019  0.288026  \n",
       "          873576               NaN    0.878621  0.435461  \n",
       "          873593               NaN    0.641166  0.880506  \n",
       "          873665               NaN    0.999432  0.567663  \n",
       " \n",
       " [5293 rows x 170 columns]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = GeneralBooster.df_input()\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 1, Est-Err: 0.4939, F_name: OCFA_Resd\n",
      "Round: 2, Est-Err: 0.4960, F_name: Amount_20D_Avg\n",
      "Round: 3, Est-Err: 0.4986, F_name: CL\n",
      "Round: 4, Est-Err: 0.4992, F_name: OCFA_Para\n",
      "Round: 5, Est-Err: 0.4992, F_name: BuyMinusSell_5D_Vol\n",
      "Round: 6, Est-Err: 0.4985, F_name: Rating_R3M\n",
      "Round: 7, Est-Err: 0.4995, F_name: Equity_LR_Gr\n",
      "Round: 8, Est-Err: 0.4996, F_name: Num_Emp\n",
      "Round: 9, Est-Err: 0.4997, F_name: BuyMinusSell_5D_Amount\n",
      "Round: 10, Est-Err: 0.4990, F_name: OCFA_Resd\n",
      "Round: 11, Est-Err: 0.4997, F_name: EPS_FY0_R1M\n",
      "Round: 12, Est-Err: 0.4998, F_name: CloseTrend_240D_Reg\n",
      "Round: 13, Est-Err: 0.4998, F_name: BuyMinusSell_5D_Vol\n",
      "Round: 14, Est-Err: 0.4997, F_name: Bias_5D\n",
      "Round: 15, Est-Err: 0.4998, F_name: ILLIQ_240D\n",
      "Round: 16, Est-Err: 0.4998, F_name: NetProfitDeducted_SQ_YoY\n",
      "Round: 17, Est-Err: 0.4998, F_name: MarketCap\n",
      "Round: 18, Est-Err: 0.4998, F_name: BuyMinusSell_5D_Amount\n",
      "Round: 19, Est-Err: 0.4997, F_name: FloatCap\n",
      "Round: 20, Est-Err: 0.4998, F_name: IVR_20D\n",
      "Round: 21, Est-Err: 0.4998, F_name: Vol_20D_240D_Avg\n",
      "Round: 22, Est-Err: 0.4999, F_name: ROE_Fwd12M\n",
      "Round: 23, Est-Err: 0.4999, F_name: TargetReturn\n",
      "Round: 24, Est-Err: 0.4999, F_name: BuyMinusSell_5D_Vol\n",
      "Round: 25, Est-Err: 0.4998, F_name: ROE_Fwd12M_R3M\n",
      "Round: 26, Est-Err: 0.4999, F_name: Rating_R1M\n",
      "Round: 27, Est-Err: 0.4999, F_name: EPS_FY0_R3M\n",
      "Round: 28, Est-Err: 0.4999, F_name: OCF_SQ_Acc\n",
      "Round: 29, Est-Err: 0.4999, F_name: Num_EPS_FY0\n",
      "Round: 30, Est-Err: 0.4999, F_name: Turnover_Close_5D_Corr\n"
     ]
    }
   ],
   "source": [
    "model1 = GeneralBooster('lgbm',**inputs).fit()\n",
    "model2 = GeneralBooster('ada',**inputs).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update Files\n",
      "Sun Aug 25 20:21:13 2024 : Updated ~ DB_information\\calendar.feather Done! Cost 0.02 Secs\n",
      "Sun Aug 25 20:21:13 2024 : Updated ~ DB_information\\description.feather Done! Cost 0.03 Secs\n",
      "Sun Aug 25 20:21:13 2024 : Updated ~ DB_information\\st.feather Done! Cost 0.02 Secs\n",
      "Sun Aug 25 20:21:15 2024 : Updated ~ DB_information\\industry.feather Done! Cost 2.34 Secs\n",
      "Sun Aug 25 20:21:20 2024 : Updated ~ DB_information\\concepts.feather Done! Cost 5.19 Secs\n",
      "Sun Aug 25 20:21:22 2024 : Updated ~ DB_models\\longcl_exp\\2024\\longcl_exp.20240822.feather Done! Cost 0.10 Secs\n",
      "Sun Aug 25 20:21:22 2024 : Updated ~ DB_models\\risk_exp\\2024\\risk_exp.20240823.feather Done! Cost 0.05 Secs\n",
      "Sun Aug 25 20:21:22 2024 : Updated ~ DB_models\\risk_cov\\2024\\risk_cov.20240823.feather Done! Cost 0.03 Secs\n",
      "Sun Aug 25 20:21:22 2024 : Updated ~ DB_models\\risk_spec\\2024\\risk_spec.20240823.feather Done! Cost 0.02 Secs\n",
      "Sun Aug 25 20:21:24 2024 : Updated ~ DB_trade\\day\\2024\\day.20240823.feather Done! Cost 0.07 Secs\n",
      "Sun Aug 25 20:21:24 2024 : Updated ~ DB_trade\\5day\\2024\\5day.20240823.feather Done! Cost 0.27 Secs\n",
      "Sun Aug 25 20:21:25 2024 : Updated ~ DB_trade\\10day\\2024\\10day.20240823.feather Done! Cost 0.47 Secs\n",
      "Sun Aug 25 20:21:26 2024 : Updated ~ DB_trade\\20day\\2024\\20day.20240823.feather Done! Cost 1.00 Secs\n",
      "Sun Aug 25 20:21:28 2024 : Updated ~ DB_trade\\min\\2024\\min.20240823.feather Done! Cost 2.94 Secs\n",
      "Sun Aug 25 20:21:29 2024 : Updated ~ DB_trade\\5min\\2024\\5min.20240823.feather Done! Cost 0.35 Secs\n",
      "Sun Aug 25 20:21:29 2024 : Updated ~ DB_trade\\10min\\2024\\10min.20240823.feather Done! Cost 0.31 Secs\n",
      "Sun Aug 25 20:21:29 2024 : Updated ~ DB_trade\\15min\\2024\\15min.20240823.feather Done! Cost 0.24 Secs\n",
      "Sun Aug 25 20:21:30 2024 : Updated ~ DB_trade\\30min\\2024\\30min.20240823.feather Done! Cost 0.23 Secs\n",
      "Sun Aug 25 20:21:30 2024 : Updated ~ DB_trade\\60min\\2024\\60min.20240823.feather Done! Cost 0.24 Secs\n",
      "Sun Aug 25 20:21:32 2024 : Updated ~ DB_labels\\ret20_lag\\2024\\ret20_lag.20240725.feather Done! Cost 0.79 Secs\n",
      "Sun Aug 25 20:21:33 2024 : Updated ~ DB_labels\\ret20\\2024\\ret20.20240726.feather Done! Cost 0.66 Secs\n",
      "Sun Aug 25 20:21:41 2024 : Updated ~ DB_labels\\ret10_lag\\2024\\ret10_lag.20240808.feather Done! Cost 0.48 Secs\n",
      "Sun Aug 25 20:21:42 2024 : Updated ~ DB_labels\\ret10\\2024\\ret10.20240809.feather Done! Cost 0.62 Secs\n",
      "Sun Aug 25 20:21:49 2024 : Updated ~ DB_labels\\ret5_lag\\2024\\ret5_lag.20240815.feather Done! Cost 0.45 Secs\n",
      "Sun Aug 25 20:21:51 2024 : Updated ~ DB_labels\\ret5\\2024\\ret5.20240816.feather Done! Cost 0.47 Secs\n",
      "Sun Aug 25 20:22:04 2024 : Updated ~ DB_benchmark\\csi300\\2024\\csi300.20240822.feather Done! Cost 0.01 Secs\n",
      "Sun Aug 25 20:22:04 2024 : Updated ~ DB_benchmark\\csi500\\2024\\csi500.20240822.feather Done! Cost 0.01 Secs\n",
      "Sun Aug 25 20:22:04 2024 : Updated ~ DB_benchmark\\csi1000\\2024\\csi1000.20240822.feather Done! Cost 0.02 Secs\n",
      "Sun Aug 25 20:22:04 2024 : Updated ~ DB_benchmark\\csi300\\2024\\csi300.20240823.feather Done! Cost 0.01 Secs\n",
      "Sun Aug 25 20:22:04 2024 : Updated ~ DB_benchmark\\csi500\\2024\\csi500.20240823.feather Done! Cost 0.00 Secs\n",
      "Sun Aug 25 20:22:04 2024 : Updated ~ DB_benchmark\\csi1000\\2024\\csi1000.20240823.feather Done! Cost 0.02 Secs\n",
      "Sun Aug 25 20:22:04 2024 : download since!\n",
      "Connection and Factor preparation finished!\n",
      "Sun Aug 25 20:22:04 2024 : sellside/dongfang.hfq_chars from 20240823 to 20240825, total 1 periods\n",
      "Start sellside/dongfang.hfq_chars:20240823-20240825 \n",
      "Done sellside/dongfang.hfq_chars:20240823-20240825, cost 2.9 Secs\n",
      "Sun Aug 25 20:22:07 2024 : sellside/dongfang.l2_chars from 20240823 to 20240825, total 1 periods\n",
      "Start sellside/dongfang.l2_chars:20240823-20240825 \n",
      "Done sellside/dongfang.l2_chars:20240823-20240825, cost 29.5 Secs\n",
      "Sun Aug 25 20:22:37 2024 : sellside/dongfang.ms_chars from 20240823 to 20240825, total 1 periods\n",
      "Start sellside/dongfang.ms_chars:20240823-20240825 \n",
      "Done sellside/dongfang.ms_chars:20240823-20240825, cost 48.2 Secs\n",
      "Sun Aug 25 20:23:25 2024 : sellside/dongfang.order_flow from 20240823 to 20240825, total 1 periods\n",
      "Start sellside/dongfang.order_flow:20240823-20240825 \n",
      "Done sellside/dongfang.order_flow:20240823-20240825, cost 1.2 Secs\n",
      "Sun Aug 25 20:23:26 2024 : sellside/dongfang.gp from 20240822 to 20240825, total 1 periods\n",
      "Start sellside/dongfang.gp:20240822-20240825 \n",
      "Done sellside/dongfang.gp:20240822-20240825, cost 2.0 Secs\n",
      "Sun Aug 25 20:23:28 2024 : sellside/dongfang.tra from 20240822 to 20240825, total 1 periods\n",
      "Start sellside/dongfang.tra:20240822-20240825 \n",
      "Done sellside/dongfang.tra:20240822-20240825, cost 1.7 Secs\n",
      "Sun Aug 25 20:23:30 2024 : sellside/dongfang.hist from 20240822 to 20240825, total 1 periods\n",
      "Start sellside/dongfang.hist:20240822-20240825 \n",
      "Done sellside/dongfang.hist:20240822-20240825, cost 1.5 Secs\n",
      "Sun Aug 25 20:23:32 2024 : sellside/dongfang.scores_v0 from 20240823 to 20240825, total 1 periods\n",
      "Start sellside/dongfang.scores_v0:20240823-20240825 \n",
      "Done sellside/dongfang.scores_v0:20240823-20240825, cost 1.6 Secs\n",
      "Sun Aug 25 20:23:33 2024 : sellside/dongfang.factorvae from 20240822 to 20240825, total 1 periods\n",
      "Start sellside/dongfang.factorvae:20240822-20240825 \n",
      "Done sellside/dongfang.factorvae:20240822-20240825, cost 1.4 Secs\n",
      "Sun Aug 25 20:23:35 2024 : sellside/huatai.dl_factors from 20240823 to 20240825, total 1 periods\n",
      "Start sellside/huatai.dl_factors:20240823-20240825 \n",
      "Done sellside/huatai.dl_factors:20240823-20240825, cost 5.0 Secs\n",
      "Sun Aug 25 20:23:40 2024 : All Updates Done! Cost 146.95 Secs\n",
      "--------------------------------------------------------------------------------\n",
      "Calendar Updating information_ts/calendar at 20240825\n",
      "Description Updating information_ts/description at 20240825\n",
      "SWIndustry Updating information_ts/industry at 20240825\n",
      "ChangeName Updating information_ts/change_name at 20240825\n",
      "THSConcept Already Updated at 20240731\n",
      "DailyValuation Updating trade_ts/day_val at 20240823\n",
      "DailyValuation Updating trade_ts/day_val at 20240824\n",
      "DailyValuation Updating trade_ts/day_val at 20240825\n",
      "DailyQuote Updating trade_ts/day at 20240823\n",
      "DailyQuote Updating trade_ts/day at 20240824\n",
      "DailyQuote Updating trade_ts/day at 20240825\n",
      "FinaIndicator Already Updated at 20240630\n",
      "Finish exposure update at date 20240823\n",
      "Finish risk update at date 20240823\n",
      "--------------------------------------------------------------------------------\n",
      "predict is True , Data Processing start!\n",
      "6 datas :['y', 'day', '30m', 'style', 'indus', 'week']\n",
      "y blocks loading start!\n",
      " --> labels blocks reading [ret10_lag] DataBase...... finished! Cost 0.63 secs\n",
      " --> labels blocks reading [ret20_lag] DataBase...... finished! Cost 0.69 secs\n",
      " --> labels blocks merging (2)...... finished! Cost 0.15 secs\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 2.35 secs\n",
      "y blocks loading finished! Cost 4.10 secs\n",
      "y blocks process...... finished! Cost 4.21 secs\n",
      "y blocks masking...... finished! Cost 0.07 secs\n",
      "y blocks saving ...... finished! Cost 0.13 secs\n",
      "y blocks norming...... finished! Cost 0.00 secs\n",
      "y finished! Cost 8.61 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "day blocks loading start!\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 0.93 secs\n",
      "day blocks loading finished! Cost 0.95 secs\n",
      "day blocks process...... finished! Cost 0.12 secs\n",
      "day blocks masking...... finished! Cost 0.10 secs\n",
      "day blocks saving ...... finished! Cost 0.13 secs\n",
      "day blocks norming...... finished! Cost 0.00 secs\n",
      "day finished! Cost 1.42 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "30m blocks loading start!\n",
      " --> trade blocks reading [30min] DataBase...... finished! Cost 5.35 secs\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 0.82 secs\n",
      "30m blocks loading finished! Cost 6.21 secs\n",
      "30m blocks process...... finished! Cost 1.57 secs\n",
      "30m blocks masking...... finished! Cost 0.15 secs\n",
      "30m blocks saving ...... finished! Cost 1.68 secs\n",
      "30m blocks norming...... finished! Cost 0.00 secs\n",
      "30m finished! Cost 9.73 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "style blocks loading start!\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 1.32 secs\n",
      "style blocks loading finished! Cost 1.35 secs\n",
      "style blocks process...... finished! Cost 0.00 secs\n",
      "style blocks masking...... finished! Cost 0.06 secs\n",
      "style blocks saving ...... finished! Cost 0.20 secs\n",
      "style blocks norming...... finished! Cost 0.00 secs\n",
      "style finished! Cost 1.72 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "indus blocks loading start!\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 2.32 secs\n",
      "indus blocks loading finished! Cost 2.32 secs\n",
      "indus blocks process...... finished! Cost 0.00 secs\n",
      "indus blocks masking...... finished! Cost 0.13 secs\n",
      "indus blocks saving ...... finished! Cost 1.19 secs\n",
      "indus blocks norming...... finished! Cost 0.00 secs\n",
      "indus finished! Cost 3.73 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "week blocks loading start!\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 1.90 secs\n",
      "week blocks loading finished! Cost 1.92 secs\n",
      "week blocks process...... finished! Cost 1.48 secs\n",
      "week blocks masking...... finished! Cost 0.17 secs\n",
      "week blocks saving ...... finished! Cost 2.38 secs\n",
      "week blocks norming...... finished! Cost 0.00 secs\n",
      "week finished! Cost 6.08 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "Data Processing Finished! Cost 31.28 Seconds\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'd:\\\\Coding\\\\learndl\\\\learndl\\\\models\\\\gru_day\\\\default.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m DataAPI\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m      4\u001b[0m DataAPI\u001b[38;5;241m.\u001b[39mprepare_predict_data()\n\u001b[1;32m----> 5\u001b[0m \u001b[43mPredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_factors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Coding\\learndl\\learndl\\src\\model\\api\\predictor.py:43\u001b[0m, in \u001b[0;36mPredictor.update_factors\u001b[1;34m(cls, silent)\u001b[0m\n\u001b[0;32m     41\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(model)\n\u001b[0;32m     42\u001b[0m CONF\u001b[38;5;241m.\u001b[39mSILENT \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m \u001b[43mmd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdeploy()\n\u001b[0;32m     44\u001b[0m CONF\u001b[38;5;241m.\u001b[39mSILENT \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinish model [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] predicting!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Coding\\learndl\\learndl\\src\\model\\api\\predictor.py:61\u001b[0m, in \u001b[0;36mPredictor.get_df\u001b[1;34m(self, start_dt, end_dt)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_df\u001b[39m(\u001b[38;5;28mself\u001b[39m , start_dt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m , end_dt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20991231\u001b[39m):\n\u001b[0;32m     60\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''save recent prediction to self.df'''\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_dt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart_dt\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_dt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mend_dt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32md:\\Coding\\learndl\\learndl\\src\\model\\api\\predictor.py:82\u001b[0m, in \u001b[0;36mPredictor.predict\u001b[1;34m(self, start_dt, end_dt)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_dt \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m: start_dt \u001b[38;5;241m=\u001b[39m today(start_dt)\n\u001b[0;32m     81\u001b[0m device       \u001b[38;5;241m=\u001b[39m Device()\n\u001b[1;32m---> 82\u001b[0m model_config \u001b[38;5;241m=\u001b[39m \u001b[43mTrainConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoinpath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m deposition   \u001b[38;5;241m=\u001b[39m Deposition(model_config)\n\u001b[0;32m     84\u001b[0m model_dates  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreg_model\u001b[38;5;241m.\u001b[39mmodel_dates \n",
      "File \u001b[1;32md:\\Coding\\learndl\\learndl\\src\\model\\util\\config.py:310\u001b[0m, in \u001b[0;36mTrainConfig.load\u001b[1;34m(cls, config_path, do_parser, par_args, override, makedir)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''load config yaml to get default/giving params'''\u001b[39;00m\n\u001b[0;32m    309\u001b[0m model_name \u001b[38;5;241m=\u001b[39m config_path\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mif\u001b[39;00m config_path \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverride\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_parser: config\u001b[38;5;241m.\u001b[39mprocess_parser(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mparser_args(par_args))\n\u001b[0;32m    313\u001b[0m base_path \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mmodel_base_path\n",
      "File \u001b[1;32md:\\Coding\\learndl\\learndl\\src\\model\\util\\config.py:261\u001b[0m, in \u001b[0;36mTrainConfig.__init__\u001b[1;34m(self, config_path, model_name, override)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m , config_path : Optional[Path] , model_name  : Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m , override \u001b[38;5;241m=\u001b[39m {}):\n\u001b[1;32m--> 261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTrain \u001b[38;5;241m=\u001b[39m \u001b[43mTrainParam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverride\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mModel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTrain\u001b[38;5;241m.\u001b[39mgenerate_model_param(update_inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_training: \u001b[38;5;28mbool\u001b[39m  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32md:\\Coding\\learndl\\learndl\\src\\model\\util\\config.py:17\u001b[0m, in \u001b[0;36mTrainParam.__init__\u001b[1;34m(self, config_path, model_name, override)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_path \u001b[38;5;241m=\u001b[39m config_path\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m=\u001b[39m model_name\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_param\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moverride\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mspecial_adjustment()\u001b[38;5;241m.\u001b[39mmake_model_name()\u001b[38;5;241m.\u001b[39mcheck_validity()\n",
      "File \u001b[1;32md:\\Coding\\learndl\\learndl\\src\\model\\util\\config.py:25\u001b[0m, in \u001b[0;36mTrainParam.load_param\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_param\u001b[39m(\u001b[38;5;28mself\u001b[39m , \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_param : \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m,Any] \u001b[38;5;241m=\u001b[39m \u001b[43mPATH\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_yaml\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_param\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32md:\\Coding\\learndl\\learndl\\src\\basic\\path.py:30\u001b[0m, in \u001b[0;36mread_yaml\u001b[1;34m(yaml_file, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m yaml_file\u001b[38;5;241m.\u001b[39mexists() \u001b[38;5;129;01mand\u001b[39;00m yaml_file\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m yaml_file\u001b[38;5;241m.\u001b[39mwith_name(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myaml_file\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m     29\u001b[0m         yaml_file \u001b[38;5;241m=\u001b[39m yaml_file\u001b[38;5;241m.\u001b[39mwith_name(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myaml_file\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43myaml_file\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     31\u001b[0m     d \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39mload(f , Loader \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39mFullLoader)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m d\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'd:\\\\Coding\\\\learndl\\\\learndl\\\\models\\\\gru_day\\\\default.yaml'"
     ]
    }
   ],
   "source": [
    "from src.api import DataAPI , Predictor\n",
    "\n",
    "DataAPI.update()\n",
    "DataAPI.prepare_predict_data()\n",
    "Predictor.update_factors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data.tushare.download.info import Calendar , pro\n",
    "renamer = {'cal_date' : 'calendar' ,'is_open'  : 'trade'}\n",
    "fields = None\n",
    "df = pro.trade_cal(exchange='SSE').rename(columns=renamer)\n",
    "#df = df.sort_values('calendar').reset_index(drop = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish model [gru_day] predicting!\n",
      "Finish model [gruRTN_day] predicting!\n",
      "Finish model [gru_avg] predicting!\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# DataAPI.prepare_predict_data()\n",
    "Predictor.update_factors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 10.2262],\n",
      "        [  6.4458],\n",
      "        [ -4.2535],\n",
      "        ...,\n",
      "        [  7.8719],\n",
      "        [ -9.5733],\n",
      "        [-43.3097]]) tensor([[  4.4866],\n",
      "        [  5.0432],\n",
      "        [ -8.9115],\n",
      "        ...,\n",
      "        [-27.7883],\n",
      "        [-24.3357],\n",
      "        [-64.8601]])\n",
      "tensor([[  9.5268],\n",
      "        [-13.1543],\n",
      "        [  8.1235],\n",
      "        ...,\n",
      "        [  4.0610],\n",
      "        [  2.5557],\n",
      "        [-28.6509]]) tensor([[ 16.0309],\n",
      "        [-25.3810],\n",
      "        [  7.7358],\n",
      "        ...,\n",
      "        [ -1.2328],\n",
      "        [-21.6224],\n",
      "        [  3.7929]])\n",
      "tensor([[  7.2132],\n",
      "        [  8.2960],\n",
      "        [-10.7186],\n",
      "        ...,\n",
      "        [  7.3211],\n",
      "        [  2.0884],\n",
      "        [-12.6653]]) tensor([[ -2.1297],\n",
      "        [  2.6120],\n",
      "        [-25.0220],\n",
      "        ...,\n",
      "        [  2.3501],\n",
      "        [ -6.2634],\n",
      "        [ -0.4066]])\n",
      "tensor([[  6.7036],\n",
      "        [  2.0849],\n",
      "        [ -8.1760],\n",
      "        ...,\n",
      "        [  7.9754],\n",
      "        [ -1.5401],\n",
      "        [-12.5849]]) tensor([[-28.0546],\n",
      "        [  2.8744],\n",
      "        [ -6.0319],\n",
      "        ...,\n",
      "        [ 10.3225],\n",
      "        [ -3.2130],\n",
      "        [ -3.6488]])\n",
      "tensor([[ -3.6597],\n",
      "        [  3.7306],\n",
      "        [  5.8602],\n",
      "        ...,\n",
      "        [  4.9644],\n",
      "        [  0.4862],\n",
      "        [-38.1238]]) tensor([[-12.5812],\n",
      "        [ -2.6276],\n",
      "        [  1.3919],\n",
      "        ...,\n",
      "        [ -1.6008],\n",
      "        [ 10.8513],\n",
      "        [-24.8606]])\n",
      "tensor([[-29.0559],\n",
      "        [  3.7346],\n",
      "        [ -1.7958],\n",
      "        ...,\n",
      "        [  5.0729],\n",
      "        [  6.7005],\n",
      "        [-28.4890]]) tensor([[-72.0239],\n",
      "        [  1.8877],\n",
      "        [  7.4442],\n",
      "        ...,\n",
      "        [ 13.9584],\n",
      "        [  1.6836],\n",
      "        [-19.6720]])\n",
      "tensor([[-27.2150],\n",
      "        [  3.7258],\n",
      "        [ -1.5324],\n",
      "        ...,\n",
      "        [  5.0138],\n",
      "        [  2.3780],\n",
      "        [-31.5738]]) tensor([[-50.4288],\n",
      "        [  1.4670],\n",
      "        [-26.4943],\n",
      "        ...,\n",
      "        [ -2.1021],\n",
      "        [ -0.3662],\n",
      "        [-33.7146]])\n",
      "Finish model [gru_day] predicting!\n",
      "tensor([[-12.0520],\n",
      "        [-10.1524],\n",
      "        [-13.9670],\n",
      "        ...,\n",
      "        [ -3.7487],\n",
      "        [-15.5251],\n",
      "        [-16.2315]]) tensor([[  0.3162],\n",
      "        [ -9.2628],\n",
      "        [ -8.6102],\n",
      "        ...,\n",
      "        [  5.7974],\n",
      "        [-20.2432],\n",
      "        [-19.6400]])\n",
      "tensor([[-15.7086],\n",
      "        [ -7.9811],\n",
      "        [-13.4141],\n",
      "        ...,\n",
      "        [ 31.8722],\n",
      "        [-15.4796],\n",
      "        [-10.3904]]) tensor([[-12.5820],\n",
      "        [ -9.1625],\n",
      "        [-13.4615],\n",
      "        ...,\n",
      "        [ 43.6141],\n",
      "        [-20.2729],\n",
      "        [-13.5468]])\n",
      "tensor([[-14.0001],\n",
      "        [-14.8610],\n",
      "        [-13.9671],\n",
      "        ...,\n",
      "        [ -5.7537],\n",
      "        [-15.4796],\n",
      "        [-14.8610]]) tensor([[-18.7348],\n",
      "        [-21.4778],\n",
      "        [-17.5162],\n",
      "        ...,\n",
      "        [ -5.6766],\n",
      "        [-11.9226],\n",
      "        [-24.6812]])\n",
      "tensor([[-14.7597],\n",
      "        [-13.4145],\n",
      "        [-13.4145],\n",
      "        ...,\n",
      "        [  5.1259],\n",
      "        [-13.4145],\n",
      "        [-14.8610]]) tensor([[-21.5984],\n",
      "        [-10.7381],\n",
      "        [-18.0183],\n",
      "        ...,\n",
      "        [  4.8534],\n",
      "        [-16.3930],\n",
      "        [-15.8887]])\n",
      "tensor([[ -7.5095],\n",
      "        [  7.4446],\n",
      "        [-13.4145],\n",
      "        ...,\n",
      "        [  5.5769],\n",
      "        [  2.2698],\n",
      "        [-15.2797]]) tensor([[ -2.9609],\n",
      "        [  5.5489],\n",
      "        [-16.8531],\n",
      "        ...,\n",
      "        [  3.7688],\n",
      "        [  2.0592],\n",
      "        [-22.4798]])\n",
      "tensor([[-13.8207],\n",
      "        [  3.3062],\n",
      "        [-13.9666],\n",
      "        ...,\n",
      "        [  7.6127],\n",
      "        [ 10.4089],\n",
      "        [-16.5220]]) tensor([[-15.1497],\n",
      "        [  2.3012],\n",
      "        [-16.0513],\n",
      "        ...,\n",
      "        [  0.7974],\n",
      "        [-18.2775],\n",
      "        [-13.8357]])\n",
      "tensor([[-14.6777],\n",
      "        [  3.3061],\n",
      "        [-14.8090],\n",
      "        ...,\n",
      "        [  5.8228],\n",
      "        [  8.6160],\n",
      "        [-12.4681]]) tensor([[-15.6440],\n",
      "        [ -4.1490],\n",
      "        [ -7.5069],\n",
      "        ...,\n",
      "        [ -2.3087],\n",
      "        [ -1.2850],\n",
      "        [-12.4256]])\n",
      "Finish model [gruRTN_day] predicting!\n",
      "tensor([[ 4.3411],\n",
      "        [-0.8404],\n",
      "        [-3.2958],\n",
      "        ...,\n",
      "        [ 3.8225],\n",
      "        [ 2.9673],\n",
      "        [-0.7505]]) tensor([[ 4.1978],\n",
      "        [-0.4058],\n",
      "        [-3.9508],\n",
      "        ...,\n",
      "        [ 4.1789],\n",
      "        [ 3.8830],\n",
      "        [-1.8663]])\n",
      "tensor([[ 3.7469],\n",
      "        [-1.4349],\n",
      "        [-4.5589],\n",
      "        ...,\n",
      "        [ 4.2272],\n",
      "        [ 3.8537],\n",
      "        [ 0.5569]]) tensor([[ 4.5967],\n",
      "        [-0.8687],\n",
      "        [-2.4433],\n",
      "        ...,\n",
      "        [ 4.2958],\n",
      "        [ 4.0195],\n",
      "        [ 1.5218]])\n",
      "tensor([[ 3.7307],\n",
      "        [ 0.5761],\n",
      "        [-2.9153],\n",
      "        ...,\n",
      "        [ 3.8394],\n",
      "        [ 4.2164],\n",
      "        [ 4.1050]]) tensor([[ 3.9393],\n",
      "        [ 0.7488],\n",
      "        [-3.0989],\n",
      "        ...,\n",
      "        [ 3.9065],\n",
      "        [ 4.4235],\n",
      "        [ 3.8330]])\n",
      "tensor([[ 3.8318],\n",
      "        [-0.8461],\n",
      "        [-1.9695],\n",
      "        ...,\n",
      "        [ 3.8502],\n",
      "        [ 3.9186],\n",
      "        [ 2.7815]]) tensor([[ 3.6329],\n",
      "        [-0.7379],\n",
      "        [-0.9364],\n",
      "        ...,\n",
      "        [ 4.1064],\n",
      "        [ 4.3303],\n",
      "        [ 2.5450]])\n",
      "tensor([[ 4.2248],\n",
      "        [-1.4629],\n",
      "        [-3.0366],\n",
      "        ...,\n",
      "        [ 4.8483],\n",
      "        [ 4.0115],\n",
      "        [-5.8598]]) tensor([[ 4.3249],\n",
      "        [-2.6681],\n",
      "        [-2.8027],\n",
      "        ...,\n",
      "        [ 5.2539],\n",
      "        [ 4.1640],\n",
      "        [-5.4784]])\n",
      "tensor([[ 4.3996],\n",
      "        [-0.4532],\n",
      "        [-4.3463],\n",
      "        ...,\n",
      "        [ 4.3421],\n",
      "        [ 2.3987],\n",
      "        [-1.6759]]) tensor([[ 4.8121],\n",
      "        [-0.8219],\n",
      "        [-1.4966],\n",
      "        ...,\n",
      "        [ 5.3170],\n",
      "        [ 2.7254],\n",
      "        [-2.6075]])\n",
      "tensor([[ 4.4152],\n",
      "        [ 0.5562],\n",
      "        [-5.8590],\n",
      "        ...,\n",
      "        [ 4.5613],\n",
      "        [ 3.9616],\n",
      "        [ 1.5436]]) tensor([[ 4.5024],\n",
      "        [ 0.5969],\n",
      "        [-6.0523],\n",
      "        ...,\n",
      "        [ 5.2708],\n",
      "        [ 4.7421],\n",
      "        [ 1.8124]])\n",
      "tensor([[ 3.8730],\n",
      "        [-3.6782],\n",
      "        [-4.5148],\n",
      "        ...,\n",
      "        [ 4.4662],\n",
      "        [ 3.4712],\n",
      "        [ 1.8872]]) tensor([[ 4.3152],\n",
      "        [-3.1470],\n",
      "        [-3.1049],\n",
      "        ...,\n",
      "        [ 4.7473],\n",
      "        [ 3.9407],\n",
      "        [ 2.3814]])\n",
      "tensor([[ 3.4501],\n",
      "        [-1.4593],\n",
      "        [-6.9152],\n",
      "        ...,\n",
      "        [ 4.6953],\n",
      "        [ 3.6284],\n",
      "        [ 2.9451]]) tensor([[ 2.5424],\n",
      "        [-2.5129],\n",
      "        [-7.3331],\n",
      "        ...,\n",
      "        [ 5.6232],\n",
      "        [ 2.7339],\n",
      "        [ 3.3225]])\n",
      "tensor([[ 3.4417],\n",
      "        [ 0.1186],\n",
      "        [-5.1872],\n",
      "        ...,\n",
      "        [ 4.0519],\n",
      "        [ 3.9368],\n",
      "        [ 2.0057]]) tensor([[ 2.8413],\n",
      "        [ 0.3550],\n",
      "        [-6.6325],\n",
      "        ...,\n",
      "        [ 3.8962],\n",
      "        [ 4.4838],\n",
      "        [ 2.5777]])\n",
      "tensor([[ 3.7083],\n",
      "        [-0.7695],\n",
      "        [-4.4535],\n",
      "        ...,\n",
      "        [ 3.6646],\n",
      "        [ 4.0755],\n",
      "        [ 1.1051]]) tensor([[ 3.6096],\n",
      "        [-0.1583],\n",
      "        [-6.0111],\n",
      "        ...,\n",
      "        [ 4.1750],\n",
      "        [ 4.3495],\n",
      "        [ 1.4561]])\n",
      "tensor([[ 4.2717],\n",
      "        [-2.0606],\n",
      "        [-4.3821],\n",
      "        ...,\n",
      "        [ 3.7810],\n",
      "        [ 3.6993],\n",
      "        [-3.2074]]) tensor([[ 3.5067],\n",
      "        [-1.6409],\n",
      "        [-5.2598],\n",
      "        ...,\n",
      "        [ 4.6537],\n",
      "        [ 4.2098],\n",
      "        [-4.0951]])\n",
      "tensor([[ 4.3954],\n",
      "        [-0.8920],\n",
      "        [-4.5084],\n",
      "        ...,\n",
      "        [ 3.6225],\n",
      "        [ 1.0947],\n",
      "        [-0.1768]]) tensor([[ 5.1349],\n",
      "        [-0.5065],\n",
      "        [-5.9381],\n",
      "        ...,\n",
      "        [ 4.2794],\n",
      "        [ 1.3979],\n",
      "        [ 0.1348]])\n",
      "tensor([[ 4.4842],\n",
      "        [ 0.4129],\n",
      "        [-3.2561],\n",
      "        ...,\n",
      "        [ 3.8651],\n",
      "        [ 3.7002],\n",
      "        [ 2.1809]]) tensor([[ 4.8000],\n",
      "        [ 0.6315],\n",
      "        [-1.4360],\n",
      "        ...,\n",
      "        [ 5.0768],\n",
      "        [ 3.6947],\n",
      "        [ 2.7181]])\n",
      "tensor([[ 3.6556],\n",
      "        [-1.1733],\n",
      "        [-2.7294],\n",
      "        ...,\n",
      "        [ 3.6375],\n",
      "        [ 3.5992],\n",
      "        [ 4.1277]]) tensor([[ 2.6436],\n",
      "        [-1.1899],\n",
      "        [-2.8656],\n",
      "        ...,\n",
      "        [ 2.9799],\n",
      "        [ 3.0413],\n",
      "        [ 3.9552]])\n",
      "tensor([[ 3.1916],\n",
      "        [-1.3533],\n",
      "        [-3.0912],\n",
      "        ...,\n",
      "        [ 3.4276],\n",
      "        [ 3.3104],\n",
      "        [ 4.1318]]) tensor([[ 3.4730],\n",
      "        [-1.4081],\n",
      "        [-3.8033],\n",
      "        ...,\n",
      "        [ 3.5595],\n",
      "        [ 3.5072],\n",
      "        [ 3.7596]])\n",
      "tensor([[ 3.3545],\n",
      "        [ 0.1209],\n",
      "        [-2.2631],\n",
      "        ...,\n",
      "        [ 3.4974],\n",
      "        [ 3.8349],\n",
      "        [ 3.6541]]) tensor([[ 3.2743],\n",
      "        [ 0.0792],\n",
      "        [-1.4062],\n",
      "        ...,\n",
      "        [ 3.1360],\n",
      "        [ 3.4285],\n",
      "        [ 3.3423]])\n",
      "tensor([[ 3.6023],\n",
      "        [-0.4583],\n",
      "        [-1.5300],\n",
      "        ...,\n",
      "        [ 2.7638],\n",
      "        [ 3.9123],\n",
      "        [ 3.8924]]) tensor([[ 4.0099],\n",
      "        [-0.8858],\n",
      "        [-2.0484],\n",
      "        ...,\n",
      "        [ 3.0261],\n",
      "        [ 2.9526],\n",
      "        [ 4.5214]])\n",
      "tensor([[ 3.8876],\n",
      "        [-0.0673],\n",
      "        [-1.9409],\n",
      "        ...,\n",
      "        [ 3.1996],\n",
      "        [ 3.6970],\n",
      "        [ 0.1109]]) tensor([[ 4.0937],\n",
      "        [ 0.2559],\n",
      "        [-1.7891],\n",
      "        ...,\n",
      "        [ 3.2524],\n",
      "        [ 4.0553],\n",
      "        [ 0.7722]])\n",
      "tensor([[ 4.2784],\n",
      "        [ 0.2935],\n",
      "        [-3.0926],\n",
      "        ...,\n",
      "        [ 2.8252],\n",
      "        [ 2.8022],\n",
      "        [-0.6637]]) tensor([[ 4.3443],\n",
      "        [-0.3852],\n",
      "        [-4.3559],\n",
      "        ...,\n",
      "        [ 3.3221],\n",
      "        [ 2.8651],\n",
      "        [-1.6408]])\n",
      "tensor([[ 4.2181],\n",
      "        [-0.3050],\n",
      "        [-4.7905],\n",
      "        ...,\n",
      "        [ 3.8725],\n",
      "        [ 3.4245],\n",
      "        [ 1.4459]]) tensor([[ 5.0077],\n",
      "        [ 0.2431],\n",
      "        [-5.5314],\n",
      "        ...,\n",
      "        [ 3.1127],\n",
      "        [ 3.2653],\n",
      "        [ 0.5592]])\n",
      "tensor([[ 3.3839],\n",
      "        [-1.4108],\n",
      "        [-5.4749],\n",
      "        ...,\n",
      "        [ 4.0158],\n",
      "        [ 3.0556],\n",
      "        [ 3.3166]]) tensor([[ 2.9855],\n",
      "        [-1.7117],\n",
      "        [-4.4898],\n",
      "        ...,\n",
      "        [ 4.0420],\n",
      "        [ 3.2796],\n",
      "        [ 2.9852]])\n",
      "tensor([[ 3.2074],\n",
      "        [-1.7656],\n",
      "        [-5.8383],\n",
      "        ...,\n",
      "        [ 3.9641],\n",
      "        [ 3.2194],\n",
      "        [ 3.9032]]) tensor([[ 3.6005],\n",
      "        [-2.7537],\n",
      "        [-5.7724],\n",
      "        ...,\n",
      "        [ 3.4808],\n",
      "        [ 3.5245],\n",
      "        [ 4.0327]])\n",
      "tensor([[ 3.3416],\n",
      "        [-1.2080],\n",
      "        [-5.6934],\n",
      "        ...,\n",
      "        [ 3.9101],\n",
      "        [ 3.6444],\n",
      "        [ 2.1960]]) tensor([[ 3.7029],\n",
      "        [-2.7274],\n",
      "        [-7.5214],\n",
      "        ...,\n",
      "        [ 2.9466],\n",
      "        [ 3.8930],\n",
      "        [ 2.6414]])\n",
      "tensor([[ 3.4965],\n",
      "        [-1.7279],\n",
      "        [-1.0442],\n",
      "        ...,\n",
      "        [ 3.7450],\n",
      "        [ 3.6357],\n",
      "        [ 2.1655]]) tensor([[ 3.0596],\n",
      "        [-1.9193],\n",
      "        [-1.1921],\n",
      "        ...,\n",
      "        [ 3.8788],\n",
      "        [ 3.7379],\n",
      "        [ 2.2233]])\n",
      "tensor([[ 3.7899],\n",
      "        [-1.0768],\n",
      "        [-2.7186],\n",
      "        ...,\n",
      "        [ 3.8101],\n",
      "        [ 3.1646],\n",
      "        [-1.1145]]) tensor([[ 4.0341],\n",
      "        [-1.3794],\n",
      "        [-2.3891],\n",
      "        ...,\n",
      "        [ 3.8104],\n",
      "        [ 3.1007],\n",
      "        [-0.3780]])\n",
      "tensor([[ 4.4431],\n",
      "        [-1.0995],\n",
      "        [-4.4847],\n",
      "        ...,\n",
      "        [ 3.8598],\n",
      "        [ 2.2008],\n",
      "        [-0.9153]]) tensor([[ 4.2788],\n",
      "        [-1.1001],\n",
      "        [-5.7313],\n",
      "        ...,\n",
      "        [ 4.3311],\n",
      "        [ 3.2996],\n",
      "        [-2.7552]])\n",
      "tensor([[ 4.2755],\n",
      "        [-0.7039],\n",
      "        [-1.2483],\n",
      "        ...,\n",
      "        [ 3.9234],\n",
      "        [ 3.2017],\n",
      "        [ 1.5138]]) tensor([[ 4.5377],\n",
      "        [ 0.0385],\n",
      "        [-0.5789],\n",
      "        ...,\n",
      "        [ 2.4290],\n",
      "        [ 3.0828],\n",
      "        [ 1.7589]])\n",
      "tensor([[ 3.6540],\n",
      "        [-1.1673],\n",
      "        [-2.9207],\n",
      "        ...,\n",
      "        [ 4.2690],\n",
      "        [ 3.0920],\n",
      "        [ 2.9536]]) tensor([[ 3.5501],\n",
      "        [-1.4887],\n",
      "        [-2.0324],\n",
      "        ...,\n",
      "        [ 3.4903],\n",
      "        [ 3.2339],\n",
      "        [ 2.6800]])\n",
      "tensor([[ 3.3908],\n",
      "        [-1.3008],\n",
      "        [-3.1128],\n",
      "        ...,\n",
      "        [ 4.2343],\n",
      "        [ 3.0613],\n",
      "        [ 3.9672]]) tensor([[ 3.2001],\n",
      "        [-2.3660],\n",
      "        [-2.9905],\n",
      "        ...,\n",
      "        [ 3.9437],\n",
      "        [ 2.7253],\n",
      "        [ 3.9445]])\n",
      "tensor([[ 3.2432],\n",
      "        [-0.0338],\n",
      "        [-2.7985],\n",
      "        ...,\n",
      "        [ 4.2409],\n",
      "        [ 3.5778],\n",
      "        [ 2.9172]]) tensor([[ 2.6464],\n",
      "        [ 0.1932],\n",
      "        [-2.0207],\n",
      "        ...,\n",
      "        [ 3.3741],\n",
      "        [ 3.3848],\n",
      "        [ 2.6052]])\n",
      "tensor([[ 3.2752],\n",
      "        [-0.2462],\n",
      "        [-0.3827],\n",
      "        ...,\n",
      "        [ 4.1574],\n",
      "        [ 3.8848],\n",
      "        [ 2.9823]]) tensor([[ 2.6423],\n",
      "        [-0.6951],\n",
      "        [-1.6381],\n",
      "        ...,\n",
      "        [ 3.5188],\n",
      "        [ 3.7741],\n",
      "        [ 2.0708]])\n",
      "tensor([[ 3.8420],\n",
      "        [-0.0068],\n",
      "        [-2.1464],\n",
      "        ...,\n",
      "        [ 3.9982],\n",
      "        [ 3.6718],\n",
      "        [-2.3091]]) tensor([[ 3.7159],\n",
      "        [-0.8956],\n",
      "        [-3.2414],\n",
      "        ...,\n",
      "        [ 3.3050],\n",
      "        [ 3.6978],\n",
      "        [-4.0582]])\n",
      "tensor([[ 4.0586],\n",
      "        [ 0.1390],\n",
      "        [-4.4118],\n",
      "        ...,\n",
      "        [ 4.1205],\n",
      "        [ 3.2818],\n",
      "        [-1.9572]]) tensor([[ 3.8761],\n",
      "        [-1.4052],\n",
      "        [-5.7182],\n",
      "        ...,\n",
      "        [ 4.0706],\n",
      "        [ 3.1424],\n",
      "        [-1.2512]])\n",
      "tensor([[ 4.0016],\n",
      "        [ 0.0355],\n",
      "        [-4.8059],\n",
      "        ...,\n",
      "        [ 4.0663],\n",
      "        [ 3.8584],\n",
      "        [ 0.8177]]) tensor([[ 3.8445],\n",
      "        [-1.1444],\n",
      "        [-4.2763],\n",
      "        ...,\n",
      "        [ 3.7740],\n",
      "        [ 3.1569],\n",
      "        [ 0.3338]])\n",
      "Finish model [gru_avg] predicting!\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.api import DataAPI , Predictor\n",
    "# DataAPI.prepare_predict_data()\n",
    "md = Predictor.update_factors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'net_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet_0\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'net_0'"
     ]
    }
   ],
   "source": [
    "app.net_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from \n",
    "\n",
    "pred0 = BatchOutput(net(batch_data.x)).pred\n",
    "pred1 = net2(batch_data.x)\n",
    "\n",
    "app.net_0 = net\n",
    "app.net_1 = net2\n",
    "\n",
    "self.net_x = batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load  2 DataBlocks ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... cost 0.22 secs\n",
      "Align 2 DataBlocks ...... cost 0.21 secs\n",
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n",
      "x shape is torch.Size([5064, 30, 6])\n",
      "y shape is torch.Size([5064, 1])\n",
      "Test Forward Success\n",
      "metrics :  Metrics.MetricOutput(loss=tensor(1.0688, grad_fn=<AddBackward0>), score=-0.015420470386743546, loss_item=1.068833589553833, penalty=0.0, losses=tensor(1.0688, grad_fn=<ExpBackward0>))\n",
      "Test Metrics Success\n"
     ]
    }
   ],
   "source": [
    "from src.api import ModelTestor\n",
    "ModelTestor.new('ts_mixer').try_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
