{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update Files\n",
      "Thu Jun 13 23:51:14 2024 : Updated ~ data\\DataBase\\DB_information\\calendar.feather Done! Cost 0.04 Secs\n",
      "Thu Jun 13 23:51:14 2024 : Updated ~ data\\DataBase\\DB_information\\description.feather Done! Cost 0.04 Secs\n",
      "Thu Jun 13 23:51:14 2024 : Updated ~ data\\DataBase\\DB_information\\st.feather Done! Cost 0.01 Secs\n",
      "Thu Jun 13 23:51:17 2024 : Updated ~ data\\DataBase\\DB_information\\industry.feather Done! Cost 2.49 Secs\n",
      "Thu Jun 13 23:51:21 2024 : Updated ~ data\\DataBase\\DB_information\\concepts.feather Done! Cost 4.33 Secs\n",
      "Thu Jun 13 23:51:34 2024 : download since!\n",
      "Connection and Factor preparation finished!\n",
      "Thu Jun 13 23:51:34 2024 : sellside/haitong.hf_factors from 20240614 to 20240613, total 1 periods\n",
      "Start sellside/haitong.hf_factors:20240614-20240613 \n",
      "Done sellside/haitong.hf_factors:20240614-20240613, cost 1.4 Secs\n",
      "Thu Jun 13 23:51:35 2024 : sellside/haitong.dl_factors from 20240613 to 20240613, total 1 periods\n",
      "Start sellside/haitong.dl_factors:20240613-20240613 \n",
      "Done sellside/haitong.dl_factors:20240613-20240613, cost 144.3 Secs\n",
      "Thu Jun 13 23:54:00 2024 : sellside/dongfang.hfq_chars from 20240614 to 20240613, total 1 periods\n",
      "Start sellside/dongfang.hfq_chars:20240614-20240613 \n",
      "Done sellside/dongfang.hfq_chars:20240614-20240613, cost 1.0 Secs\n",
      "Thu Jun 13 23:54:01 2024 : sellside/dongfang.l2_chars from 20240614 to 20240613, total 1 periods\n",
      "Start sellside/dongfang.l2_chars:20240614-20240613 \n",
      "Done sellside/dongfang.l2_chars:20240614-20240613, cost 12.1 Secs\n",
      "Thu Jun 13 23:54:13 2024 : sellside/dongfang.ms_chars from 20240614 to 20240613, total 1 periods\n",
      "Start sellside/dongfang.ms_chars:20240614-20240613 \n",
      "Done sellside/dongfang.ms_chars:20240614-20240613, cost 19.9 Secs\n",
      "Thu Jun 13 23:54:33 2024 : sellside/dongfang.order_flow from 20240614 to 20240613, total 1 periods\n",
      "Start sellside/dongfang.order_flow:20240614-20240613 \n",
      "Done sellside/dongfang.order_flow:20240614-20240613, cost 0.1 Secs\n",
      "Thu Jun 13 23:54:33 2024 : sellside/dongfang.gp from 20240613 to 20240613, total 1 periods\n",
      "Start sellside/dongfang.gp:20240613-20240613 \n",
      "Done sellside/dongfang.gp:20240613-20240613, cost 0.1 Secs\n",
      "Thu Jun 13 23:54:33 2024 : sellside/dongfang.tra from 20240613 to 20240613, total 1 periods\n",
      "Start sellside/dongfang.tra:20240613-20240613 \n",
      "Done sellside/dongfang.tra:20240613-20240613, cost 0.2 Secs\n",
      "Thu Jun 13 23:54:33 2024 : sellside/dongfang.hist from 20240613 to 20240613, total 1 periods\n",
      "Start sellside/dongfang.hist:20240613-20240613 \n",
      "Done sellside/dongfang.hist:20240613-20240613, cost 0.1 Secs\n",
      "Thu Jun 13 23:54:33 2024 : sellside/dongfang.scores_v0 from 20240614 to 20240613, total 1 periods\n",
      "Start sellside/dongfang.scores_v0:20240614-20240613 \n",
      "Done sellside/dongfang.scores_v0:20240614-20240613, cost 1.4 Secs\n",
      "Thu Jun 13 23:54:35 2024 : sellside/dongfang.factorvae from 20240613 to 20240613, total 1 periods\n",
      "Start sellside/dongfang.factorvae:20240613-20240613 \n",
      "Done sellside/dongfang.factorvae:20240613-20240613, cost 0.1 Secs\n",
      "Thu Jun 13 23:54:35 2024 : sellside/huatai.dl_factors from 20240613 to 20240613, total 1 periods\n",
      "Start sellside/huatai.dl_factors:20240613-20240613 \n",
      "Done sellside/huatai.dl_factors:20240613-20240613, cost 1.4 Secs\n",
      "Thu Jun 13 23:54:36 2024 : All Updates Done! Cost 202.48 Secs\n",
      "--------------------------------------------------------------------------------\n",
      "predict is True , Data Processing start!\n",
      "4 datas :['y', 'day', '30m', 'risk']\n",
      "y blocks loading start!\n",
      "y blocks loading finished! Cost 0.00 secs\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "['ret10_lag', 'ret20_lag'] not in d:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_labels",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m API\n\u001b[0;32m      3\u001b[0m API\u001b[38;5;241m.\u001b[39mDataAPI\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m----> 4\u001b[0m \u001b[43mAPI\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataAPI\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_train_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m API\u001b[38;5;241m.\u001b[39mPredictor\u001b[38;5;241m.\u001b[39mupdate_factors()\n",
      "File \u001b[1;32md:\\Coding\\learndl\\learndl\\src\\API\\data.py:37\u001b[0m, in \u001b[0;36mDataAPI.prepare_train_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_train_data\u001b[39m(): \n\u001b[0;32m     34\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m    prepare latest(1 year or so) train data for predict use, do it after 'update'\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     \u001b[43mDataProcessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m)\n",
      "File \u001b[1;32md:\\Coding\\learndl\\learndl\\src\\data\\process.py:60\u001b[0m, in \u001b[0;36mDataProcessor.main\u001b[1;34m(cls, predict, confirm, parser, data_key)\u001b[0m\n\u001b[0;32m     58\u001b[0m tt1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Timer(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m blocks loading\u001b[39m\u001b[38;5;124m'\u001b[39m , newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 60\u001b[0m     block_dict \u001b[38;5;241m=\u001b[39m \u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_start_dt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_end_dt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Timer(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m blocks process\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     62\u001b[0m     data_block \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mprocess_blocks(block_dict)\n",
      "File \u001b[1;32md:\\Coding\\learndl\\learndl\\src\\data\\process.py:99\u001b[0m, in \u001b[0;36m_TypeProcessor.load_blocks\u001b[1;34m(self, start_dt, end_dt, secid_align, date_align, **kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_blocks\u001b[39m(\u001b[38;5;28mself\u001b[39m , start_dt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m , end_dt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m , secid_align \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m , date_align \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m , \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     98\u001b[0m     blocks : \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m,DataBlock] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m src_key , loader \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock_loaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    100\u001b[0m         blocks[src_key] \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload_block(start_dt , end_dt , \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39malign(secid \u001b[38;5;241m=\u001b[39m secid_align , date \u001b[38;5;241m=\u001b[39m date_align)\n\u001b[0;32m    101\u001b[0m         secid_align \u001b[38;5;241m=\u001b[39m blocks[src_key]\u001b[38;5;241m.\u001b[39msecid\n",
      "File \u001b[1;32md:\\Coding\\learndl\\learndl\\src\\data\\process.py:117\u001b[0m, in \u001b[0;36mprocY.block_loaders\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mblock_loaders\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[43mBlockLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mret10_lag\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mret20_lag\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m ,\n\u001b[0;32m    118\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrisk\u001b[39m\u001b[38;5;124m'\u001b[39m : BlockLoader(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrisk_exp\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mINDUS_FEAT, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m])}\n",
      "File \u001b[1;32m<string>:6\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, db_src, db_key, feature)\u001b[0m\n",
      "File \u001b[1;32md:\\Coding\\learndl\\learndl\\src\\data\\core.py:85\u001b[0m, in \u001b[0;36mBlockLoader.__post_init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDB_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb_src\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(PATH\u001b[38;5;241m.\u001b[39mdatabase) , \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDB_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb_src\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPATH\u001b[38;5;241m.\u001b[39mdatabase\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     84\u001b[0m src_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(PATH\u001b[38;5;241m.\u001b[39mdatabase , \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDB_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb_src\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 85\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb_key \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(src_path) , \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: ['ret10_lag', 'ret20_lag'] not in d:\\Coding\\learndl\\learndl\\data\\DataBase\\DB_labels"
     ]
    }
   ],
   "source": [
    "from src import API\n",
    "\n",
    "API.DataAPI.update()\n",
    "API.DataAPI.prepare_train_data()\n",
    "API.Predictor.update_factors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load  2 DataBlocks...... finished! Cost 0.11 secs\n",
      "Align 2 DataBlocks...... finished! Cost 0.17 secs\n",
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n",
      "20231201 new\n",
      "Load  2 DataBlocks...... finished! Cost 0.03 secs\n",
      "Align 2 DataBlocks...... finished! Cost 0.15 secs\n",
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n",
      "20231201 new\n",
      "Load  2 DataBlocks...... finished! Cost 0.03 secs\n",
      "Align 2 DataBlocks...... finished! Cost 0.17 secs\n",
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n",
      "20231201 new\n"
     ]
    }
   ],
   "source": [
    "from src import API\n",
    "API.Predictor.update_factors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load  2 DataBlocks ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... cost 0.22 secs\n",
      "Align 2 DataBlocks ...... cost 0.21 secs\n",
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n",
      "x shape is torch.Size([5064, 30, 6])\n",
      "y shape is torch.Size([5064, 1])\n",
      "Test Forward Success\n",
      "metrics :  Metrics.MetricOutput(loss=tensor(1.0688, grad_fn=<AddBackward0>), score=-0.015420470386743546, loss_item=1.068833589553833, penalty=0.0, losses=tensor(1.0688, grad_fn=<ExpBackward0>))\n",
      "Test Metrics Success\n"
     ]
    }
   ],
   "source": [
    "from src import API\n",
    "API.ModelTestor.new('ts_mixer').try_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
