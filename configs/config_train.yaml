# most frequently changing variables
short_test:  False
tra_switch: true
buffer_type: tra
buffer_param: 
  tra_num_states: &tra_num_states 5

model_module: resnet_lstm # tra_lstm2 # 'LSTM' # 'TRA_LSTM' # 'GeneralRNN' 
model_nickname: null # 'LSTM' # 'TCN_vs_LSTM' any str or None
model_num: 3
model_datatype:
  rnn_general: day
  gru: day
  lstm: day
  tcn: day
  transformer: day
  tra_lstm: day
  resnet_lstm: 15m
  resnet_gru: 15m
  other: [day , 15m , 30m , gp , 'day+15m']
labels: 
  - rtn_lag1_10
  - res_lag1_10
MODEL_PARAM:
  hidden_dim:     [32] #  2**5
  seqlens:        [{'day': 40 , '30m': 30 , '15m': 20 , 'dms': 40}] # although not a param for model, but can be different values(dict of SEQLEN) #
  tra_seqlens:    [{'hist_loss': 40}]
  dropout:        [0.1]
  enc_in:         [true]
  enc_att:        [false] 
  rnn_type:       ['lstm'] # 'gru' , 'lstm' , 'transformer' , 'tcn'
  rnn_att:        [false]
  rnn_layers:     [2]
  dec_mlp_layers: [1] 
  num_output:     [1]
  kernel_size:    [3 , 3] # for tcn
  hidden_as_factor:    [false]
  ordered_param_group: [false]  # multiple data input , if train sequentially
  tra_num_states: [*tra_num_states]
  resnet_blocks:  [2,3,4]
COMPT_PARAM: 
  cuda_first: true
  num_worker: 10
TRAIN_PARAM:
  dataloader:
    random_seed:     null
    random_split:    true
    sample_method:   train_shuffle # total_shuffle , sequential , both_shuffle , train_shuffle
    train_ratio:     0.8
  trainer:
    optimizer: {'name' : 'Adam' , 'param' : {} ,}  #{'name' : 'SGD' , 'param' : {} ,}
    scheduler: {'name' : 'cycle' , 'param' : {'base_lr': 1.0e-7 , 'step_size_up': 4} ,}  #{'name' : 'SGD' , 'param' : {} ,}
    learn_rate:
      base:    0.005
      ratio:   {'attempt':[1 , 0.1 , 10 , 0.01 , 100] , 'round' : [1.] , 'transfer' : 0.1 , } 
      reset:   {'num_reset' : 2 , 'trigger' : 40 , 'recover_level' : 1. , 'speedup2x' : true , }
    nanloss:   {'retry' : 5}
    gradient:  {'clip_value' : 10.0}
    retrain:   {'attempts' : 4 , 'min_epoch' : 20 , 'min_epoch_round' : 10} 
  criterion:
    loss:      pearson # mse , pearson , ccc
    score:     #mse,pearson,ccc,spearman
      train:   pearson
      valid:   pearson
      test:    pearson
    penalty:   
      hidden_orthogonality : 
        lamb : 0.001
      tra_ot_penalty : 
        lamb : &tra_ot_penalty 0.01
        rho : 0.999
    weight:
      train:    'equal' # 'top'
      test:     'equal' # 'top'
  transfer:    false
  output_types: [best , swalast , swabest]
  multitask:
    type: hybrid
    param_dict:
      dwa: {'tau' : 2}
      ruw: {'phi' : null}
      ewa: {}
      gls: {}
      rws: {}
      hybrid: {'phi' : null , 'tau' : 2}
  terminate:
    overall:
      early_stop: 20
      max_epoch: 200
      valid_converge: {'min_epoch' : 5 , 'eps' : 1.0e-5} 
      #'train_converge' : {'min_epoch' : 5 , 'eps' : 1.0e-5} 
      #'tv_converge'    : {'min_epoch' : 5 , 'eps' : 1.0e-5}
    round:
      early_stop: 10
      max_epoch: 100
      valid_converge: {'min_epoch' : 5 , 'eps' : 1.0e-5} 
special_config:
  short_test:
    beg_date:   20170103
    end_date:   20171201
    input_span: 480
    max_epoch:  20
    verbosity:  3
    model_nickname: ShortTest
  transformer:
    trainer:
      gradient:  {'clip_value' : 10.}
      learn_rate:
        base:    0.005
        ratio:   {'attempt':[1 , 0.1 , 10 , 0.01 , 100] , 'round' : [1.] , 'transfer' : 0.1 , } 
        reset:   {'num_reset' : 1 , 'trigger' : 60 , 'recover_level' : 1. , 'speedup2x' : true , }
      scheduler: {'name' : 'cycle' , 'param' : {'base_lr':1.0e-7,'step_size_up':4} ,}

storage_type: mem # disk
output_prediction: False
precision:  float # double , bfloat16

beg_date:   20170103
end_date:   99991231
input_span: 2400
interval:   120
max_epoch:  100
verbosity:  2
batch_size: 10000
test_step_day:  1
input_step_day: 5
skip_horizon: &skip_horizon 20 

tra_param:
  tra_num_states : *tra_num_states
  tra_horizon : *skip_horizon
  
# torch utility
allow_tf32: true
detect_anomaly: false