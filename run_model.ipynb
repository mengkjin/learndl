{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[44m24-02-08 06:55:39|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[34mModel Specifics:\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-02-08 06:55:39|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[31mStart Process [Load Data]!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Process Queue : Data + Instance\n",
      "--Confirm Resume Training!\n",
      "--Model_name is set to TRA_LSTM_day!\n",
      "{'verbosity': 2,\n",
      " 'storage_type': 'mem',\n",
      " 'device': device(type='cuda', index=0),\n",
      " 'precision': 'float',\n",
      " 'batch_size': 10000,\n",
      " 'model_name': 'TRA_LSTM_day',\n",
      " 'model_module': 'TRA_LSTM',\n",
      " 'model_data_type': 'day',\n",
      " 'model_num': 1,\n",
      " 'beg_date': 20170103,\n",
      " 'end_date': 99991231,\n",
      " 'interval': 120,\n",
      " 'input_step_day': 5,\n",
      " 'test_step_day': 1,\n",
      " 'MODEL_PARAM': {'hidden_dim': [64],\n",
      "                 'seqlens': [{'day': 40, '15m': 20, 'dms': 40}],\n",
      "                 'tra_seqlens': [{'hist_loss': 40}],\n",
      "                 'rnn_layers': [2],\n",
      "                 'mlp_layers': [1],\n",
      "                 'dropout': [0.1],\n",
      "                 'fc_in': [True],\n",
      "                 'fc_att': [False],\n",
      "                 'type_rnn': ['lstm'],\n",
      "                 'rnn_att': [False],\n",
      "                 'num_output': [1],\n",
      "                 'kernel_size': [3, 3],\n",
      "                 'hidden_as_factor': [False],\n",
      "                 'ordered_param_group': [False],\n",
      "                 'tra_num_states': [3]},\n",
      " 'train_params': {'dataloader': {'random_seed': None, 'random_tv_split': True, 'sample_method': 'train_shuffle', 'train_ratio': 0.8},\n",
      "                  'trainer': {'optimizer': {'name': 'Adam', 'param': {}},\n",
      "                              'scheduler': {'name': 'cycle', 'param': {'base_lr': 1e-07, 'step_size_up': 4}},\n",
      "                              'learn_rate': {'base': 0.005,\n",
      "                                             'ratio': {'attempt': [1, 0.1, 10, 0.01, 100], 'round': [1.0], 'transfer': 0.1},\n",
      "                                             'reset': {'num_reset': 2, 'trigger': 40, 'recover_level': 1.0, 'speedup2x': True}},\n",
      "                              'nanloss': {'retry': 5},\n",
      "                              'gradient': {'clip_value': 10.0},\n",
      "                              'retrain': {'attempts': 4, 'min_epoch': 20, 'min_epoch_round': 10}},\n",
      "                  'criterion': {'loss': 'pearson',\n",
      "                                'score': {'train': 'pearson', 'valid': 'pearson', 'test': 'pearson'},\n",
      "                                'penalty': {'hidden_orthogonality': {'lamb': 0.001}, 'tra_ot_penalty': {'lamb': 0.01, 'rho': 0.999}},\n",
      "                                'weight': {'train': 'equal', 'test': 'equal'}},\n",
      "                  'transfer': False,\n",
      "                  'output_types': ['best', 'swalast', 'swabest'],\n",
      "                  'multitask': {'type': 'hybrid',\n",
      "                                'param_dict': {'dwa': {'tau': 2},\n",
      "                                               'ruw': {'phi': None},\n",
      "                                               'ewa': {},\n",
      "                                               'gls': {},\n",
      "                                               'rws': {},\n",
      "                                               'hybrid': {'phi': None, 'tau': 2}}},\n",
      "                  'terminate': {'overall': {'early_stop': 20, 'max_epoch': 200, 'valid_converge': {'min_epoch': 5, 'eps': 1e-05}},\n",
      "                                'round': {'early_stop': 10, 'max_epoch': 100, 'valid_converge': {'min_epoch': 5, 'eps': 1e-05}}}},\n",
      " 'compt_params': {'cuda_first': True, 'num_worker': 10}}\n",
      "use /home/mengkjin/Workspace/learndl/scripts/util/../../data/torch_pack/day+rtn11+res11.20231220.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-02-08 06:55:43|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Load Data]! Cost 3.2Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-02-08 06:55:43|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[31mStart Process [Copy to Instance]!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-02-08 06:55:43|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[34mCopy from model to instance finished , Start going forward\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Norming method of [day] : [endpoint_division(True) , history_standardize(True)]\n",
      "score function of [pearson] calculated and success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m20170103     0.1458  0.1442  0.1438\u001b[0m\n",
      "\u001b[32m20170704     0.1285  0.1275  0.1259\u001b[0m\n",
      "\u001b[32m20171226     0.1450  0.1483  0.1458\u001b[0m\n",
      "\u001b[32m20180627     0.1281  0.1280  0.1259\u001b[0m\n",
      "\u001b[32m20181220     0.0968  0.0947  0.0962\u001b[0m\n",
      "\u001b[32m20190624     0.0945  0.0961 -0.0072\u001b[0m\n",
      "\u001b[32m20191217     0.0889  0.0884  0.0874\u001b[0m\n",
      "\u001b[32m20200617     0.0747  0.0755  0.0754\u001b[0m\n",
      "\u001b[32m20201214     0.0979  0.0989  0.0980\u001b[0m\n",
      "\u001b[32m20210615     0.0462  0.0471  0.0477\u001b[0m\n",
      "\u001b[32m20211209     0.0965  0.0943  0.0963\u001b[0m\n",
      "\u001b[32m20220613     0.0803  0.0825  0.0199\u001b[0m\n",
      "\u001b[32m20221206     0.0569  0.0598  0.0591\u001b[0m\n",
      "\u001b[32m20230606     0.0640  0.0675  0.0693\u001b[0m\n",
      "\u001b[32m20231201     0.0949  0.0932  0.0935\u001b[0m\n",
      "\u001b[32mAllTimeAvg   0.0960  0.0966  0.0847\u001b[0m\n",
      "\u001b[32mAllTimeSum   163.55  164.59  144.28\u001b[0m\n",
      "\u001b[32mStd          0.0772  0.0757  0.0816\u001b[0m\n",
      "\u001b[32mTValue        51.33   52.67   42.83\u001b[0m\n",
      "\u001b[32mAnnIR        6.0915  6.2503  5.0828\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-02-08 06:59:16|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Copy to Instance]! Cost 213.0 Secs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%run run_model.py --process=3 --rawname=1 --resume=1 --anchoring=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use d:\\Coding\\learndl\\learndl\\scripts\\util/../../data/torch_pack/day+rtn11+res11.20231222.pt\n",
      "Pre-Norming method of [day] : [endpoint_division(True) , history_standardize(True)]\n"
     ]
    }
   ],
   "source": [
    "from run_model import RunModel\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "config , net , batch_data , model_data , metrics , multiloss = RunModel.new_random_input('simple_lstm' , 'day')\n",
    "optimizer = RunModel.new_optimizer(net)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = deepcopy(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.9836, grad_fn=<ExpBackward0>), 'loss_item': 0.983590841293335, 'score': 0.016545256599783897, 'penalty': 0.0, 'losses': None}\n",
      "tensor([[ 0.0346, -0.0963, -0.0509,  0.0964,  0.0248, -0.0379, -0.1012,  0.0861,\n",
      "          0.0339, -0.0355,  0.0143, -0.0078, -0.0076, -0.0438,  0.1430, -0.0164,\n",
      "          0.0045, -0.0180,  0.0081, -0.0945, -0.0632,  0.0245, -0.0833, -0.1091,\n",
      "          0.0300, -0.0056,  0.0512, -0.0070, -0.0515,  0.0182, -0.0090,  0.0971,\n",
      "         -0.0975, -0.0578, -0.0407, -0.0361, -0.0425,  0.0118, -0.0330,  0.0438,\n",
      "         -0.0207, -0.1619,  0.0648, -0.0720,  0.0446, -0.0255,  0.0405, -0.0399,\n",
      "         -0.0412, -0.0356,  0.0476,  0.0033, -0.0390,  0.0607,  0.0745,  0.0257,\n",
      "          0.0352,  0.0615, -0.1354, -0.0018, -0.0071, -0.1329, -0.0302, -0.0660]])\n"
     ]
    }
   ],
   "source": [
    "#pipeline 1\n",
    "\n",
    "sd = deepcopy(net.state_dict())\n",
    "optimizer = RunModel.new_optimizer(net)\n",
    "optimizer.zero_grad()\n",
    "if hasattr(net , 'dynamic_data_assign'): net.dynamic_data_assign(batch_data , model_data)\n",
    "pred , hidden = net(batch_data['x'])\n",
    "penalty_kwargs = {'net' : net , 'hidden' : hidden , 'label' : batch_data['y']}\n",
    "metric = RunModel.calculate_metrics('train' , metrics, label=batch_data['y'], pred=pred,\n",
    "                            weight=batch_data['w'], multiloss=multiloss,net=net,valid_sample=None,\n",
    "                            penalty_kwargs=penalty_kwargs)\n",
    "print(metric)\n",
    "(metric['loss'] + metric['penalty']).backward()\n",
    "print(net.get_parameter('fc.weight').grad)\n",
    "clip_value = config.train_params['trainer']['gradient'].get('clip_value')\n",
    "if clip_value is not None : nn.utils.clip_grad_value_(net.parameters(), clip_value = clip_value)\n",
    "optimizer.step()\n",
    "sd_step = deepcopy(net.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.9836, grad_fn=<ExpBackward0>), 'loss_item': 0.983590841293335, 'score': 0.016545256599783897, 'penalty': 0.0, 'losses': None}\n",
      "tensor([[ 0.0346, -0.0963, -0.0509,  0.0964,  0.0248, -0.0379, -0.1012,  0.0861,\n",
      "          0.0339, -0.0355,  0.0143, -0.0078, -0.0076, -0.0438,  0.1430, -0.0164,\n",
      "          0.0045, -0.0180,  0.0081, -0.0945, -0.0632,  0.0245, -0.0833, -0.1091,\n",
      "          0.0300, -0.0056,  0.0512, -0.0070, -0.0515,  0.0182, -0.0090,  0.0971,\n",
      "         -0.0975, -0.0578, -0.0407, -0.0361, -0.0425,  0.0118, -0.0330,  0.0438,\n",
      "         -0.0207, -0.1619,  0.0648, -0.0720,  0.0446, -0.0255,  0.0405, -0.0399,\n",
      "         -0.0412, -0.0356,  0.0476,  0.0033, -0.0390,  0.0607,  0.0745,  0.0257,\n",
      "          0.0352,  0.0615, -0.1354, -0.0018, -0.0071, -0.1329, -0.0302, -0.0660]])\n"
     ]
    }
   ],
   "source": [
    "#pipeline 2\n",
    "sd2 = deepcopy(net2.state_dict())\n",
    "optimizer2 = RunModel.new_optimizer(net2)\n",
    "if hasattr(net2 , 'dynamic_data_assign'): net2.dynamic_data_assign(batch_data , model_data)\n",
    "pred , hidden = net2(batch_data['x'])\n",
    "penalty_kwargs = {'net' : net2 , 'hidden' : hidden , 'label' : batch_data['y']}\n",
    "metric = RunModel.calculate_metrics('train' , metrics, label=batch_data['y'], pred=pred,\n",
    "                            weight=batch_data['w'], multiloss=multiloss,net=net2,valid_sample=None,\n",
    "                            penalty_kwargs=penalty_kwargs)\n",
    "optimizer2.zero_grad()\n",
    "print(metric)\n",
    "(metric['loss'] + metric['penalty']).backward()\n",
    "print(net2.get_parameter('fc.weight').grad)\n",
    "clip_value = config.train_params['trainer']['gradient'].get('clip_value')\n",
    "if clip_value is not None : nn.utils.clip_grad_value_(net2.parameters(), clip_value = clip_value)\n",
    "optimizer2.step()\n",
    "sd2_step = deepcopy(net2.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm.weight_ih_l0 lstm.weight_ih_l0 tensor(True)\n",
      "lstm.weight_hh_l0 lstm.weight_hh_l0 tensor(True)\n",
      "lstm.bias_ih_l0 lstm.bias_ih_l0 tensor(True)\n",
      "lstm.bias_hh_l0 lstm.bias_hh_l0 tensor(True)\n",
      "fc.weight fc.weight tensor(True)\n",
      "fc.bias fc.bias tensor(True)\n"
     ]
    }
   ],
   "source": [
    "for (k,v),(k2,v2) in zip(sd_step.items(),sd2_step.items()):\n",
    "    print(k , k2 , (v == v2).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "class Test():\n",
    "    @staticmethod\n",
    "    def aa(x):\n",
    "        print(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def bb(x):\n",
    "        print(x)\n",
    "\n",
    "    def trytry(self , y = 1):\n",
    "        Test.aa(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "a = Test()\n",
    "a.trytry(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is static method 1\n",
      "This is static method 2\n",
      "0\n",
      "This is static method 2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "class MyClass:\n",
    "    def static_method1(self):\n",
    "        print(\"This is static method 1\")\n",
    "        self.static_method2()\n",
    "\n",
    "    @classmethod\n",
    "    def static_method2(cls , x : int = 0) -> None:\n",
    "        print(f\"This is static method 2\")\n",
    "        print(x)\n",
    "        return None\n",
    "\n",
    "# 调用静态方法1\n",
    "a = MyClass()\n",
    "a.static_method1()\n",
    "MyClass.static_method2(x=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "pool = np.arange(100)\n",
    "random.shuffle(pool) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lambda x=0:1)(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('lstm.weight_ih_l0',\n",
       "              tensor([[ 0.0910,  0.0800,  0.0628,  0.0726, -0.1145, -0.1069],\n",
       "                      [ 0.0649, -0.1171, -0.1229,  0.0789, -0.0136, -0.1013],\n",
       "                      [-0.0654,  0.0215, -0.0326, -0.0674, -0.0718, -0.0181],\n",
       "                      ...,\n",
       "                      [-0.0225, -0.0093, -0.0572,  0.1153,  0.0017,  0.0702],\n",
       "                      [ 0.1080,  0.1080,  0.1071,  0.0696, -0.0466,  0.0816],\n",
       "                      [ 0.0576, -0.0698,  0.0820,  0.1018, -0.0175,  0.0566]])),\n",
       "             ('lstm.weight_hh_l0',\n",
       "              tensor([[-0.0280, -0.0936,  0.0853,  ..., -0.0813, -0.1271, -0.1084],\n",
       "                      [-0.0192, -0.0755,  0.0637,  ...,  0.0753,  0.0598,  0.0185],\n",
       "                      [ 0.0307,  0.0137,  0.0812,  ..., -0.0837, -0.0918, -0.0508],\n",
       "                      ...,\n",
       "                      [-0.0289,  0.0206, -0.0827,  ...,  0.1069,  0.0243, -0.1109],\n",
       "                      [-0.0859,  0.0232, -0.0917,  ..., -0.0174, -0.0597,  0.0848],\n",
       "                      [ 0.0366,  0.0733, -0.0168,  ..., -0.0157,  0.0892, -0.0741]])),\n",
       "             ('lstm.bias_ih_l0',\n",
       "              tensor([ 0.0191, -0.0746, -0.0396, -0.0141,  0.0038, -0.0083,  0.1003,  0.0409,\n",
       "                       0.1198, -0.0119, -0.0639,  0.0693, -0.0330, -0.0458,  0.0855, -0.0679,\n",
       "                      -0.0744,  0.0140, -0.0287, -0.0987,  0.0438, -0.0394, -0.0564, -0.0499,\n",
       "                      -0.0671,  0.0057, -0.0117,  0.0957, -0.0763, -0.0820, -0.0899, -0.0484,\n",
       "                       0.0807, -0.1250,  0.0337, -0.0455, -0.0529,  0.1024,  0.0419, -0.1134,\n",
       "                       0.0531,  0.0296, -0.0274, -0.0653,  0.1151,  0.0220, -0.1196, -0.1238,\n",
       "                       0.0945,  0.0823,  0.0274,  0.0777, -0.0018, -0.0074,  0.0274,  0.0546,\n",
       "                       0.0709,  0.0588,  0.0872, -0.0416, -0.0822,  0.0054, -0.0199,  0.0918,\n",
       "                       0.0202, -0.1180,  0.1075, -0.0389, -0.0285, -0.0412, -0.0231,  0.0722,\n",
       "                       0.0403,  0.1063,  0.0028,  0.1151, -0.0995, -0.0875,  0.0494, -0.0099,\n",
       "                      -0.0218,  0.0593, -0.1183, -0.0232, -0.0525,  0.0346, -0.1204,  0.1160,\n",
       "                       0.1286,  0.0876,  0.0789, -0.0588,  0.0021,  0.0850,  0.0929,  0.0830,\n",
       "                       0.0324, -0.0251,  0.1146,  0.0827,  0.0535, -0.0651, -0.0082, -0.0471,\n",
       "                      -0.0977,  0.0690,  0.0600,  0.1240, -0.1115,  0.1121,  0.0962, -0.0509,\n",
       "                      -0.0685, -0.1064,  0.0246,  0.0216, -0.0092,  0.0810, -0.1299,  0.0248,\n",
       "                       0.0235, -0.0550, -0.1054, -0.1239, -0.0160,  0.0740,  0.0160, -0.0961,\n",
       "                       0.0100,  0.1118, -0.1289,  0.0109,  0.0239,  0.0069,  0.0771, -0.0248,\n",
       "                       0.0159,  0.0632, -0.0608, -0.0988,  0.0210,  0.0676, -0.0270, -0.1007,\n",
       "                      -0.0643, -0.1038,  0.0737,  0.0225,  0.0297, -0.0365, -0.0258,  0.0042,\n",
       "                       0.0251, -0.1205,  0.0640, -0.0582,  0.0603,  0.0540,  0.0846, -0.0021,\n",
       "                       0.0436,  0.0105, -0.0377,  0.0684,  0.0077, -0.0786, -0.1108, -0.0411,\n",
       "                       0.0809, -0.1047,  0.0511,  0.1093, -0.1085,  0.1075, -0.0161,  0.1070,\n",
       "                      -0.1276, -0.0751, -0.0694, -0.0189, -0.0160, -0.0765, -0.0686,  0.1142,\n",
       "                      -0.1082,  0.0634, -0.0013,  0.0584,  0.0667,  0.0689,  0.0911, -0.0751,\n",
       "                       0.0092,  0.0314,  0.1020,  0.0496, -0.0460, -0.0268,  0.1155,  0.0294,\n",
       "                       0.0297,  0.0935, -0.0533, -0.0776,  0.0688, -0.0881,  0.0971, -0.0980,\n",
       "                      -0.1249, -0.0068, -0.0847,  0.0627, -0.0610, -0.0423, -0.1300, -0.0243,\n",
       "                       0.0870,  0.0074, -0.0749,  0.1192, -0.0578, -0.0766,  0.0950,  0.0155,\n",
       "                       0.0475, -0.0734, -0.0437,  0.0593, -0.0462,  0.0725,  0.0467,  0.0680,\n",
       "                      -0.0663,  0.1045,  0.0774,  0.1032, -0.1158,  0.0054,  0.0423,  0.1126,\n",
       "                       0.0494,  0.0075,  0.0054, -0.0629, -0.0271, -0.0586,  0.0953, -0.0693,\n",
       "                       0.0435, -0.1092, -0.0347,  0.0917,  0.0693,  0.0091, -0.1078, -0.0773])),\n",
       "             ('lstm.bias_hh_l0',\n",
       "              tensor([-0.0679,  0.1002,  0.0016,  0.1253, -0.0299,  0.0723, -0.0513,  0.0205,\n",
       "                      -0.1295, -0.1281,  0.0734, -0.0957, -0.1162,  0.0429, -0.0343,  0.0438,\n",
       "                      -0.0777,  0.0099, -0.0384,  0.1028,  0.0523, -0.0802,  0.0399, -0.0406,\n",
       "                      -0.0793,  0.0264, -0.0516, -0.0366,  0.0355, -0.1175, -0.0294,  0.0540,\n",
       "                       0.0311, -0.0571, -0.0668, -0.0448, -0.1273, -0.1192, -0.0119,  0.0182,\n",
       "                       0.1074,  0.0850,  0.1133,  0.0680,  0.0913,  0.1194, -0.0952, -0.0393,\n",
       "                       0.0581, -0.0862, -0.1219, -0.0151,  0.0965,  0.0913, -0.1001,  0.0393,\n",
       "                       0.1259,  0.1084, -0.1057, -0.0298,  0.0983, -0.0420, -0.0226,  0.0115,\n",
       "                       0.0322,  0.0568, -0.0428, -0.0957, -0.0862,  0.1276, -0.1038, -0.0382,\n",
       "                       0.0871,  0.0627, -0.0961, -0.0693,  0.0139,  0.1265, -0.0518, -0.0220,\n",
       "                       0.0055,  0.0138,  0.0626, -0.0895,  0.0912, -0.0519,  0.0011,  0.0661,\n",
       "                      -0.0040,  0.0226, -0.0365,  0.0081, -0.0620,  0.0177,  0.0447, -0.0357,\n",
       "                       0.1284, -0.0757, -0.0313,  0.0632, -0.1149, -0.0980, -0.0702, -0.0002,\n",
       "                       0.1188,  0.0665, -0.0687, -0.0883, -0.0409, -0.0280, -0.1052, -0.1158,\n",
       "                      -0.0487, -0.0670, -0.0003, -0.0370,  0.0804, -0.1016, -0.0936,  0.0459,\n",
       "                       0.1131,  0.0914,  0.0745, -0.1137, -0.0566, -0.1219,  0.0297,  0.0022,\n",
       "                      -0.0309, -0.0867, -0.1191,  0.0544,  0.0136, -0.1222,  0.1281,  0.0092,\n",
       "                      -0.0869, -0.0654,  0.0975,  0.0140,  0.1289,  0.0941,  0.0861, -0.0870,\n",
       "                       0.0266, -0.0647, -0.0021,  0.0537,  0.0554, -0.0172, -0.0509, -0.0593,\n",
       "                      -0.0841,  0.0765, -0.0832,  0.0570, -0.1173,  0.0913,  0.1182,  0.1119,\n",
       "                      -0.0646, -0.1288, -0.1264, -0.1006,  0.0895,  0.0169, -0.0128,  0.0462,\n",
       "                      -0.0349, -0.0033,  0.1043, -0.0463, -0.0179, -0.0934, -0.0540,  0.0063,\n",
       "                       0.0608, -0.0776, -0.0387,  0.0334, -0.0947, -0.0911, -0.1106,  0.0994,\n",
       "                       0.0534, -0.0644, -0.1208,  0.0498,  0.0440, -0.0205,  0.0163, -0.0064,\n",
       "                      -0.0361, -0.0416,  0.1031, -0.0885, -0.1199, -0.0078, -0.0498, -0.0829,\n",
       "                      -0.0668,  0.0052, -0.0900, -0.0585, -0.0733,  0.0585,  0.0038,  0.1114,\n",
       "                       0.0279, -0.0499,  0.0853,  0.0380,  0.0655, -0.1116,  0.0966, -0.0721,\n",
       "                      -0.0056, -0.1050,  0.0796,  0.0114,  0.1237, -0.0625, -0.0847, -0.0011,\n",
       "                      -0.1169,  0.0864, -0.0757, -0.1102, -0.1182, -0.0920, -0.0223,  0.0926,\n",
       "                      -0.0916,  0.0562, -0.0689, -0.0101, -0.0221, -0.0086, -0.0036, -0.0093,\n",
       "                       0.0365,  0.0406,  0.0091, -0.0124, -0.0593, -0.0711, -0.0601,  0.0161,\n",
       "                       0.0382, -0.0658, -0.0966,  0.1171, -0.1012, -0.1066,  0.1027, -0.0883])),\n",
       "             ('fc.weight',\n",
       "              tensor([[-0.0217, -0.1234,  0.0678,  0.0253,  0.0283, -0.1199, -0.0025, -0.1178,\n",
       "                        0.0973, -0.0186,  0.0734,  0.0133, -0.1014, -0.0919,  0.0246,  0.0543,\n",
       "                        0.0546,  0.0942, -0.0880, -0.0958, -0.0656,  0.1047,  0.0508,  0.0113,\n",
       "                        0.0990, -0.0692, -0.1104, -0.0767, -0.0039, -0.0765,  0.0166, -0.0615,\n",
       "                        0.0143,  0.0189,  0.0767,  0.0443,  0.0828,  0.1069, -0.0269,  0.0865,\n",
       "                       -0.0148, -0.0489,  0.0533, -0.0161,  0.1266, -0.0524, -0.0883, -0.0403,\n",
       "                       -0.0875, -0.0551, -0.0175,  0.0242,  0.0700,  0.0162, -0.1245, -0.0126,\n",
       "                        0.0409, -0.1209, -0.0381,  0.0557,  0.0020,  0.0390,  0.0625,  0.0696]])),\n",
       "             ('fc.bias', tensor([-0.1200]))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (k,v),(k2,v2) in zip(sd.items(),sd2.items()):\n",
    "    print(k , k2 , (v == v2).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
