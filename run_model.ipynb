{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[44m24-02-08 06:55:39|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[34mModel Specifics:\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-02-08 06:55:39|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[31mStart Process [Load Data]!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Process Queue : Data + Instance\n",
      "--Confirm Resume Training!\n",
      "--Model_name is set to TRA_LSTM_day!\n",
      "{'verbosity': 2,\n",
      " 'storage_type': 'mem',\n",
      " 'device': device(type='cuda', index=0),\n",
      " 'precision': 'float',\n",
      " 'batch_size': 10000,\n",
      " 'model_name': 'TRA_LSTM_day',\n",
      " 'model_module': 'TRA_LSTM',\n",
      " 'model_data_type': 'day',\n",
      " 'model_num': 1,\n",
      " 'beg_date': 20170103,\n",
      " 'end_date': 99991231,\n",
      " 'interval': 120,\n",
      " 'input_step_day': 5,\n",
      " 'test_step_day': 1,\n",
      " 'MODEL_PARAM': {'hidden_dim': [64],\n",
      "                 'seqlens': [{'day': 40, '15m': 20, 'dms': 40}],\n",
      "                 'tra_seqlens': [{'hist_loss': 40}],\n",
      "                 'rnn_layers': [2],\n",
      "                 'mlp_layers': [1],\n",
      "                 'dropout': [0.1],\n",
      "                 'fc_in': [True],\n",
      "                 'fc_att': [False],\n",
      "                 'type_rnn': ['lstm'],\n",
      "                 'rnn_att': [False],\n",
      "                 'num_output': [1],\n",
      "                 'kernel_size': [3, 3],\n",
      "                 'hidden_as_factor': [False],\n",
      "                 'ordered_param_group': [False],\n",
      "                 'tra_num_states': [3]},\n",
      " 'train_params': {'dataloader': {'random_seed': None, 'random_tv_split': True, 'sample_method': 'train_shuffle', 'train_ratio': 0.8},\n",
      "                  'trainer': {'optimizer': {'name': 'Adam', 'param': {}},\n",
      "                              'scheduler': {'name': 'cycle', 'param': {'base_lr': 1e-07, 'step_size_up': 4}},\n",
      "                              'learn_rate': {'base': 0.005,\n",
      "                                             'ratio': {'attempt': [1, 0.1, 10, 0.01, 100], 'round': [1.0], 'transfer': 0.1},\n",
      "                                             'reset': {'num_reset': 2, 'trigger': 40, 'recover_level': 1.0, 'speedup2x': True}},\n",
      "                              'nanloss': {'retry': 5},\n",
      "                              'gradient': {'clip_value': 10.0},\n",
      "                              'retrain': {'attempts': 4, 'min_epoch': 20, 'min_epoch_round': 10}},\n",
      "                  'criterion': {'loss': 'pearson',\n",
      "                                'score': {'train': 'pearson', 'valid': 'pearson', 'test': 'pearson'},\n",
      "                                'penalty': {'hidden_orthogonality': {'lamb': 0.001}, 'tra_ot_penalty': {'lamb': 0.01, 'rho': 0.999}},\n",
      "                                'weight': {'train': 'equal', 'test': 'equal'}},\n",
      "                  'transfer': False,\n",
      "                  'output_types': ['best', 'swalast', 'swabest'],\n",
      "                  'multitask': {'type': 'hybrid',\n",
      "                                'param_dict': {'dwa': {'tau': 2},\n",
      "                                               'ruw': {'phi': None},\n",
      "                                               'ewa': {},\n",
      "                                               'gls': {},\n",
      "                                               'rws': {},\n",
      "                                               'hybrid': {'phi': None, 'tau': 2}}},\n",
      "                  'terminate': {'overall': {'early_stop': 20, 'max_epoch': 200, 'valid_converge': {'min_epoch': 5, 'eps': 1e-05}},\n",
      "                                'round': {'early_stop': 10, 'max_epoch': 100, 'valid_converge': {'min_epoch': 5, 'eps': 1e-05}}}},\n",
      " 'compt_params': {'cuda_first': True, 'num_worker': 10}}\n",
      "use /home/mengkjin/Workspace/learndl/scripts/util/../../data/torch_pack/day+rtn11+res11.20231220.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-02-08 06:55:43|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Load Data]! Cost 3.2Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-02-08 06:55:43|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[31mStart Process [Copy to Instance]!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-02-08 06:55:43|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[34mCopy from model to instance finished , Start going forward\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Norming method of [day] : [endpoint_division(True) , history_standardize(True)]\n",
      "score function of [pearson] calculated and success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m20170103     0.1458  0.1442  0.1438\u001b[0m\n",
      "\u001b[32m20170704     0.1285  0.1275  0.1259\u001b[0m\n",
      "\u001b[32m20171226     0.1450  0.1483  0.1458\u001b[0m\n",
      "\u001b[32m20180627     0.1281  0.1280  0.1259\u001b[0m\n",
      "\u001b[32m20181220     0.0968  0.0947  0.0962\u001b[0m\n",
      "\u001b[32m20190624     0.0945  0.0961 -0.0072\u001b[0m\n",
      "\u001b[32m20191217     0.0889  0.0884  0.0874\u001b[0m\n",
      "\u001b[32m20200617     0.0747  0.0755  0.0754\u001b[0m\n",
      "\u001b[32m20201214     0.0979  0.0989  0.0980\u001b[0m\n",
      "\u001b[32m20210615     0.0462  0.0471  0.0477\u001b[0m\n",
      "\u001b[32m20211209     0.0965  0.0943  0.0963\u001b[0m\n",
      "\u001b[32m20220613     0.0803  0.0825  0.0199\u001b[0m\n",
      "\u001b[32m20221206     0.0569  0.0598  0.0591\u001b[0m\n",
      "\u001b[32m20230606     0.0640  0.0675  0.0693\u001b[0m\n",
      "\u001b[32m20231201     0.0949  0.0932  0.0935\u001b[0m\n",
      "\u001b[32mAllTimeAvg   0.0960  0.0966  0.0847\u001b[0m\n",
      "\u001b[32mAllTimeSum   163.55  164.59  144.28\u001b[0m\n",
      "\u001b[32mStd          0.0772  0.0757  0.0816\u001b[0m\n",
      "\u001b[32mTValue        51.33   52.67   42.83\u001b[0m\n",
      "\u001b[32mAnnIR        6.0915  6.2503  5.0828\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-02-08 06:59:16|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Copy to Instance]! Cost 213.0 Secs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%run run_model.py --process=3 --rawname=1 --resume=1 --anchoring=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--process PROCESS] [--rawname RAWNAME]\n",
      "                             [--resume RESUME] [--anchoring ANCHORING]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=c:\\Users\\jinmeng\\AppData\\Roaming\\jupyter\\runtime\\kernel-v2-16620Iv4LGbZ7ymXs.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use d:\\Coding\\learndl\\learndl\\scripts\\util/../../data/torch_pack/day+rtn11+res11.20231222.pt\n",
      "Pre-Norming method of [day] : [endpoint_division(True) , history_standardize(True)]\n"
     ]
    }
   ],
   "source": [
    "from run_model import * \n",
    "\n",
    "def new_random_input(module = 'tra_lstm2' , model_data_type = 'day' , model_data = None):\n",
    "\n",
    "    config = train_config(override_config = {'model_module' : module , 'model_data_type' : model_data_type} , do_process=False)\n",
    "    data_type_list = config.data_type_list\n",
    "    for smp in config.model_params: smp.update(model_params_filler(data_type_list = data_type_list))\n",
    "    model_data = ModelData(data_type_list , config)\n",
    "    model_data.create_dataloader(*model_data.get_dataloader_param('train','train',20170104,config.model_params[0]))\n",
    "    \n",
    "    #inday_dim_dict = {'15m' : 16 , '30m' : 8 , '60m' : 4 , '120m' : 2}\n",
    "    for i , batch_data in enumerate(model_data.dataloaders['train']):\n",
    "        batch_data = batch_data\n",
    "        break\n",
    "    net = new_net(module , param = config.model_params[0])\n",
    "    return net , batch_data , model_data\n",
    "\n",
    "net , batch_data , model_data = new_random_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[0.0867],\n",
       "          [0.0472],\n",
       "          [0.0484],\n",
       "          ...,\n",
       "          [0.0460],\n",
       "          [0.0476],\n",
       "          [0.0547]], grad_fn=<SumBackward1>),\n",
       "  tensor([[-0.1038,  0.1009, -0.0315,  ...,  0.0290,  0.0731,  0.1308],\n",
       "          [-0.0927,  0.0907, -0.0234,  ...,  0.0006,  0.1136,  0.1002],\n",
       "          [-0.1030,  0.0872, -0.0305,  ...,  0.0111,  0.0954,  0.1172],\n",
       "          ...,\n",
       "          [-0.0609,  0.0836, -0.0369,  ...,  0.0289,  0.1214,  0.1175],\n",
       "          [-0.0798,  0.0881, -0.0388,  ...,  0.0179,  0.0939,  0.1199],\n",
       "          [-0.1133,  0.0842, -0.0278,  ...,  0.0129,  0.0782,  0.1264]],\n",
       "         grad_fn=<AddmmBackward0>)),\n",
       " tensor([[ 0.3875],\n",
       "         [ 0.4519],\n",
       "         [-0.7027],\n",
       "         ...,\n",
       "         [ 1.1804],\n",
       "         [-1.3341],\n",
       "         [-0.1899]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.dynamic_data_assign(batch_data , model_data)\n",
    "net(batch_data['x']) , batch_data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test:\n",
    "    def __init__(self , n) -> None:\n",
    "        self.a = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = test(3)\n",
    "b = test(4)\n",
    "a.a , b.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.b = b\n",
    "a.a = a.b.a\n",
    "a.a , b.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.b.a = 5\n",
    "a.a , b.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = net.get_probs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.2050, 0.1918, 0.2121, 0.1930, 0.1981]])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8426, 0.3418, 0.4790, 0.4916],\n",
       "         [0.7773, 0.6809, 0.3131, 0.3789],\n",
       "         [0.0613, 0.5946, 0.9516, 0.7583]],\n",
       "\n",
       "        [[0.6826, 0.1543, 0.4325, 0.3777],\n",
       "         [0.9519, 0.4940, 0.3675, 0.8293],\n",
       "         [0.6968, 0.6019, 0.7147, 0.7691]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = None\n",
    "torch.concat([torch.rand(2,3,4), a] if a is not None else [torch.rand(2,3,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-78de06a6da7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mhist_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'hist_loss' is not defined"
     ]
    }
   ],
   "source": [
    "x.shape , hist_loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class tra_module:\n",
    "    '''\n",
    "    Decorator to grant a module dynamic data access, and output probs (tra feature)\n",
    "    '''\n",
    "    def __call__(self, original_class):\n",
    "        class new_tra_class(original_class):\n",
    "            def __init__(self , *args , **kwargs):\n",
    "                super().__init__(*args , **kwargs)\n",
    "                self.dynamic_data_assigned = False\n",
    "            def __call__(self , *args , **kwargs):\n",
    "                assert self.dynamic_data_assigned , f'Run dynamic_data_assign first'\n",
    "                self.dynamic_data_assigned = False\n",
    "                return super().__call__(*args , **kwargs)\n",
    "            def dynamic_data_assign(self , batch_data , model_data , **kwargs):\n",
    "                self.dynamic_data = {'model_data':model_data,'batch_data':batch_data,**kwargs}\n",
    "                self.dynamic_data_assigned = True\n",
    "            def get_probs(self):\n",
    "                v = torch.rand(2,5)\n",
    "                return v/v.sum(dim=1,keepdim=True)   \n",
    "                if self.probs_record is not None: return self.probs_record/self.probs_record.sum(dim=1,keepdim=True)   \n",
    "        return new_tra_class\n",
    "\n",
    "class tra_component:\n",
    "    '''\n",
    "    Decorator to identify a component of a module as tra components, apply pipeline dynamic data access, and output probs (tra feature)\n",
    "    '''\n",
    "    def __init__(self, *args):\n",
    "        self.tra_component_list = args\n",
    "    def __call__(self, original_class):\n",
    "        tra_component_list = self.tra_component_list\n",
    "        class new_tra_class(original_class):\n",
    "            def dynamic_data_assign(self , *args , **kwargs):\n",
    "                for comp in tra_component_list:\n",
    "                    getattr(self , comp).dynamic_data_assign(*args , **kwargs)\n",
    "            def dynamic_data_access(self , *args , **kwargs):\n",
    "                dynamic_data = [getattr(self , comp).dynamic_data for comp in tra_component_list]\n",
    "                return dynamic_data if len(dynamic_data) > 1 else dynamic_data[0]\n",
    "            def get_probs(self , *args , **kwargs):\n",
    "                probs = [getattr(self,comp).get_probs(*args , **kwargs) for comp in tra_component_list]\n",
    "                return probs if len(probs) > 1 else probs[0]\n",
    "        return new_tra_class\n",
    "\n",
    "@tra_module()\n",
    "class mod_tra(nn.Module):\n",
    "    def __init__(self , input_dim , output_dim , dropout=0.0 , num_layers = 2):\n",
    "        super().__init__()\n",
    "        num_layers = min(3,num_layers)\n",
    "        self.lstm = nn.LSTM(input_dim , output_dim , num_layers = num_layers , dropout = dropout , batch_first = True)\n",
    "    def forward(self, inputs):\n",
    "        return self.lstm(inputs)[0]\n",
    "\n",
    "@tra_component('tra1' , 'tra2')\n",
    "class mod_tra2(nn.Module):\n",
    "    def __init__(self , input_dim , output_dim , dropout=0.0 , num_layers = 2):\n",
    "        super().__init__()\n",
    "        self.tra1 = mod_tra(input_dim , output_dim)\n",
    "        self.tra2 = mod_tra(input_dim , output_dim)\n",
    "    def forward(self, inputs):\n",
    "        return self.tra1(inputs) + self.tra2(inputs)\n",
    "\n",
    "obj = mod_tra2(6,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(10).fill_(torch.nan)\n",
    "a.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.dynamic_data_assign(batch_data = 1,model_data = 2)\n",
    "obj.tra1.dynamic_data_assigned , obj.tra2.dynamic_data_assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.2405, 0.2494, 0.2031, 0.1997, 0.1073],\n",
       "         [0.4132, 0.1782, 0.1846, 0.1987, 0.0254]]),\n",
       " tensor([[0.1323, 0.2215, 0.2372, 0.2747, 0.1342],\n",
       "         [0.2788, 0.2884, 0.1591, 0.2695, 0.0042]])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = mod_tra2(6,4)\n",
    "obj.dynamic_data_assign(batch_data = 1,model_data = 2)\n",
    "obj(torch.rand(2,10,6))\n",
    "obj.get_probs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model_data': 2, 'batch_data': 1}, {'model_data': 2, 'batch_data': 1}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.dynamic_data_access()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
