{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-02-21 01:26:32|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[31mStart Process [Load Data]!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Process Queue : Data + Train + Test + Instance\n",
      "--Start Training New!\n",
      "--Model_name is set to tra_lstm2_day_ShortTest!\n",
      "use /home/mengkjin/Workspace/learndl/scripts/util/../../data/torch_pack/day+rtn11+res11.20231220.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-02-21 01:26:35|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Load Data]! Cost 3.0Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-02-21 01:26:35|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[31mStart Process [Train Model]!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Norming method of [day] : [endpoint_division(True) , history_standardize(True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mtra_lstm2_day_ShortTest #0 @20170103 LoadData Cost    2.3Secs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score function of [pearson] calculated and success!\n",
      "loss function of [pearson] calculated and success!\n",
      "penalty function of [hidden_orthogonality] calculated and success!\n",
      "penalty function of [tra_ot_penalty] calculated and success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mFirstBite Ep#  0 : loss  0.99741, train 0.00296, valid-0.00657, max-0.0066, best-0.0066, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  5 : loss  0.88611, train 0.12169, valid 0.07081, max 0.0708, best 0.0708, lr3.8e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 10 : loss  0.83631, train 0.17984, valid 0.08398, max 0.0847, best 0.0847, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 15 : loss  0.80640, train 0.21697, valid 0.08760, max 0.0956, best 0.0956, lr6.3e-04\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-02-21 01:26:52|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[34mtra_lstm2_day_ShortTest #0 @20170103|Round 0 FirstBite Ep# 19 Max Epoch|Train 0.2240 Valid 0.0865 BestVal 0.0956|Cost  0.3Min,  0.7Sec/Ep\u001b[0m\n",
      "\u001b[32mtra_lstm2_day_ShortTest #0 @20170704 LoadData Cost    2.0Secs\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  0 : loss  1.00103, train-0.00097, valid 0.00311, max 0.0031, best 0.0031, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  5 : loss  0.90061, train 0.10475, valid 0.06224, max 0.0622, best 0.0622, lr3.8e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 10 : loss  0.86083, train 0.14996, valid 0.08214, max 0.0821, best 0.0821, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 15 : loss  0.81832, train 0.20067, valid 0.09249, max 0.0925, best 0.0925, lr6.3e-04\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-02-21 01:27:08|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[34mtra_lstm2_day_ShortTest #0 @20170704|Round 0 FirstBite Ep# 19 Max Epoch|Train 0.2071 Valid 0.0956 BestVal 0.0956|Cost  0.3Min,  0.7Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-02-21 01:27:08|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Train Model]! Cost 0.0 Hours, 0.3 Min/model, 0.8 Sec/Epoch\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-02-21 01:27:08|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[31mStart Process [Test Model]!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-02-21 01:27:08|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[34mEach Model Date Testing Mean Score({'train': 'pearson', 'valid': 'pearson', 'test': 'pearson'}):\u001b[0m\n",
      "\u001b[32mModels            0       0       0\u001b[0m\n",
      "\u001b[32mOutput         best swalast swabest\u001b[0m\n",
      "\u001b[32m20170103     0.0846  0.0778  0.0838\u001b[0m\n",
      "\u001b[32m20170704     0.0921  0.0864  0.0914\u001b[0m\n",
      "\u001b[32mAllTimeAvg   0.0881  0.0818  0.0873\u001b[0m\n",
      "\u001b[32mAllTimeSum    19.64   18.24   19.46\u001b[0m\n",
      "\u001b[32mStd          0.0797  0.0724  0.0823\u001b[0m\n",
      "\u001b[32mTValue        16.51   16.87   15.84\u001b[0m\n",
      "\u001b[32mAnnIR        5.4161  5.5357  5.1968\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-02-21 01:27:19|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Test Model]! Cost 10.7 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-02-21 01:27:19|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[31mStart Process [Copy to Instance]!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-02-21 01:27:19|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[34mCopy from model to instance finished , Start going forward\u001b[0m\n",
      "\u001b[32m20170103     0.0840  0.0757  0.0842\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/Workspace/learndl/run_model.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Workspace/learndl/run_model.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mMain\u001b[0m \u001b[0mprocess\u001b[0m \u001b[0mof\u001b[0m \u001b[0mload_data\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \"\"\"\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocess_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_queue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_setname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'process_{process_name.lower()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Workspace/learndl/run_model.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_date\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmodel_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_date\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_date\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmodel_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_preparation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'instance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finish Process [Copy to Instance]! Cost {:.1f} Secs'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'instance_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/learndl/run_model.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'instance'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_test/save_preds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0mpath_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{config.instance_path}/{config.model_name}_allpreds.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mop_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m                 \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_data_alist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mop_data_alist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mop_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m                 \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'values'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'secid'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_output\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/learndl/run_model.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'instance'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_test/save_preds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0mpath_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{config.instance_path}/{config.model_name}_allpreds.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    837\u001b[0m                 )\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# For data is scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DataFrame constructor not properly called!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m             \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "%run run_model.py --process=0 --rawname=1 --resume=0 --anchoring=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class c1:\n",
    "    def __init__(self) -> None:\n",
    "        self.a = 1\n",
    "\n",
    "import torch\n",
    "a = torch.nn.ModuleList([torch.nn.LSTM(6,2) , torch.nn.LSTM(6,2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-1): 2 x LSTM(6, 2)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>d/0</th>\n",
       "      <th>d/1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>secid</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.019063</th>\n",
       "      <th>0.154501</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.469486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.083159</th>\n",
       "      <th>0.313822</th>\n",
       "      <td>0.522550</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.109028</th>\n",
       "      <th>0.535813</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.978911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.178684</th>\n",
       "      <th>0.097270</th>\n",
       "      <td>0.079051</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.211369</th>\n",
       "      <th>0.218383</th>\n",
       "      <td>0.633363</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.215425</th>\n",
       "      <th>0.753413</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.520709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.220946</th>\n",
       "      <th>0.496912</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.274408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.401072</th>\n",
       "      <th>0.483752</th>\n",
       "      <td>0.407401</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.442726</th>\n",
       "      <th>0.947592</th>\n",
       "      <td>0.603936</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.444994</th>\n",
       "      <th>0.001455</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.867273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.479292</th>\n",
       "      <th>0.400828</th>\n",
       "      <td>0.244216</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.529513</th>\n",
       "      <th>0.884884</th>\n",
       "      <td>0.285021</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.551971</th>\n",
       "      <th>0.205335</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.380068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.664661</th>\n",
       "      <th>0.605606</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.794666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.789619</th>\n",
       "      <th>0.732458</th>\n",
       "      <td>0.831630</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.876316</th>\n",
       "      <th>0.360330</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.387346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.909550</th>\n",
       "      <th>0.708239</th>\n",
       "      <td>0.693771</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.919721</th>\n",
       "      <th>0.449483</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.940539</th>\n",
       "      <th>0.496373</th>\n",
       "      <td>0.137543</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.991531</th>\n",
       "      <th>0.369816</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.324118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model                   d/0       d/1\n",
       "secid    date                        \n",
       "0.019063 0.154501       NaN  0.469486\n",
       "0.083159 0.313822  0.522550       NaN\n",
       "0.109028 0.535813       NaN  0.978911\n",
       "0.178684 0.097270  0.079051       NaN\n",
       "0.211369 0.218383  0.633363       NaN\n",
       "0.215425 0.753413       NaN  0.520709\n",
       "0.220946 0.496912       NaN  0.274408\n",
       "0.401072 0.483752  0.407401       NaN\n",
       "0.442726 0.947592  0.603936       NaN\n",
       "0.444994 0.001455       NaN  0.867273\n",
       "0.479292 0.400828  0.244216       NaN\n",
       "0.529513 0.884884  0.285021       NaN\n",
       "0.551971 0.205335       NaN  0.380068\n",
       "0.664661 0.605606       NaN  0.794666\n",
       "0.789619 0.732458  0.831630       NaN\n",
       "0.876316 0.360330       NaN  0.387346\n",
       "0.909550 0.708239  0.693771       NaN\n",
       "0.919721 0.449483       NaN  0.636414\n",
       "0.940539 0.496373  0.137543       NaN\n",
       "0.991531 0.369816       NaN  0.324118"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "prediction = []\n",
    "for i in range(2):\n",
    "    prediction.append({\n",
    "            'secid' : np.random.rand(10) , \n",
    "            'date'  : np.random.rand(10) ,\n",
    "            'model' : f'd/{i}' ,\n",
    "            'values': np.random.rand(10)\n",
    "        })\n",
    "df = pd.concat([pd.DataFrame(op_data) for op_data in prediction])\n",
    "df.pivot_table('values' , ['secid' , 'date'] , ['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -r ./instance/tra_lstm2_day_ShortTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mengkjin/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use /home/mengkjin/Workspace/learndl/scripts/util/../../data/torch_pack/day+rtn11+res11.20231220.pt\n",
      "Pre-Norming method of [day] : [endpoint_division(True) , history_standardize(True)]\n"
     ]
    }
   ],
   "source": [
    "from run_model import RunModel\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "config , net , batch_data , model_data , metrics , multiloss = RunModel.new_random_input('simple_lstm' , 'day')\n",
    "optimizer = RunModel.new_optimizer(net)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: empty expression not allowed (190273836.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    fstr = '{: <11s}' + f'\\\\{: >8.{digits}f\\\\}'*len(values)\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: empty expression not allowed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "digits = 2 \n",
    "values = np.random.rand(4)\n",
    "fstr = '{: <11s}' + ('{: >8.'+str(digits)+'f}')*len(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.044630740953896075, 'b': 0.1951984348401472}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "{k:v for k,v in zip(['a','b'] , np.random.rand(2))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5              0.30    0.21    0.92    0.75'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fstr.format(str(5) , *values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = deepcopy(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score function of [pearson] calculated and success!\n",
      "loss function of [pearson] calculated and success!\n",
      "{'loss': tensor(0.9808, grad_fn=<ExpBackward0>), 'loss_item': 0.9807661175727844, 'score': 0.01942128874361515, 'penalty': 0.0, 'losses': None}\n",
      "tensor([[ 0.0140, -0.0108,  0.0078, -0.0284, -0.0481,  0.0078, -0.0258,  0.0035,\n",
      "         -0.0371, -0.0073,  0.0234,  0.0281,  0.0275,  0.0296,  0.0173, -0.0114,\n",
      "          0.0221,  0.0060, -0.0328, -0.0356,  0.0031, -0.0325,  0.0141, -0.0161,\n",
      "          0.0009, -0.0024,  0.0167,  0.0265,  0.0198,  0.0362, -0.0010, -0.0116,\n",
      "         -0.0077, -0.0318, -0.0098,  0.0167, -0.0049, -0.0375,  0.0130, -0.0538,\n",
      "         -0.0527,  0.0242,  0.0462,  0.0368,  0.0090,  0.0316, -0.0234,  0.0166,\n",
      "         -0.0204, -0.0324,  0.0425,  0.0208, -0.0011,  0.0560, -0.0481,  0.0026,\n",
      "          0.0176,  0.0150, -0.0724, -0.0247, -0.0164,  0.0246,  0.0033, -0.0301]])\n"
     ]
    }
   ],
   "source": [
    "#pipeline 1\n",
    "\n",
    "sd = deepcopy(net.state_dict())\n",
    "optimizer = RunModel.new_optimizer(net)\n",
    "optimizer.zero_grad()\n",
    "if hasattr(net , 'dynamic_data_assign'): net.dynamic_data_assign(batch_data , model_data)\n",
    "pred , hidden = net(batch_data['x'])\n",
    "penalty_kwargs = {'net' : net , 'hidden' : hidden , 'label' : batch_data['y']}\n",
    "metric = RunModel.calculate_metrics('train' , metrics, label=batch_data['y'], pred=pred,\n",
    "                            weight=batch_data['w'], multiloss=multiloss,net=net,valid_sample=None,\n",
    "                            penalty_kwargs=penalty_kwargs)\n",
    "print(metric)\n",
    "(metric['loss'] + metric['penalty']).backward()\n",
    "print(net.get_parameter('fc.weight').grad)\n",
    "clip_value = config.train_params['trainer']['gradient'].get('clip_value')\n",
    "if clip_value is not None : nn.utils.clip_grad_value_(net.parameters(), clip_value = clip_value)\n",
    "optimizer.step()\n",
    "sd_step = deepcopy(net.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.9808, grad_fn=<ExpBackward0>), 'loss_item': 0.9807661175727844, 'score': 0.01942128874361515, 'penalty': 0.0, 'losses': None}\n",
      "tensor([[ 0.0140, -0.0108,  0.0078, -0.0284, -0.0481,  0.0078, -0.0258,  0.0035,\n",
      "         -0.0371, -0.0073,  0.0234,  0.0281,  0.0275,  0.0296,  0.0173, -0.0114,\n",
      "          0.0221,  0.0060, -0.0328, -0.0356,  0.0031, -0.0325,  0.0141, -0.0161,\n",
      "          0.0009, -0.0024,  0.0167,  0.0265,  0.0198,  0.0362, -0.0010, -0.0116,\n",
      "         -0.0077, -0.0318, -0.0098,  0.0167, -0.0049, -0.0375,  0.0130, -0.0538,\n",
      "         -0.0527,  0.0242,  0.0462,  0.0368,  0.0090,  0.0316, -0.0234,  0.0166,\n",
      "         -0.0204, -0.0324,  0.0425,  0.0208, -0.0011,  0.0560, -0.0481,  0.0026,\n",
      "          0.0176,  0.0150, -0.0724, -0.0247, -0.0164,  0.0246,  0.0033, -0.0301]])\n"
     ]
    }
   ],
   "source": [
    "#pipeline 2\n",
    "sd2 = deepcopy(net2.state_dict())\n",
    "optimizer2 = RunModel.new_optimizer(net2)\n",
    "if hasattr(net2 , 'dynamic_data_assign'): net2.dynamic_data_assign(batch_data , model_data)\n",
    "pred , hidden = net2(batch_data['x'])\n",
    "penalty_kwargs = {'net' : net2 , 'hidden' : hidden , 'label' : batch_data['y']}\n",
    "metric = RunModel.calculate_metrics('train' , metrics, label=batch_data['y'], pred=pred,\n",
    "                            weight=batch_data['w'], multiloss=multiloss,net=net2,valid_sample=None,\n",
    "                            penalty_kwargs=penalty_kwargs)\n",
    "optimizer2.zero_grad()\n",
    "print(metric)\n",
    "(metric['loss'] + metric['penalty']).backward()\n",
    "print(net2.get_parameter('fc.weight').grad)\n",
    "clip_value = config.train_params['trainer']['gradient'].get('clip_value')\n",
    "if clip_value is not None : nn.utils.clip_grad_value_(net2.parameters(), clip_value = clip_value)  # type:ignore\n",
    "optimizer2.step()\n",
    "sd2_step = deepcopy(net2.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm.weight_ih_l0 lstm.weight_ih_l0 tensor(True)\n",
      "lstm.weight_hh_l0 lstm.weight_hh_l0 tensor(True)\n",
      "lstm.bias_ih_l0 lstm.bias_ih_l0 tensor(True)\n",
      "lstm.bias_hh_l0 lstm.bias_hh_l0 tensor(True)\n",
      "fc.weight fc.weight tensor(True)\n",
      "fc.bias fc.bias tensor(True)\n"
     ]
    }
   ],
   "source": [
    "for (k,v),(k2,v2) in zip(sd_step.items(),sd2_step.items()):\n",
    "    print(k , k2 , (v == v2).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "class Test():\n",
    "    @staticmethod\n",
    "    def aa(x):\n",
    "        print(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def bb(x):\n",
    "        print(x)\n",
    "\n",
    "    def trytry(self , y = 1):\n",
    "        Test.aa(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "a = Test()\n",
    "a.trytry(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is static method 1\n",
      "This is static method 2\n",
      "0\n",
      "This is static method 2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "class MyClass:\n",
    "    def static_method1(self):\n",
    "        print(\"This is static method 1\")\n",
    "        self.static_method2()\n",
    "\n",
    "    @classmethod\n",
    "    def static_method2(cls , x : int = 0) -> None:\n",
    "        print(f\"This is static method 2\")\n",
    "        print(x)\n",
    "        return None\n",
    "\n",
    "# 调用静态方法1\n",
    "a = MyClass()\n",
    "a.static_method1()\n",
    "MyClass.static_method2(x=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "pool = np.arange(100)\n",
    "random.shuffle(pool) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lambda x=0:1)(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('lstm.weight_ih_l0',\n",
       "              tensor([[ 0.0910,  0.0800,  0.0628,  0.0726, -0.1145, -0.1069],\n",
       "                      [ 0.0649, -0.1171, -0.1229,  0.0789, -0.0136, -0.1013],\n",
       "                      [-0.0654,  0.0215, -0.0326, -0.0674, -0.0718, -0.0181],\n",
       "                      ...,\n",
       "                      [-0.0225, -0.0093, -0.0572,  0.1153,  0.0017,  0.0702],\n",
       "                      [ 0.1080,  0.1080,  0.1071,  0.0696, -0.0466,  0.0816],\n",
       "                      [ 0.0576, -0.0698,  0.0820,  0.1018, -0.0175,  0.0566]])),\n",
       "             ('lstm.weight_hh_l0',\n",
       "              tensor([[-0.0280, -0.0936,  0.0853,  ..., -0.0813, -0.1271, -0.1084],\n",
       "                      [-0.0192, -0.0755,  0.0637,  ...,  0.0753,  0.0598,  0.0185],\n",
       "                      [ 0.0307,  0.0137,  0.0812,  ..., -0.0837, -0.0918, -0.0508],\n",
       "                      ...,\n",
       "                      [-0.0289,  0.0206, -0.0827,  ...,  0.1069,  0.0243, -0.1109],\n",
       "                      [-0.0859,  0.0232, -0.0917,  ..., -0.0174, -0.0597,  0.0848],\n",
       "                      [ 0.0366,  0.0733, -0.0168,  ..., -0.0157,  0.0892, -0.0741]])),\n",
       "             ('lstm.bias_ih_l0',\n",
       "              tensor([ 0.0191, -0.0746, -0.0396, -0.0141,  0.0038, -0.0083,  0.1003,  0.0409,\n",
       "                       0.1198, -0.0119, -0.0639,  0.0693, -0.0330, -0.0458,  0.0855, -0.0679,\n",
       "                      -0.0744,  0.0140, -0.0287, -0.0987,  0.0438, -0.0394, -0.0564, -0.0499,\n",
       "                      -0.0671,  0.0057, -0.0117,  0.0957, -0.0763, -0.0820, -0.0899, -0.0484,\n",
       "                       0.0807, -0.1250,  0.0337, -0.0455, -0.0529,  0.1024,  0.0419, -0.1134,\n",
       "                       0.0531,  0.0296, -0.0274, -0.0653,  0.1151,  0.0220, -0.1196, -0.1238,\n",
       "                       0.0945,  0.0823,  0.0274,  0.0777, -0.0018, -0.0074,  0.0274,  0.0546,\n",
       "                       0.0709,  0.0588,  0.0872, -0.0416, -0.0822,  0.0054, -0.0199,  0.0918,\n",
       "                       0.0202, -0.1180,  0.1075, -0.0389, -0.0285, -0.0412, -0.0231,  0.0722,\n",
       "                       0.0403,  0.1063,  0.0028,  0.1151, -0.0995, -0.0875,  0.0494, -0.0099,\n",
       "                      -0.0218,  0.0593, -0.1183, -0.0232, -0.0525,  0.0346, -0.1204,  0.1160,\n",
       "                       0.1286,  0.0876,  0.0789, -0.0588,  0.0021,  0.0850,  0.0929,  0.0830,\n",
       "                       0.0324, -0.0251,  0.1146,  0.0827,  0.0535, -0.0651, -0.0082, -0.0471,\n",
       "                      -0.0977,  0.0690,  0.0600,  0.1240, -0.1115,  0.1121,  0.0962, -0.0509,\n",
       "                      -0.0685, -0.1064,  0.0246,  0.0216, -0.0092,  0.0810, -0.1299,  0.0248,\n",
       "                       0.0235, -0.0550, -0.1054, -0.1239, -0.0160,  0.0740,  0.0160, -0.0961,\n",
       "                       0.0100,  0.1118, -0.1289,  0.0109,  0.0239,  0.0069,  0.0771, -0.0248,\n",
       "                       0.0159,  0.0632, -0.0608, -0.0988,  0.0210,  0.0676, -0.0270, -0.1007,\n",
       "                      -0.0643, -0.1038,  0.0737,  0.0225,  0.0297, -0.0365, -0.0258,  0.0042,\n",
       "                       0.0251, -0.1205,  0.0640, -0.0582,  0.0603,  0.0540,  0.0846, -0.0021,\n",
       "                       0.0436,  0.0105, -0.0377,  0.0684,  0.0077, -0.0786, -0.1108, -0.0411,\n",
       "                       0.0809, -0.1047,  0.0511,  0.1093, -0.1085,  0.1075, -0.0161,  0.1070,\n",
       "                      -0.1276, -0.0751, -0.0694, -0.0189, -0.0160, -0.0765, -0.0686,  0.1142,\n",
       "                      -0.1082,  0.0634, -0.0013,  0.0584,  0.0667,  0.0689,  0.0911, -0.0751,\n",
       "                       0.0092,  0.0314,  0.1020,  0.0496, -0.0460, -0.0268,  0.1155,  0.0294,\n",
       "                       0.0297,  0.0935, -0.0533, -0.0776,  0.0688, -0.0881,  0.0971, -0.0980,\n",
       "                      -0.1249, -0.0068, -0.0847,  0.0627, -0.0610, -0.0423, -0.1300, -0.0243,\n",
       "                       0.0870,  0.0074, -0.0749,  0.1192, -0.0578, -0.0766,  0.0950,  0.0155,\n",
       "                       0.0475, -0.0734, -0.0437,  0.0593, -0.0462,  0.0725,  0.0467,  0.0680,\n",
       "                      -0.0663,  0.1045,  0.0774,  0.1032, -0.1158,  0.0054,  0.0423,  0.1126,\n",
       "                       0.0494,  0.0075,  0.0054, -0.0629, -0.0271, -0.0586,  0.0953, -0.0693,\n",
       "                       0.0435, -0.1092, -0.0347,  0.0917,  0.0693,  0.0091, -0.1078, -0.0773])),\n",
       "             ('lstm.bias_hh_l0',\n",
       "              tensor([-0.0679,  0.1002,  0.0016,  0.1253, -0.0299,  0.0723, -0.0513,  0.0205,\n",
       "                      -0.1295, -0.1281,  0.0734, -0.0957, -0.1162,  0.0429, -0.0343,  0.0438,\n",
       "                      -0.0777,  0.0099, -0.0384,  0.1028,  0.0523, -0.0802,  0.0399, -0.0406,\n",
       "                      -0.0793,  0.0264, -0.0516, -0.0366,  0.0355, -0.1175, -0.0294,  0.0540,\n",
       "                       0.0311, -0.0571, -0.0668, -0.0448, -0.1273, -0.1192, -0.0119,  0.0182,\n",
       "                       0.1074,  0.0850,  0.1133,  0.0680,  0.0913,  0.1194, -0.0952, -0.0393,\n",
       "                       0.0581, -0.0862, -0.1219, -0.0151,  0.0965,  0.0913, -0.1001,  0.0393,\n",
       "                       0.1259,  0.1084, -0.1057, -0.0298,  0.0983, -0.0420, -0.0226,  0.0115,\n",
       "                       0.0322,  0.0568, -0.0428, -0.0957, -0.0862,  0.1276, -0.1038, -0.0382,\n",
       "                       0.0871,  0.0627, -0.0961, -0.0693,  0.0139,  0.1265, -0.0518, -0.0220,\n",
       "                       0.0055,  0.0138,  0.0626, -0.0895,  0.0912, -0.0519,  0.0011,  0.0661,\n",
       "                      -0.0040,  0.0226, -0.0365,  0.0081, -0.0620,  0.0177,  0.0447, -0.0357,\n",
       "                       0.1284, -0.0757, -0.0313,  0.0632, -0.1149, -0.0980, -0.0702, -0.0002,\n",
       "                       0.1188,  0.0665, -0.0687, -0.0883, -0.0409, -0.0280, -0.1052, -0.1158,\n",
       "                      -0.0487, -0.0670, -0.0003, -0.0370,  0.0804, -0.1016, -0.0936,  0.0459,\n",
       "                       0.1131,  0.0914,  0.0745, -0.1137, -0.0566, -0.1219,  0.0297,  0.0022,\n",
       "                      -0.0309, -0.0867, -0.1191,  0.0544,  0.0136, -0.1222,  0.1281,  0.0092,\n",
       "                      -0.0869, -0.0654,  0.0975,  0.0140,  0.1289,  0.0941,  0.0861, -0.0870,\n",
       "                       0.0266, -0.0647, -0.0021,  0.0537,  0.0554, -0.0172, -0.0509, -0.0593,\n",
       "                      -0.0841,  0.0765, -0.0832,  0.0570, -0.1173,  0.0913,  0.1182,  0.1119,\n",
       "                      -0.0646, -0.1288, -0.1264, -0.1006,  0.0895,  0.0169, -0.0128,  0.0462,\n",
       "                      -0.0349, -0.0033,  0.1043, -0.0463, -0.0179, -0.0934, -0.0540,  0.0063,\n",
       "                       0.0608, -0.0776, -0.0387,  0.0334, -0.0947, -0.0911, -0.1106,  0.0994,\n",
       "                       0.0534, -0.0644, -0.1208,  0.0498,  0.0440, -0.0205,  0.0163, -0.0064,\n",
       "                      -0.0361, -0.0416,  0.1031, -0.0885, -0.1199, -0.0078, -0.0498, -0.0829,\n",
       "                      -0.0668,  0.0052, -0.0900, -0.0585, -0.0733,  0.0585,  0.0038,  0.1114,\n",
       "                       0.0279, -0.0499,  0.0853,  0.0380,  0.0655, -0.1116,  0.0966, -0.0721,\n",
       "                      -0.0056, -0.1050,  0.0796,  0.0114,  0.1237, -0.0625, -0.0847, -0.0011,\n",
       "                      -0.1169,  0.0864, -0.0757, -0.1102, -0.1182, -0.0920, -0.0223,  0.0926,\n",
       "                      -0.0916,  0.0562, -0.0689, -0.0101, -0.0221, -0.0086, -0.0036, -0.0093,\n",
       "                       0.0365,  0.0406,  0.0091, -0.0124, -0.0593, -0.0711, -0.0601,  0.0161,\n",
       "                       0.0382, -0.0658, -0.0966,  0.1171, -0.1012, -0.1066,  0.1027, -0.0883])),\n",
       "             ('fc.weight',\n",
       "              tensor([[-0.0217, -0.1234,  0.0678,  0.0253,  0.0283, -0.1199, -0.0025, -0.1178,\n",
       "                        0.0973, -0.0186,  0.0734,  0.0133, -0.1014, -0.0919,  0.0246,  0.0543,\n",
       "                        0.0546,  0.0942, -0.0880, -0.0958, -0.0656,  0.1047,  0.0508,  0.0113,\n",
       "                        0.0990, -0.0692, -0.1104, -0.0767, -0.0039, -0.0765,  0.0166, -0.0615,\n",
       "                        0.0143,  0.0189,  0.0767,  0.0443,  0.0828,  0.1069, -0.0269,  0.0865,\n",
       "                       -0.0148, -0.0489,  0.0533, -0.0161,  0.1266, -0.0524, -0.0883, -0.0403,\n",
       "                       -0.0875, -0.0551, -0.0175,  0.0242,  0.0700,  0.0162, -0.1245, -0.0126,\n",
       "                        0.0409, -0.1209, -0.0381,  0.0557,  0.0020,  0.0390,  0.0625,  0.0696]])),\n",
       "             ('fc.bias', tensor([-0.1200]))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (k,v),(k2,v2) in zip(sd.items(),sd2.items()):\n",
    "    print(k , k2 , (v == v2).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
