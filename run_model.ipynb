{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[44m24-02-08 06:55:39|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[34mModel Specifics:\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-02-08 06:55:39|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[31mStart Process [Load Data]!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Process Queue : Data + Instance\n",
      "--Confirm Resume Training!\n",
      "--Model_name is set to TRA_LSTM_day!\n",
      "{'verbosity': 2,\n",
      " 'storage_type': 'mem',\n",
      " 'device': device(type='cuda', index=0),\n",
      " 'precision': 'float',\n",
      " 'batch_size': 10000,\n",
      " 'model_name': 'TRA_LSTM_day',\n",
      " 'model_module': 'TRA_LSTM',\n",
      " 'model_data_type': 'day',\n",
      " 'model_num': 1,\n",
      " 'beg_date': 20170103,\n",
      " 'end_date': 99991231,\n",
      " 'interval': 120,\n",
      " 'input_step_day': 5,\n",
      " 'test_step_day': 1,\n",
      " 'MODEL_PARAM': {'hidden_dim': [64],\n",
      "                 'seqlens': [{'day': 40, '15m': 20, 'dms': 40}],\n",
      "                 'tra_seqlens': [{'hist_loss': 40}],\n",
      "                 'rnn_layers': [2],\n",
      "                 'mlp_layers': [1],\n",
      "                 'dropout': [0.1],\n",
      "                 'fc_in': [True],\n",
      "                 'fc_att': [False],\n",
      "                 'type_rnn': ['lstm'],\n",
      "                 'rnn_att': [False],\n",
      "                 'num_output': [1],\n",
      "                 'kernel_size': [3, 3],\n",
      "                 'hidden_as_factor': [False],\n",
      "                 'ordered_param_group': [False],\n",
      "                 'tra_num_states': [3]},\n",
      " 'train_params': {'dataloader': {'random_seed': None, 'random_tv_split': True, 'sample_method': 'train_shuffle', 'train_ratio': 0.8},\n",
      "                  'trainer': {'optimizer': {'name': 'Adam', 'param': {}},\n",
      "                              'scheduler': {'name': 'cycle', 'param': {'base_lr': 1e-07, 'step_size_up': 4}},\n",
      "                              'learn_rate': {'base': 0.005,\n",
      "                                             'ratio': {'attempt': [1, 0.1, 10, 0.01, 100], 'round': [1.0], 'transfer': 0.1},\n",
      "                                             'reset': {'num_reset': 2, 'trigger': 40, 'recover_level': 1.0, 'speedup2x': True}},\n",
      "                              'nanloss': {'retry': 5},\n",
      "                              'gradient': {'clip_value': 10.0},\n",
      "                              'retrain': {'attempts': 4, 'min_epoch': 20, 'min_epoch_round': 10}},\n",
      "                  'criterion': {'loss': 'pearson',\n",
      "                                'score': {'train': 'pearson', 'valid': 'pearson', 'test': 'pearson'},\n",
      "                                'penalty': {'hidden_orthogonality': {'lamb': 0.001}, 'tra_ot_penalty': {'lamb': 0.01, 'rho': 0.999}},\n",
      "                                'weight': {'train': 'equal', 'test': 'equal'}},\n",
      "                  'transfer': False,\n",
      "                  'output_types': ['best', 'swalast', 'swabest'],\n",
      "                  'multitask': {'type': 'hybrid',\n",
      "                                'param_dict': {'dwa': {'tau': 2},\n",
      "                                               'ruw': {'phi': None},\n",
      "                                               'ewa': {},\n",
      "                                               'gls': {},\n",
      "                                               'rws': {},\n",
      "                                               'hybrid': {'phi': None, 'tau': 2}}},\n",
      "                  'terminate': {'overall': {'early_stop': 20, 'max_epoch': 200, 'valid_converge': {'min_epoch': 5, 'eps': 1e-05}},\n",
      "                                'round': {'early_stop': 10, 'max_epoch': 100, 'valid_converge': {'min_epoch': 5, 'eps': 1e-05}}}},\n",
      " 'compt_params': {'cuda_first': True, 'num_worker': 10}}\n",
      "use /home/mengkjin/Workspace/learndl/scripts/util/../../data/torch_pack/day+rtn11+res11.20231220.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-02-08 06:55:43|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Load Data]! Cost 3.2Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-02-08 06:55:43|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[31mStart Process [Copy to Instance]!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-02-08 06:55:43|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[34mCopy from model to instance finished , Start going forward\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Norming method of [day] : [endpoint_division(True) , history_standardize(True)]\n",
      "score function of [pearson] calculated and success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m20170103     0.1458  0.1442  0.1438\u001b[0m\n",
      "\u001b[32m20170704     0.1285  0.1275  0.1259\u001b[0m\n",
      "\u001b[32m20171226     0.1450  0.1483  0.1458\u001b[0m\n",
      "\u001b[32m20180627     0.1281  0.1280  0.1259\u001b[0m\n",
      "\u001b[32m20181220     0.0968  0.0947  0.0962\u001b[0m\n",
      "\u001b[32m20190624     0.0945  0.0961 -0.0072\u001b[0m\n",
      "\u001b[32m20191217     0.0889  0.0884  0.0874\u001b[0m\n",
      "\u001b[32m20200617     0.0747  0.0755  0.0754\u001b[0m\n",
      "\u001b[32m20201214     0.0979  0.0989  0.0980\u001b[0m\n",
      "\u001b[32m20210615     0.0462  0.0471  0.0477\u001b[0m\n",
      "\u001b[32m20211209     0.0965  0.0943  0.0963\u001b[0m\n",
      "\u001b[32m20220613     0.0803  0.0825  0.0199\u001b[0m\n",
      "\u001b[32m20221206     0.0569  0.0598  0.0591\u001b[0m\n",
      "\u001b[32m20230606     0.0640  0.0675  0.0693\u001b[0m\n",
      "\u001b[32m20231201     0.0949  0.0932  0.0935\u001b[0m\n",
      "\u001b[32mAllTimeAvg   0.0960  0.0966  0.0847\u001b[0m\n",
      "\u001b[32mAllTimeSum   163.55  164.59  144.28\u001b[0m\n",
      "\u001b[32mStd          0.0772  0.0757  0.0816\u001b[0m\n",
      "\u001b[32mTValue        51.33   52.67   42.83\u001b[0m\n",
      "\u001b[32mAnnIR        6.0915  6.2503  5.0828\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-02-08 06:59:16|MOD:run_model   |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Copy to Instance]! Cost 213.0 Secs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%run run_model.py --process=3 --rawname=1 --resume=1 --anchoring=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[ 0.8244],\n",
       "          [-0.8244]], grad_fn=<CatBackward0>),\n",
       "  tensor([[ 0.0150, -0.0151,  0.0328,  0.0110, -0.0407, -0.0875, -0.0561, -0.0384,\n",
       "           -0.0614,  0.0018, -0.0611, -0.1183,  0.0858, -0.1193, -0.1083, -0.1048,\n",
       "            0.0545,  0.0358, -0.1490,  0.0227,  0.1039,  0.1015, -0.1277, -0.0368,\n",
       "            0.0947, -0.0881,  0.0536,  0.0759, -0.0913, -0.0826,  0.0479, -0.0714,\n",
       "            0.0476,  0.1189, -0.0798,  0.0711,  0.0692, -0.0146, -0.1710, -0.0201,\n",
       "            0.0053, -0.0978, -0.1515, -0.0618,  0.0748,  0.1126, -0.0168, -0.0885,\n",
       "           -0.0999, -0.1310,  0.0005, -0.0547, -0.0484, -0.0192,  0.0115,  0.0833,\n",
       "           -0.1187, -0.1257,  0.1197, -0.0753,  0.0007, -0.0495, -0.1086,  0.1079],\n",
       "          [ 0.0530, -0.0267,  0.0408, -0.0038, -0.0435, -0.0722, -0.0830, -0.0138,\n",
       "           -0.0461, -0.0029, -0.0767, -0.1159,  0.0926, -0.1050, -0.1398, -0.0993,\n",
       "            0.0514,  0.0300, -0.1183,  0.0063,  0.1082,  0.1206, -0.1221, -0.0250,\n",
       "            0.0894, -0.0906,  0.0322,  0.0646, -0.1235, -0.0822,  0.0542, -0.0656,\n",
       "            0.0364,  0.1058, -0.0900,  0.0680,  0.0519, -0.0027, -0.1338, -0.0282,\n",
       "            0.0288, -0.0909, -0.1187, -0.0436,  0.0658,  0.1046, -0.0192, -0.1086,\n",
       "           -0.0819, -0.0935, -0.0004, -0.0552, -0.0545,  0.0138,  0.0241,  0.0798,\n",
       "           -0.1186, -0.1143,  0.0893, -0.1052, -0.0352, -0.0337, -0.1032,  0.1148]],\n",
       "         grad_fn=<AddmmBackward0>)),\n",
       " tensor([[0.4317],\n",
       "         [0.4114]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from run_model import * \n",
    "\n",
    "net , x , y = new_random_input('ResNet_LSTM' , '30m')\n",
    "net(x) , y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.8050],\n",
       "         [-0.8050]], grad_fn=<CatBackward0>),\n",
       " tensor([[-0.0043,  0.0230, -0.0724, -0.0051, -0.0170, -0.0417,  0.1198,  0.0162,\n",
       "           0.0065,  0.0669, -0.0142,  0.0682,  0.0672,  0.0975, -0.1097,  0.0147,\n",
       "          -0.0106, -0.0431,  0.1217, -0.0439,  0.0584,  0.1293,  0.0923,  0.0027,\n",
       "           0.0279,  0.0484,  0.0966, -0.0188, -0.0034, -0.0446,  0.1307,  0.0209,\n",
       "          -0.0230, -0.0275,  0.0201, -0.0880, -0.1329,  0.1055, -0.0347, -0.1129,\n",
       "          -0.0720, -0.0871,  0.0238,  0.0540,  0.0128, -0.0959,  0.0696, -0.1054,\n",
       "           0.0717, -0.0020,  0.0773,  0.0373, -0.0932,  0.1856,  0.1003,  0.0376,\n",
       "           0.1033, -0.1120,  0.0046, -0.1180, -0.0295,  0.0177,  0.0780, -0.0852],\n",
       "         [ 0.0038,  0.0252, -0.0847,  0.0183, -0.0090, -0.0060,  0.0791,  0.0243,\n",
       "          -0.0389,  0.0877,  0.0175,  0.0573,  0.1012,  0.0882, -0.1257,  0.0270,\n",
       "          -0.0339, -0.0702,  0.1098, -0.0691,  0.0365,  0.0791,  0.0758,  0.0029,\n",
       "           0.0114,  0.0738,  0.0858, -0.0118, -0.0172, -0.0625,  0.1242, -0.0210,\n",
       "          -0.0170, -0.0495,  0.0267, -0.0864, -0.1170,  0.0734, -0.0342, -0.1149,\n",
       "          -0.0830, -0.0899,  0.0029,  0.0304, -0.0066, -0.0776,  0.0448, -0.1235,\n",
       "           0.0820, -0.0135,  0.0642,  0.0374, -0.0758,  0.1419,  0.1076,  0.0287,\n",
       "           0.0734, -0.0980, -0.0133, -0.0834, -0.0146,  0.0121,  0.0426, -0.1004]],\n",
       "        grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 30, 8, 6]), torch.Size([2, 1]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['30m'].shape , y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = new_net(config.model_module , model_params[0])\n",
    "o , h = net(x['30m'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 30, 64])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = net.encoder.mod_list[0].fc_enc_in(x)\n",
    "net.encoder.mod_list[0].fc_rnn(x1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uni_rnn_encoder(\n",
       "  (fc_enc_in): resnet_1d(\n",
       "    (blocks): Sequential(\n",
       "      (0): resnet_block_1d(\n",
       "        (downsample): Conv1d(6, 16, kernel_size=(1,), stride=(1,))\n",
       "        (conv): Sequential(\n",
       "          (0): Conv1d(6, 4, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv1d(4, 4, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (4): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "          (6): Conv1d(4, 16, kernel_size=(1,), stride=(1,))\n",
       "          (7): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (8): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (1): resnet_block_1d(\n",
       "        (downsample): Sequential()\n",
       "        (conv): Sequential(\n",
       "          (0): Conv1d(16, 4, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv1d(4, 4, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (4): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "          (6): Conv1d(4, 16, kernel_size=(1,), stride=(1,))\n",
       "          (7): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (8): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (2): resnet_block_1d(\n",
       "        (downsample): Sequential()\n",
       "        (conv): Sequential(\n",
       "          (0): Conv1d(16, 4, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv1d(4, 4, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (4): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "          (6): Conv1d(4, 16, kernel_size=(1,), stride=(1,))\n",
       "          (7): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (8): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc_out): Linear(in_features=128, out_features=16, bias=True)\n",
       "  )\n",
       "  (fc_rnn): mod_lstm(\n",
       "    (lstm): LSTM(16, 64, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.encoder.mod_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'a' : None}\n",
    "a.get('a' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if None and 'a' == 'a':\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden shape : torch.Size([2, 30, 16])\n",
      "output shape : torch.Size([2, 64])\n",
      "hidden shape : torch.Size([2, 30, 16])\n",
      "output shape : torch.Size([2, 64])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# pip install pytimedinput -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "from scripts.nn.My import mod_gru\n",
    "from scripts.nn.ResNet import resnet_1d, resnet_2d\n",
    "    \n",
    "class resnet1d_gru(nn.Module):\n",
    "    def __init__(self, seq_len , feat_len , dim_res = 16 , dim_rnn = 64 , *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.resnet = resnet_1d(seq_len , feat_len , dim_res , 10 , 3) \n",
    "        self.gru    = mod_gru(dim_res , dim_rnn , 0.1 , 2)\n",
    "    def forward(self , x):\n",
    "        hidden = self.resnet(x)\n",
    "        print(\"hidden shape :\" , hidden.shape)\n",
    "        output = self.gru(hidden)[:,-1,:]\n",
    "        print(\"output shape :\" , output.shape)\n",
    "        return output\n",
    "    \n",
    "class resnet2d_gru(nn.Module):\n",
    "    def __init__(self, seq_len , feat_len , dim_res = 16 , dim_rnn = 64 , *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.resnet = resnet_2d(seq_len , feat_len , dim_res , 10 , 3) \n",
    "        self.gru    = mod_gru(dim_res , dim_rnn , 0.1 , 2)\n",
    "    def forward(self , x):\n",
    "        hidden = self.resnet(x)\n",
    "        output = self.gru(hidden)[:,-1,:]\n",
    "        print(\"hidden shape :\" , hidden.shape)\n",
    "        print(\"output shape :\" , output.shape)\n",
    "        return output\n",
    "    \n",
    "\n",
    "batch_n  = 2\n",
    "seq_day  = 30\n",
    "seq_inday  = 8\n",
    "feat_len = 5\n",
    "dim_out  = 64\n",
    "x = torch.randn(batch_n,seq_day,seq_inday,feat_len)\n",
    "\n",
    "net_1d = resnet1d_gru(seq_inday , feat_len , dim_res = dim_out // 4 , dim_rnn = dim_out)\n",
    "net_2d = resnet2d_gru(seq_inday , feat_len , dim_res = dim_out // 4 , dim_rnn = dim_out)\n",
    "y1 = net_1d(x)\n",
    "y2 = net_2d(x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
