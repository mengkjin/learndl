{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haitong/hf_factors\n",
      "since 20130101 to 20231227, total 43 periods(Q)\n",
      "Wed Dec 27 23:14:12 2023 : haitong:hf_factors:201407                    \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/mengkjin/Workspace/learndl/scripts/data_util/sqlConnector.py\", line 173, in default_query\n",
      "    df = pd.read_sql_query(query , self.connections[src])\n",
      "  File \"/home/mengkjin/.local/lib/python3.10/site-packages/pandas/io/sql.py\", line 486, in read_sql_query\n",
      "    return pandas_sql.read_query(\n",
      "  File \"/home/mengkjin/.local/lib/python3.10/site-packages/pandas/io/sql.py\", line 1776, in read_query\n",
      "    result = self.execute(sql, params)\n",
      "  File \"/home/mengkjin/.local/lib/python3.10/site-packages/pandas/io/sql.py\", line 1599, in execute\n",
      "    return self.con.exec_driver_sql(sql, *args)\n",
      "  File \"/home/mengkjin/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1778, in exec_driver_sql\n",
      "    ret = self._execute_context(\n",
      "  File \"/home/mengkjin/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1848, in _execute_context\n",
      "    return self._exec_single_context(\n",
      "  File \"/home/mengkjin/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1988, in _exec_single_context\n",
      "    self._handle_dbapi_exception(\n",
      "  File \"/home/mengkjin/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 2346, in _handle_dbapi_exception\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/home/mengkjin/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1969, in _exec_single_context\n",
      "    self.dialect.do_execute(\n",
      "  File \"/home/mengkjin/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py\", line 922, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mengkjin/Workspace/learndl/scripts/data_util/sqlConnector.py\", line 297, in update_connector\n",
      "    connector.download_since(dtank,src,qtype,trace=trace,ask=False)\n",
      "  File \"/home/mengkjin/Workspace/learndl/scripts/data_util/sqlConnector.py\", line 247, in download_since\n",
      "    data = self.default_query(src , query_type , s , e)\n",
      "  File \"/home/mengkjin/Workspace/learndl/scripts/data_util/sqlConnector.py\", line 182, in default_query\n",
      "    raise Exception\n",
      "Exception\n"
     ]
    }
   ],
   "source": [
    "from scripts.data_util.sqlConnector import online_sql_connector , update_connector\n",
    "update_connector(path = './data/DB_data/DB_3rdPartySQL.h5' , connector = online_sql_connector() , trace = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haitong/hf_factors\n",
      "since 20230101 to 20230110, total 1 periods(Q)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mengkjin/.local/lib/python3.10/site-packages/pymysql/connections.py\", line 779, in _read_bytes\n",
      "    data = self._rfile.read(num_bytes)\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mengkjin/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 988, in _finalize_fairy\n",
      "    fairy._reset(\n",
      "  File \"/home/mengkjin/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 1438, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/home/mengkjin/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py\", line 692, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "  File \"/home/mengkjin/.local/lib/python3.10/site-packages/pymysql/connections.py\", line 488, in rollback\n",
      "    self._read_ok_packet()\n",
      "  File \"/home/mengkjin/.local/lib/python3.10/site-packages/pymysql/connections.py\", line 448, in _read_ok_packet\n",
      "    pkt = self._read_packet()\n",
      "  File \"/home/mengkjin/.local/lib/python3.10/site-packages/pymysql/connections.py\", line 739, in _read_packet\n",
      "    packet_header = self._read_bytes(4)\n",
      "  File \"/home/mengkjin/.local/lib/python3.10/site-packages/pymysql/connections.py\", line 785, in _read_bytes\n",
      "    raise err.OperationalError(\n",
      "pymysql.err.OperationalError: (2013, 'Lost connection to MySQL server during query ([Errno 104] Connection reset by peer)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 27 23:07:26 2023 : haitong:hf_factors:202301                    \n",
      "\n",
      "haitong/dl_factors\n",
      "since 20230101 to 20230110, total 1 periods(Q)\n",
      "Wed Dec 27 23:08:10 2023 : haitong:dl_factors:202301                    \n",
      "\n",
      "dongfang/hfq_chars\n",
      "since 20230101 to 20230110, total 1 periods(Q)\n",
      "Wed Dec 27 23:08:17 2023 : dongfang:hfq_chars:202301                    \n",
      "\n",
      "dongfang/l2_chars\n",
      "since 20230101 to 20230110, total 1 periods(Q)\n",
      "Wed Dec 27 23:08:41 2023 : dongfang:l2_chars:202301                    \n",
      "\n",
      "dongfang/ms_chars\n",
      "since 20230101 to 20230110, total 1 periods(Q)\n",
      "Wed Dec 27 23:09:20 2023 : dongfang:ms_chars:202301                    \n",
      "\n",
      "dongfang/order_flow\n",
      "since 20230101 to 20230110, total 1 periods(Q)\n",
      "Wed Dec 27 23:09:22 2023 : dongfang:order_flow:202301                    \n",
      "\n",
      "dongfang/gp\n",
      "since 20230101 to 20230110, total 1 periods(Q)\n",
      "Wed Dec 27 23:09:23 2023 : dongfang:gp:202301                    \n",
      "\n",
      "dongfang/tra\n",
      "since 20230101 to 20230110, total 1 periods(Q)\n",
      "Wed Dec 27 23:09:24 2023 : dongfang:tra:202301                    \n",
      "\n",
      "dongfang/scores_v0\n",
      "since 20230101 to 20230110, total 1 periods(Q)\n",
      "Wed Dec 27 23:09:24 2023 : dongfang:scores_v0:202301                    \n",
      "\n",
      "kaiyuan/positive\n",
      "since 20230101 to 20230110, total 1 periods(Q)\n",
      "Wed Dec 27 23:09:26 2023 : kaiyuan:positive:202301                    \n",
      "\n",
      "kaiyuan/negative\n",
      "since 20230101 to 20230110, total 1 periods(Q)\n",
      "Wed Dec 27 23:09:27 2023 : kaiyuan:negative:202301                    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine , exc , text\n",
    "from datetime import date , datetime\n",
    "import traceback\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os , time\n",
    "\n",
    "connect_dict = {\n",
    "    'haitong':{\n",
    "        'dialect'  : 'mssql+pyodbc' ,\n",
    "        'driver'   : 'FreeTDS' ,\n",
    "        'username' : 'JSJJDataReader' ,\n",
    "        'password' : 'JSJJDataReader' ,\n",
    "        'host'     : 'rm-uf6777pp2098v0um6hm.sqlserver.rds.aliyuncs.com' ,\n",
    "        'port'     : 3433 ,\n",
    "        'database' : 'daily_factor_db' ,\n",
    "    },\n",
    "    'dongfang':{\n",
    "        'dialect'  : 'mysql+pymysql' ,\n",
    "        'username' : 'hfq_jiashi' ,\n",
    "        'password' : 'LTBi94we' ,\n",
    "        'host'     : '139.196.77.199' ,\n",
    "        'port'     : 81 ,\n",
    "        'database' : 'model' ,\n",
    "    },\n",
    "    'kaiyuan':{\n",
    "        'dialect'  : 'postgresql' ,\n",
    "        'username' : 'harvest_user' ,\n",
    "        'password' : 'harvest' ,\n",
    "        'host'     : '1.15.124.26' ,\n",
    "        'port'     : 5432 ,\n",
    "        'database' : 'kyfactor' ,\n",
    "    },\n",
    "    'guojin':{\n",
    "        'dialect'  : 'mysql+pymysql' ,\n",
    "        'username' : 'jsfund' ,\n",
    "        'password' : 'Gjquant_js!' ,\n",
    "        'host'     : 'quantstudio.tpddns.cn' ,\n",
    "        'port'     : 3306 ,\n",
    "        'database' : 'gjquant' ,\n",
    "    },\n",
    "}\n",
    "\n",
    "data_start_dt = {\n",
    "    'haitong':{'hf_factors': 20130101,\n",
    "               'dl_factors': 20161230},\n",
    "    'dongfang':{'hfq_chars'     : 20050101 ,\n",
    "                'l2_chars'      : 20130930 ,\n",
    "                'ms_chars'      : 20050101 ,\n",
    "                'order_flow'    : 20130930 ,\n",
    "                'gp'            : 20170101 ,\n",
    "                'tra'           : 20200101} ,\n",
    "    'kaiyuan':{\n",
    "        'positive': 20140130,\n",
    "        'negative': 20140130},\n",
    "    'guojin':{}\n",
    "}\n",
    "query_params = {\n",
    "    'haitong':{'hf_factors':{}, 'dl_factors':{},},\n",
    "    'dongfang':{'hfq_chars' :{'date_col':'tradingdate','date_fmt':'%Y%m%d'},\n",
    "                'l2_chars'  :{'date_col':'trade_date' ,'date_fmt':'%Y%m%d'},\n",
    "                'ms_chars'  :{'date_col':'trade_date' ,'date_fmt':'%Y%m%d'},\n",
    "                'order_flow':{'date_col':'trade_date' ,'date_fmt':'%Y%m%d'},\n",
    "                'gp'        :{'date_col':'tradingdate','date_fmt':'%Y-%m-%d'},\n",
    "                'tra'       :{'date_col':'tradingdate','date_fmt':'%Y-%m-%d'},\n",
    "                'scores_v0' :{'date_col':'tradingdate','date_fmt':'%Y-%m-%d'},\n",
    "                } ,\n",
    "    'kaiyuan':{\n",
    "        'positive':{'factors' : \n",
    "                    ['active_trading','apm','opt_synergy_effect','large_trader_ret_error',\n",
    "                     'offense_defense','high_freq_shareholder','pe_change',],},\n",
    "        'negative':{'factors' : \n",
    "                    ['smart_money','ideal_vol','ideal_reverse','herd_effect','small_trader_ret_error',],},\n",
    "        # +1 : 'traction_f' , 'traction_ns' , 'traction_si', , 'long_momentum2' , 'merge_sue', 'consensus_adjustment',\n",
    "    },\n",
    "    'guojin':{},\n",
    "}\n",
    "\n",
    "# class online_sql_connector\n",
    "class online_sql_connector():\n",
    "    def __init__(self):\n",
    "        self.connect_dict = connect_dict\n",
    "        self.engines = dict()\n",
    "        self.connections = dict()\n",
    "        self.data_start_dt = data_start_dt\n",
    "        self.query_params = query_params\n",
    "        [self.create_engines(src) for src in self.connect_dict.keys()]\n",
    "\n",
    "    def create_engines(self , srcs):\n",
    "        if not isinstance(srcs , (list,tuple)): srcs = [srcs]\n",
    "        for src in srcs:\n",
    "            self.engines[src] = self._single_engine(self.connect_dict[src])\n",
    "            \n",
    "    def create_connections(self , srcs):\n",
    "        if not isinstance(srcs , (list,tuple)): srcs = [srcs]\n",
    "        for src in srcs:\n",
    "            if self.connections.get(src) is not None:\n",
    "                self.connections.get(src).close()\n",
    "            self.connections[src] = self.engines[src].connect()\n",
    "\n",
    "    def close_all(self):\n",
    "        [connection.close() for _,connection in self.connections.items()]\n",
    "        \n",
    "    def _single_engine(self , src_dict):\n",
    "        connect_url = '{dialect}://{username}:{password}@{host}:{port}/{database}'.format(\n",
    "            dialect  = src_dict['dialect'],\n",
    "            username = src_dict['username'],\n",
    "            password = src_dict['password'],\n",
    "            host     = src_dict['host'],\n",
    "            port     = src_dict['port'],\n",
    "            database = src_dict['database'],\n",
    "        )\n",
    "        \n",
    "        if src_dict.get('driver'): connect_url += f'?driver={src_dict.get(\"driver\")}'\n",
    "        return create_engine(connect_url)\n",
    "    \n",
    "    def _single_default_query(self , src , query_type , start_dt , end_dt):\n",
    "        assert query_type in self.query_params[src].keys()\n",
    "        if src == 'haitong':\n",
    "            if query_type == 'hf_factors':\n",
    "                query = '''\n",
    "                select *  \n",
    "                from daily_factor_db.dbo.JSJJHFFactors t \n",
    "                where t.trade_dt between \\'{}\\' and \\'{}\\'\n",
    "                '''.format(start_dt , end_dt)\n",
    "            else:\n",
    "                query = '''\n",
    "                select s_info_windcode , trade_dt , f_value , model \n",
    "                from daily_factor_db.dbo.JSJJDeepLearnFactorsV2 t \n",
    "                where t.trade_dt between \\'{}\\' and \\'{}\\'\n",
    "                '''.format(start_dt , end_dt)\n",
    "        elif src == 'dongfang':\n",
    "            date_col = self.query_params[src][query_type]['date_col']\n",
    "            date_fmt = self.query_params[src][query_type]['date_fmt']\n",
    "            query = '''\n",
    "            select *  \n",
    "            from {} t \n",
    "            where t.{} between \\'{}\\' and \\'{}\\'\n",
    "            '''.format(query_type , date_col , \n",
    "                        datetime.strptime(str(start_dt) , '%Y%m%d').strftime(date_fmt) ,\n",
    "                        datetime.strptime(str(end_dt) , '%Y%m%d').strftime(date_fmt))\n",
    "        elif src == 'kaiyuan':\n",
    "            query = {v:f'select * from public.{v} where date >= \\'{start_dt}\\' and date <= \\'{end_dt}\\''\n",
    "                    for v in self.query_params[src][query_type]['factors']}\n",
    "        elif src == 'guojin':\n",
    "            query = 'select * from gjquant.factordescription'\n",
    "        return query\n",
    "    \n",
    "    def query_start_dt(self , src , query_type):\n",
    "        assert query_type in self.query_params[src].keys()\n",
    "        if src == 'haitong':\n",
    "            if query_type == 'hf_factors':\n",
    "                query = 'select min(trade_dt) from daily_factor_db.dbo.JSJJHFFactors'\n",
    "            else:\n",
    "                query = 'select min(trade_dt) daily_factor_db.dbo.JSJJDeepLearnFactorsV2'\n",
    "        elif src == 'dongfang':\n",
    "            date_col = self.query_params[src][query_type]['date_col']\n",
    "            query = 'select min({}) from {}'.format(date_col , query_type)\n",
    "        elif src == 'kaiyuan':\n",
    "            query = 'select min(date) from public.smart_money'\n",
    "        elif src == 'guojin':\n",
    "            return 99991231\n",
    "        return pd.read_sql_query(query , self.connections[src])\n",
    "\n",
    "    def default_query(self , src , query_type , start_dt = 20231101, end_dt = 20231103):\n",
    "        query = self._single_default_query(src , query_type , start_dt , end_dt)\n",
    "        if src not in self.connections.keys(): self.create_connections(src)\n",
    "        try:\n",
    "            if src == 'kaiyuan':\n",
    "                df = {k:pd.read_sql_query(q , self.connections[src]) for k,q in query.items()}\n",
    "            else:\n",
    "                df = pd.read_sql_query(query , self.connections[src])\n",
    "        except exc.ResourceClosedError:\n",
    "            print(f'{src} Connection is closed, re-connect')\n",
    "            self.create_connections(src)\n",
    "            if src == 'kaiyuan':\n",
    "                pass\n",
    "            else:\n",
    "                df = pd.read_sql_query(query , self.connections[src])\n",
    "        except:\n",
    "            raise Exception\n",
    "        df = self.df_process(df , src , query_type)\n",
    "        return df\n",
    "    \n",
    "    def df_process(self , df , src , query_type):\n",
    "        if src == 'haitong':\n",
    "            df.columns = map(str.lower , df.columns)\n",
    "            df = df.rename(columns={'s_info_windcode':'secid','trade_dt':'date'})\n",
    "            df['date'] = df['date'].astype(int)\n",
    "            df['secid'] = self._IDconvert(df['secid'])\n",
    "            if query_type == 'hf_factors':\n",
    "                df = df.reset_index(drop = True)\n",
    "            else:\n",
    "                df.loc[:,'model'] = 'haitong_dl_' + df.loc[:,'model'].astype(str)\n",
    "                df = df.pivot_table('f_value',['date','secid'],'model').reset_index()\n",
    "        elif src == 'dongfang':\n",
    "            df.columns = map(str.lower , df.columns)\n",
    "            df = df.rename(columns={'stockcode':'secid','ticker':'secid',\n",
    "                                    'tradingdate':'date','trade_dt':'date' , 'trade_date':'date'})\n",
    "            df['secid'] = df['secid'].str.replace('[-.a-zA-Z]','',regex=True).astype(int)\n",
    "            df['date'] = df['date'].astype(str).str.replace('-','').astype(int)\n",
    "        elif src == 'kaiyuan':\n",
    "            df0 = pd.DataFrame(columns = ['date','code'])\n",
    "            for k,subdf in df.items():\n",
    "                subdf.rename(columns = {'factor':k})\n",
    "                # print(subdf.iloc[:5])\n",
    "                df0 = df0.merge(subdf.rename(columns = {'factor':k}),how='outer',on=['date','code'])\n",
    "            df = df0.rename(columns={'code':'secid'})\n",
    "            df['secid'] = df['secid'].str.replace('[-.a-zA-Z]','',regex=True).astype(int)\n",
    "            df['date']  = df['date'].astype(int)\n",
    "            df = df.set_index(['date','secid']).reset_index()\n",
    "        elif src == 'guojin':\n",
    "            pass\n",
    "        return df.fillna(np.nan)\n",
    "    \n",
    "    def _IDconvert(self , x):\n",
    "        if isinstance(x , (bytes)):\n",
    "            return int(x.decode('utf-8').split('.')[0].split('!')[0])\n",
    "        if isinstance(x , (str)):\n",
    "            return int(x.split('.')[0].split('!')[0])\n",
    "        else:\n",
    "            return type(x)([self._IDconvert(xx) for xx in x])\n",
    "\n",
    "    def download_since(self , dir , src , query_type , start_dt , end_dt , ask = True):\n",
    "        os.makedirs(dir , exist_ok= True)\n",
    "        file_name = os.path.join(dir , src , query_type , query_type + '_{}.pkl')\n",
    "        os.makedirs(os.path.dirname(file_name) , exist_ok= True)\n",
    "        end_dt = min(end_dt , int(date.today().strftime('%Y%m%d')))\n",
    "        if end_dt < start_dt: return\n",
    "\n",
    "        freq = 'Q'\n",
    "        date_segs = self.date_seg(start_dt , end_dt , freq = freq)\n",
    "        prompt = f'since {start_dt} to {end_dt}, total {len(date_segs)} periods({freq})'\n",
    "        if ask:\n",
    "            assert input(prompt + ', print \"yes\" to confirm!') == 'yes'\n",
    "        else:\n",
    "            print(prompt)\n",
    "\n",
    "        for (s , e) in date_segs:\n",
    "            data = self.default_query(src , query_type , s , e)\n",
    "            data = data.sort_values(['date' , 'secid']).set_index('date')\n",
    "            for d in data.index.unique():\n",
    "                data.loc[d].to_pickle(file_name.format(d))\n",
    "            print(f'{time.ctime()} : {src}:{query_type}:{s // 100}{\" \"*20}' , end='\\r')\n",
    "        print('\\n')\n",
    "\n",
    "    def date_seg(self , start_dt , end_dt , freq='Q'):\n",
    "        dt_list = pd.date_range(str(start_dt) , str(end_dt) , freq=freq).strftime('%Y%m%d').astype(int)\n",
    "        dt_starts = [start_dt , *self.numdate_offset(dt_list[:-1],1)]\n",
    "        dt_ends = [*dt_list[:-1] , end_dt]\n",
    "        return [(s,e) for s,e in zip(dt_starts , dt_ends)]\n",
    "    \n",
    "    def numdate_offset(self , date , offset):\n",
    "        if offset == 0:\n",
    "            return date\n",
    "        else:\n",
    "            if isinstance(date , (np.ndarray,pd.Index , pd.Series)):\n",
    "                return (pd.DatetimeIndex(date.astype(str))+pd.DateOffset(offset)).strftime('%Y%m%d').astype(int).values\n",
    "            else:\n",
    "                return (pd.DatetimeIndex([str(date)])+pd.DateOffset(offset)).strftime('%Y%m%d').astype(int)[0]\n",
    "                \n",
    "\n",
    "connector = online_sql_connector()\n",
    "DIR = 'test_data'\n",
    "start_dt = 20230101\n",
    "end_dt = 20230110\n",
    "try:\n",
    "    for src in connector.query_params.keys():\n",
    "        for qtype in connector.query_params[src].keys():\n",
    "            print('/'.join([src,qtype]))\n",
    "            connector.download_since(DIR,src,qtype,start_dt,end_dt,ask=False)\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ab-cc.c2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-ba.ccc4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a\n",
       "0  ab-cc.c2\n",
       "1  -ba.ccc4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "a = pd.DataFrame({'a':['ab-cc.c2','-ba.ccc4']})\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    00000002\n",
       "1    00000004\n",
       "Name: a, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = a['a'].str.replace('[-.a-zA-Z]','0',regex=True)\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
