{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main path: /Users/mengkjin/workspace/learndl\n",
      "src.INSTANCE_RECORD can be accessed to check ['trainer', 'account', 'factor']\n"
     ]
    }
   ],
   "source": [
    "from src.algo.nn.model import TemporalFusionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ–¥ï¸  ç³»ç»Ÿ: Darwin arm64\n",
      "ðŸ PyTorchç‰ˆæœ¬: 2.2.2\n",
      "ðŸ”¥ MPSå¯ç”¨: True\n",
      "ðŸ”¥ MPSæž„å»º: True\n",
      "âœ… Apple Silicon Mac - æ”¯æŒMPSåŠ é€Ÿ\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import platform\n",
    "\n",
    "print(f\"ðŸ–¥ï¸  ç³»ç»Ÿ: {platform.system()} {platform.machine()}\")\n",
    "print(f\"ðŸ PyTorchç‰ˆæœ¬: {torch.__version__}\")\n",
    "print(f\"ðŸ”¥ MPSå¯ç”¨: {torch.backends.mps.is_available()}\")\n",
    "print(f\"ðŸ”¥ MPSæž„å»º: {torch.backends.mps.is_built()}\")\n",
    "\n",
    "# å¦‚æžœæ˜¯Apple Silicon\n",
    "if platform.machine() == 'arm64':\n",
    "    print(\"âœ… Apple Silicon Mac - æ”¯æŒMPSåŠ é€Ÿ\")\n",
    "else:\n",
    "    print(\"â„¹ï¸  Intel Mac - å¯èƒ½éœ€è¦å…¶ä»–åŠ é€Ÿæ–¹æ¡ˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main path: /Users/mengkjin/workspace/learndl\n",
      "src.INSTANCE_RECORD can be accessed to check ['trainer', 'account', 'factor']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'simple_lstm': src.algo.nn.model.Recurrent.simple_lstm,\n",
       " 'gru': src.algo.nn.model.Recurrent.gru,\n",
       " 'lstm': src.algo.nn.model.Recurrent.lstm,\n",
       " 'resnet_lstm': src.algo.nn.model.Recurrent.resnet_lstm,\n",
       " 'resnet_gru': src.algo.nn.model.Recurrent.resnet_gru,\n",
       " 'transformer': src.algo.nn.model.Recurrent.transformer,\n",
       " 'tcn': src.algo.nn.model.Recurrent.tcn,\n",
       " 'rnn_ntask': src.algo.nn.model.Recurrent.rnn_ntask,\n",
       " 'rnn_general': src.algo.nn.model.Recurrent.rnn_general,\n",
       " 'gru_dsize': src.algo.nn.model.Recurrent.gru_dsize,\n",
       " 'patch_tst': src.algo.nn.model.PatchTST.patch_tst,\n",
       " 'modern_tcn': src.algo.nn.model.ModernTCN.modern_tcn,\n",
       " 'ts_mixer': src.algo.nn.model.TSMixer.ts_mixer,\n",
       " 'tra': src.algo.nn.model.TRA.tra,\n",
       " 'factor_vae': src.algo.nn.model.FactorVAE.FactorVAE,\n",
       " 'risk_att_gru': src.algo.nn.model.RiskAttGRU.risk_att_gru,\n",
       " 'ple_gru': src.algo.nn.model.PLE.ple_gru,\n",
       " 'tft': src.algo.nn.model.TemporalFusionTransformer.TemporalFusionTransformer,\n",
       " 'lgbm': src.algo.boost.booster.lgbm.Lgbm,\n",
       " 'ada': src.algo.boost.booster.ada.AdaBoost,\n",
       " 'xgboost': src.algo.boost.booster.xgboost.XgBoost,\n",
       " 'catboost': src.algo.boost.booster.catboost.CatBoost}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.api import ModelAPI  \n",
    "ModelAPI.Trainer.available_modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'ModelAPI' has no attribute 'short_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelAPI  \n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m app = \u001b[43mModelAPI\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshort_test\u001b[49m(module = \u001b[33m'\u001b[39m\u001b[33mgru\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: type object 'ModelAPI' has no attribute 'short_test'"
     ]
    }
   ],
   "source": [
    "from src.api import ModelAPI  \n",
    "app = ModelAPI.short_test(module = 'gru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.api import ModelAPI\n",
    "ModelAPI.clear_st_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InstanceRecord(names=['trainer', 'account'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src import INSTANCE_RECORD\n",
    "INSTANCE_RECORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name is None, update all hidden models\n",
      "{'name': 'gru_day', 'nums': None, 'submodels': ['best']}\n",
      "Beware! Should be at server or short_test, but short_test is False now!\n",
      "try using d:\\Coding\\learndl\\learndl\\data\\DataSet/day.20240607.pt , success!\n",
      "Load  2 DataBlocks...... finished! Cost 0.08 secs\n",
      "Align 2 DataBlocks...... finished! Cost 0.21 secs\n",
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 316/316 [00:00<00:00, 2933.69it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 316/316 [00:00<00:00, 3047.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.model.model_module.application.extractor.ModelHiddenExtractor at 0x1bcbb3520d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.api import ModelAPI\n",
    "ModelAPI.Extractor.update()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.basic.INSTANCE_RECORD can be accessed to check ['trainer', 'account']\n",
      "Basic module imported!\n",
      "Use device name: NVIDIA GeForce RTX 4090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[44m24-12-15 18:40:32|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mModel Specifics:\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-12-15 18:40:32|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Data] at Sun Dec 15 18:40:32 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "**************************** RECONSTRUCT TRAIN DATA ****************************\n",
      "predict is False , Data Processing start!\n",
      "6 datas : ['y', 'day', '30m', 'style', 'indus', 'week'] , from 20070101 to None\n",
      "y is up to 20241215121914 already!\n",
      "day is up to 20241215122636 already!\n",
      "30m is up to 20241215122719 already!\n",
      "style is up to 20241215124444 already!\n",
      "indus is up to 20241215124618 already!\n",
      "week is up to 20241215124746 already!\n",
      "Data Processing Finished! Cost 0.00 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "******************************** UPDATE MODELS ********************************\n",
      "--------------------------------------------------------------------------------\n",
      "***************************** PARSER TRAINING ARGS *****************************\n",
      "--Process Queue : Data + Fit + Test\n",
      "--Confirm Resume Training!\n",
      "--Model_name is set to gru_day!\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "******************************* SETUP CALLBACKS *******************************\n",
      "ResetOptimizer(num_reset=2,trigger=40,recover_level=1.0,speedup2x=True) , reset optimizer on some epoch (can speedup scheduler)\n",
      "CallbackTimer(verbosity=2) , record time cost of callback hooks\n",
      "EarlyStoppage(patience=20) , stop fitting when validation score cease to improve\n",
      "ValidationConverge(patience=5,eps=1e-05) , stop fitting when valid_score converge\n",
      "EarlyExitRetrain(earliest=10,max_attempt=4,lr_multiplier=[1, 0.1, 10, 0.01, 100, 1]) , retrain with new lr if fitting stopped too early\n",
      "NanLossRetrain(max_attempt=4) , retrain if fitting encounters nan loss\n",
      "BatchDisplay(verbosity=2) , display batch progress bar\n",
      "StatusDisplay(verbosity=2) , display epoch and event information\n",
      "DetailedAlphaAnalysis(use_num=avg)\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "********************************** MODEL INFO **********************************\n",
      "Model Name   : gru_day\n",
      "Model Module : gru\n",
      "  -->  Model Params :\n",
      "    -->  hidden_dim : [32, 64]\n",
      "    -->  seqlens : [{'day': 30, '30m': 30, 'dms': 30}]\n",
      "    -->  tra_seqlens : [{'hist_loss': 40}]\n",
      "    -->  dropout : [0.1]\n",
      "    -->  enc_in : [True]\n",
      "    -->  enc_att : [False]\n",
      "    -->  rnn_type : ['lstm']\n",
      "    -->  rnn_att : [False]\n",
      "    -->  rnn_layers : [2]\n",
      "    -->  dec_mlp_layers : [2]\n",
      "    -->  num_output : [1]\n",
      "    -->  kernel_size : [3]\n",
      "    -->  hidden_as_factor : [False]\n",
      "    -->  ordered_param_group : [False]\n",
      "    -->  tra_num_states : [5]\n",
      "    -->  verbosity : 2\n",
      "Model Inputs : data\n",
      "  -->  Data Types : ['day']\n",
      "Model Labels : ['std_lag1_10']\n",
      "Model Period : 20170103 ~ 99991231\n",
      "Sampling     : sequential\n",
      "Shuffling    : epoch\n",
      "Random Seed  : None\n",
      "--------------------------------------------------------------------------------\n",
      "try using /home/mengkjin/Workspace/learndl/data/Interim/DataSet/day.20241128.pt , success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-12-15 18:40:36|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Data], Cost 3.7 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-12-15 18:40:36|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Fit] at Sun Dec 15 18:40:36 2024!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-12-15 18:40:36|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Fit], Cost 0.0 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-12-15 18:40:36|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Test] at Sun Dec 15 18:40:36 2024!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-12-15 18:40:36|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mTesting Mean Score(spearman):\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-12-15 18:40:36|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Test], Cost 0.0 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-12-15 18:40:36|MOD:timer       |\u001b[0m: \u001b[1m\u001b[31mMain Process Finished! Cost 3.8 Seconds\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-12-15 18:40:36|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mModel Specifics:\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-12-15 18:40:36|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Data] at Sun Dec 15 18:40:36 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n",
      "--------------------------------------------------------------------------------\n",
      "***************************** PARSER TRAINING ARGS *****************************\n",
      "--Process Queue : Data + Fit + Test\n",
      "--Confirm Resume Training!\n",
      "--Model_name is set to gruRTN_day!\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "******************************* SETUP CALLBACKS *******************************\n",
      "ResetOptimizer(num_reset=2,trigger=40,recover_level=1.0,speedup2x=True) , reset optimizer on some epoch (can speedup scheduler)\n",
      "CallbackTimer(verbosity=2) , record time cost of callback hooks\n",
      "EarlyStoppage(patience=20) , stop fitting when validation score cease to improve\n",
      "ValidationConverge(patience=5,eps=1e-05) , stop fitting when valid_score converge\n",
      "EarlyExitRetrain(earliest=10,max_attempt=4,lr_multiplier=[1, 0.1, 10, 0.01, 100, 1]) , retrain with new lr if fitting stopped too early\n",
      "NanLossRetrain(max_attempt=4) , retrain if fitting encounters nan loss\n",
      "BatchDisplay(verbosity=2) , display batch progress bar\n",
      "StatusDisplay(verbosity=2) , display epoch and event information\n",
      "DetailedAlphaAnalysis(use_num=avg)\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "********************************** MODEL INFO **********************************\n",
      "Model Name   : gruRTN_day\n",
      "Model Module : gru\n",
      "  -->  Model Params :\n",
      "    -->  hidden_dim : [32, 64]\n",
      "    -->  seqlens : [{'day': 30, '30m': 30, 'dms': 30}]\n",
      "    -->  tra_seqlens : [{'hist_loss': 40}]\n",
      "    -->  dropout : [0.1]\n",
      "    -->  enc_in : [True]\n",
      "    -->  enc_att : [False]\n",
      "    -->  rnn_type : ['lstm']\n",
      "    -->  rnn_att : [False]\n",
      "    -->  rnn_layers : [2]\n",
      "    -->  dec_mlp_layers : [2]\n",
      "    -->  num_output : [1]\n",
      "    -->  kernel_size : [3]\n",
      "    -->  hidden_as_factor : [False]\n",
      "    -->  ordered_param_group : [False]\n",
      "    -->  tra_num_states : [5]\n",
      "    -->  verbosity : 2\n",
      "Model Inputs : data\n",
      "  -->  Data Types : ['day']\n",
      "Model Labels : ['rtn_lag1_10']\n",
      "Model Period : 20170103 ~ 99991231\n",
      "Sampling     : sequential\n",
      "Shuffling    : epoch\n",
      "Random Seed  : None\n",
      "--------------------------------------------------------------------------------\n",
      "try using /home/mengkjin/Workspace/learndl/data/Interim/DataSet/day.20241128.pt , success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-12-15 18:40:40|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Data], Cost 3.7 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-12-15 18:40:40|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Fit] at Sun Dec 15 18:40:40 2024!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-12-15 18:40:40|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Fit], Cost 0.0 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-12-15 18:40:40|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Test] at Sun Dec 15 18:40:40 2024!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-12-15 18:40:40|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mTesting Mean Score(spearman):\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-12-15 18:40:40|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Test], Cost 0.0 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-12-15 18:40:40|MOD:timer       |\u001b[0m: \u001b[1m\u001b[31mMain Process Finished! Cost 3.7 Seconds\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-12-15 18:40:40|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mModel Specifics:\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-12-15 18:40:40|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Data] at Sun Dec 15 18:40:40 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n",
      "--------------------------------------------------------------------------------\n",
      "***************************** PARSER TRAINING ARGS *****************************\n",
      "--Process Queue : Data + Fit + Test\n",
      "--Confirm Resume Training!\n",
      "--Model_name is set to gru_avg!\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "******************************* SETUP CALLBACKS *******************************\n",
      "ResetOptimizer(num_reset=2,trigger=40,recover_level=1.0,speedup2x=True) , reset optimizer on some epoch (can speedup scheduler)\n",
      "CallbackTimer(verbosity=2) , record time cost of callback hooks\n",
      "EarlyStoppage(patience=20) , stop fitting when validation score cease to improve\n",
      "ValidationConverge(patience=5,eps=1e-05) , stop fitting when valid_score converge\n",
      "EarlyExitRetrain(earliest=10,max_attempt=4,lr_multiplier=[1, 0.1, 10, 0.01, 100, 1]) , retrain with new lr if fitting stopped too early\n",
      "NanLossRetrain(max_attempt=4) , retrain if fitting encounters nan loss\n",
      "BatchDisplay(verbosity=2) , display batch progress bar\n",
      "StatusDisplay(verbosity=2) , display epoch and event information\n",
      "DetailedAlphaAnalysis(use_num=avg)\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "********************************** MODEL INFO **********************************\n",
      "Model Name   : gru_avg\n",
      "Model Module : gru\n",
      "  -->  Model Params :\n",
      "    -->  hidden_dim : [32, 32, 32, 32, 32]\n",
      "    -->  seqlens : [{'day': 30, '30m': 30}]\n",
      "    -->  dropout : [0.1]\n",
      "    -->  enc_in : [True]\n",
      "    -->  enc_att : [False]\n",
      "    -->  rnn_type : ['gru']\n",
      "    -->  rnn_att : [False]\n",
      "    -->  rnn_layers : [2]\n",
      "    -->  dec_mlp_layers : [2]\n",
      "    -->  num_output : [1]\n",
      "    -->  which_output : [0]\n",
      "    -->  kernel_size : [3]\n",
      "    -->  hidden_as_factor : [True]\n",
      "    -->  ordered_param_group : [False]\n",
      "    -->  verbosity : 2\n",
      "Model Inputs : data\n",
      "  -->  Data Types : ['day']\n",
      "Model Labels : ['std_lag1_10']\n",
      "Model Period : 20170103 ~ 99991231\n",
      "Sampling     : sequential\n",
      "Shuffling    : epoch\n",
      "Random Seed  : None\n",
      "--------------------------------------------------------------------------------\n",
      "try using /home/mengkjin/Workspace/learndl/data/Interim/DataSet/day.20241128.pt , success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-12-15 18:40:44|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Data], Cost 3.7 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-12-15 18:40:44|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Fit] at Sun Dec 15 18:40:44 2024!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-12-15 18:40:44|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Fit], Cost 0.0 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-12-15 18:40:44|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Test] at Sun Dec 15 18:40:44 2024!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-12-15 18:40:44|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mTesting Mean Score(spearman):\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-12-15 18:40:44|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Test], Cost 0.0 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-12-15 18:40:44|MOD:timer       |\u001b[0m: \u001b[1m\u001b[31mMain Process Finished! Cost 3.7 Seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.api import ModelAPI\n",
    "\n",
    "ModelAPI.update_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
