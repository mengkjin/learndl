{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.api import ModelAPI\n",
    "model = ModelAPI.Testor('ts_mixer')\n",
    "model.try_forward()\n",
    "model.try_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict is False , Data Processing start!\n",
      "1 datas :['week']\n",
      "week blocks loading start!\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 33.25 secs\n",
      "week blocks loading finished! Cost 33.27 secs\n",
      "week blocks process...... finished! Cost 245.89 secs\n",
      "week blocks masking...... finished! Cost 5.20 secs\n",
      "week blocks saving ...... finished! Cost 56.84 secs\n",
      "week blocks norming...... finished! Cost 45.30 secs\n",
      "week finished! Cost 388.05 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "Data Processing Finished! Cost 388.05 Seconds\n",
      "predict is True , Data Processing start!\n",
      "1 datas :['week']\n",
      "week blocks loading start!\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 3.37 secs\n",
      "week blocks loading finished! Cost 3.38 secs\n",
      "week blocks process...... finished! Cost 1.65 secs\n",
      "week blocks masking...... finished! Cost 0.22 secs\n",
      "week blocks saving ...... finished! Cost 2.59 secs\n",
      "week blocks norming...... finished! Cost 0.00 secs\n",
      "week finished! Cost 7.94 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "Data Processing Finished! Cost 7.94 Seconds\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.api import DataAPI\n",
    "DataAPI.reconstruct_train_data('week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load  2 DataBlocks...... finished! Cost 0.59 secs\n",
      "Align 2 DataBlocks...... finished! Cost 2.12 secs\n",
      "Pre-Norming method of [week] : {'divlast': False, 'histnorm': True}\n"
     ]
    }
   ],
   "source": [
    "from src.api import DataAPI\n",
    "batch_data = DataAPI.get_realistic_batch_data('week')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5057, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from src.nn_model.nn import layer as Layer\n",
    "\n",
    "class ple_gru(nn.Module):\n",
    "    '''\n",
    "    Progressive Layered Extraction\n",
    "    '''\n",
    "    def __init__(\n",
    "            self, \n",
    "            input_dim    = 6 ,\n",
    "            hidden_dim   = 2**5,\n",
    "            dropout      = 0.1,\n",
    "            act_type     = 'leaky',\n",
    "            expert_layers = 2 ,\n",
    "            rnn_layers   = 2 ,\n",
    "            num_output   = 2 ,\n",
    "            **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        assert num_output > 1 and num_output < 5 , num_output\n",
    "        assert expert_layers >= 2 , expert_layers\n",
    "        \n",
    "        self.expert_layers = expert_layers\n",
    "        self.num_output = num_output\n",
    "\n",
    "        layers = []\n",
    "        for i in range(expert_layers):\n",
    "            layers.append(ExpertLayer(\n",
    "                input_dim = input_dim , \n",
    "                hidden_dim = hidden_dim , \n",
    "                first_layer = i == 0 , \n",
    "                dropout = dropout , \n",
    "                rnn_layers = rnn_layers , \n",
    "                num_output = num_output))\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "        self.heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                Layer.Act.get_activation_fn(act_type),\n",
    "                nn.Linear(hidden_dim , 1) , \n",
    "                nn.BatchNorm1d(1)\n",
    "            ) for _ in range(num_output)\n",
    "        ])\n",
    "\n",
    "    def forward(self , x):\n",
    "        shared_output , task_outputs = None , []\n",
    "        for layer in self.layers:\n",
    "            shared_output , task_outputs = layer(x , shared_output , task_outputs)\n",
    "        z = torch.concat([head(output[:,-1]) for head , output in zip(self.heads , task_outputs)] , dim = -1)\n",
    "        return z\n",
    "    \n",
    "class ExpertLayer(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            input_dim    = 6 ,\n",
    "            hidden_dim   = 2**5,\n",
    "            first_layer  = True ,\n",
    "            dropout      = 0.1,\n",
    "            rnn_layers   = 2 ,\n",
    "            num_output   = 2 ,\n",
    "            **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.first_layer = first_layer\n",
    "        expert_dim = input_dim if first_layer else hidden_dim\n",
    "\n",
    "        self.shared_expert = ExpertNetwork(expert_dim , hidden_dim , rnn_layers , dropout)\n",
    "        self.task_experts = nn.ModuleList([ExpertNetwork(expert_dim , hidden_dim , rnn_layers , dropout) for i in range(num_output)])\n",
    "        self.shared_gate = GatingNetwork(input_dim , 1 + num_output , rnn_layers , dropout)\n",
    "        self.task_gates = nn.ModuleList([GatingNetwork(input_dim , 2 , rnn_layers , dropout) for i in range(num_output)])\n",
    "        \n",
    "    def forward(self , x , *vecs):\n",
    "        if self.first_layer:\n",
    "            shared_vector = self.shared_expert(x)\n",
    "            task_vectors  = [expert(x) for expert in self.task_experts]\n",
    "        else:\n",
    "            shared_input , tasks_inputs = vecs\n",
    "            shared_vector = self.shared_expert(shared_input)\n",
    "            task_vectors  = [expert(input) for expert , input in zip(self.task_experts , tasks_inputs)]\n",
    "\n",
    "        shared_output = self.shared_gate(x , shared_vector , *task_vectors)\n",
    "        task_outputs  = [gate(x , shared_vector , vector) for gate , vector  in zip(self.task_gates , task_vectors)]\n",
    "        return shared_output , task_outputs\n",
    "    \n",
    "class GatingNetwork(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            selector_dim = 6 ,\n",
    "            feature_dim  = 2 ,\n",
    "            num_layers = 1 , \n",
    "            dropout = 0.1 ,\n",
    "            **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.selector = nn.GRU(selector_dim , feature_dim , num_layers , batch_first=True , dropout=dropout)\n",
    "        self.softmax = nn.Softmax(dim = -1)\n",
    "\n",
    "    def forward(self , x , *vecs):\n",
    "        v = self.selector(x)[0][:,-1]\n",
    "        v = self.softmax(v)\n",
    "        v = torch.stack([v[:,i].reshape(-1,1,1) * vec for i , vec in enumerate(vecs)] , dim = 0).sum(0)\n",
    "        return v\n",
    "    \n",
    "class ExpertNetwork(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            input_dim = 6 ,\n",
    "            hidden_dim  = 2**5 ,\n",
    "            num_layers = 1 , \n",
    "            dropout = 0.1 ,\n",
    "            **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.expert = nn.GRU(input_dim , hidden_dim , num_layers , batch_first=True , dropout=dropout)\n",
    "\n",
    "    def forward(self , x):\n",
    "        return self.expert(x)[0]\n",
    "\n",
    "net = ple_gru(expert_layers=3)\n",
    "net(batch_data.x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
