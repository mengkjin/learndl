{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False 2.2.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available() , torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is method abc2\n",
      "aaa\n"
     ]
    }
   ],
   "source": [
    "def decor(f):\n",
    "    def wrapper():\n",
    "        f()\n",
    "        print('aaa')\n",
    "    return wrapper\n",
    "\n",
    "class MyClass:\n",
    "    def __init__(self):\n",
    "        # 定义动态方法\n",
    "        self.decor = decor\n",
    "        setattr(self, 'abc', self.decor(self.abc))\n",
    "\n",
    "    def abc(self):\n",
    "        print(\"This is method abc\")\n",
    "\n",
    "class MyClass2(MyClass):\n",
    "    def abc(self):\n",
    "        print(\"This is method abc2\")\n",
    "\n",
    "# 创建类实例\n",
    "obj = MyClass2()\n",
    "\n",
    "# 调用动态方法\n",
    "obj.abc()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[44m24-05-21 21:24:53|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mModel Specifics:\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-21 21:24:53|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Data] at Tue May 21 21:24:53 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Process Queue : Data + Fit + Test\n",
      "--Model_name is set to gru_lgbm_ShortTest!\n",
      "Callback : DynamicDataLink() , assign and unlink dynamic data in tra networks\n",
      "Callback : ResetOptimizer(num_reset=2,trigger=40,recover_level=1.0,speedup2x=True) , reset optimizer on some epoch (can speedup scheduler)\n",
      "Callback : CallbackTimer(verbosity=10) , record time cost of callback hooks\n",
      "Callback : EarlyStoppage(patience=20) , stop fitting when validation score cease to improve\n",
      "Callback : ValidationConverge(patience=5,eps=1e-05) , stop fitting when valid_score converge\n",
      "Callback : EarlyExitRetrain(earliest=10,max_attempt=4,lr_multiplier=[1, 0.1, 10, 0.01, 100, 1]) , retrain with new lr if fitting stopped too early\n",
      "Callback : NanLossRetrain(max_attempt=4) , retrain if fitting encounters nan loss\n",
      "Callback : BatchDisplay(verbosity=10) , display batch progress bar\n",
      "Callback : StatusDisplay(verbosity=10) , display epoch and event information\n",
      "{'random_seed': None,\n",
      " 'model_name': 'gru_lgbm_ShortTest',\n",
      " 'model_module': 'gru',\n",
      " 'model_data_type': 'day',\n",
      " 'beg_date': 20170103,\n",
      " 'end_date': 20170228,\n",
      " 'sample_method': 'train_shuffle',\n",
      " 'shuffle_option': 'epoch',\n",
      " 'lgbm_ensembler': True}\n",
      "{'hidden_dim': [32],\n",
      " 'seqlens': [{'day': 30, '30m': 30, 'dms': 30}],\n",
      " 'tra_seqlens': [{'hist_loss': 40}],\n",
      " 'dropout': [0.1],\n",
      " 'enc_in': [True],\n",
      " 'enc_att': [False],\n",
      " 'rnn_type': ['gru'],\n",
      " 'rnn_att': [False],\n",
      " 'rnn_layers': [2],\n",
      " 'dec_mlp_layers': [2],\n",
      " 'num_output': [1],\n",
      " 'kernel_size': [3],\n",
      " 'hidden_as_factor': [True],\n",
      " 'ordered_param_group': [False]}\n",
      "use d:\\Coding\\learndl\\learndl\\data\\DataSet/day.20240315.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-05-21 21:24:56|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Data], Cost 3.0 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-21 21:24:56|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Fit] at Tue May 21 21:24:56 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score function of [spearman] calculated and success!\n",
      "loss function of [pearson] calculated and success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Ep#  0 loss : 0.98134: 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Valid Ep#  0 score : 0.06673: 100%|██████████| 10/10 [00:01<00:00,  8.60it/s]\n",
      "\u001b[32mFirstBite Ep#  0 : loss  0.99628, train 0.00685, valid 0.00858, best 0.0086, lr1.3e-03\u001b[0m\n",
      "Train Ep#  1 loss : 0.95637: 100%|██████████| 10/10 [00:08<00:00,  1.12it/s]\n",
      "Valid Ep#  1 score : -0.02383: 100%|██████████| 10/10 [00:01<00:00,  8.51it/s]\n",
      "\u001b[32mFirstBite Ep#  1 : loss  0.97932, train 0.02392, valid 0.03608, best 0.0361, lr2.5e-03\u001b[0m\n",
      "Train Ep#  2 loss : 0.93756: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Valid Ep#  2 score : -0.13844: 100%|██████████| 10/10 [00:01<00:00,  8.13it/s]\n",
      "\u001b[32mFirstBite Ep#  2 : loss  0.95643, train 0.04112, valid 0.05681, best 0.0568, lr3.8e-03\u001b[0m\n",
      "Train Ep#  3 loss : 0.93647: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Valid Ep#  3 score : 0.02695: 100%|██████████| 10/10 [00:01<00:00,  8.66it/s]\n",
      "\u001b[32mFirstBite Ep#  3 : loss  0.94138, train 0.05820, valid 0.05188, best 0.0568, lr5.0e-03\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-21 21:26:08|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mgru_lgbm_ShortTest #0 @20170103|FirstBite Ep#  4 Max Epoch|Train 0.0582 Valid 0.0519 BestVal 0.0568|Cost  1.2Min, 14.0Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-21 21:26:08|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Fit], Cost 0.0 Hours, 1.2 Min/model, 18.0 Sec/Epoch\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-21 21:26:08|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Test] at Tue May 21 21:26:08 2024!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-21 21:26:08|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mEach Model Date Testing Mean Score(spearman):\u001b[0m\n",
      "\u001b[32mModels            0       0       0\u001b[0m\n",
      "\u001b[32mOutput         best swalast swabest\u001b[0m\n",
      "Test best 20170228 score : 0.08832: 100%|██████████| 35/35 [00:05<00:00,  6.64it/s]\n",
      "Test swalast 20170228 score : 0.06649: 100%|██████████| 35/35 [00:05<00:00,  6.50it/s]\n",
      "Test swabest 20170228 score : 0.06940: 100%|██████████| 35/35 [00:05<00:00,  6.54it/s]\n",
      "\u001b[32m20170103     0.1379  0.1324  0.1234\u001b[0m\n",
      "\u001b[32mAllTimeAvg   0.1379  0.1324  0.1234\u001b[0m\n",
      "\u001b[32mAllTimeSum     4.83    4.63    4.32\u001b[0m\n",
      "\u001b[32mStd          0.0468  0.0465  0.0497\u001b[0m\n",
      "\u001b[32mTValue        17.41   16.86   14.68\u001b[0m\n",
      "\u001b[32mAnnIR       14.4197 13.9600 12.1565\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-21 21:26:25|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Test], Cost 16.7 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-21 21:26:25|MOD:time        |\u001b[0m: \u001b[1m\u001b[31mMain Process Finished! Cost 1 Minutes 31.9 Seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    hook_name  num_calls  total_time   avg_time\n",
      "10             on_train_batch         40   37.146631   0.928666\n",
      "21           on_fit_model_end          1   28.109833  28.109833\n",
      "27              on_test_batch        105   15.773787   0.150227\n",
      "15        on_validation_batch         40    4.661100   0.116528\n",
      "4          on_fit_model_start          1    2.073456   2.073456\n",
      "24        on_test_model_start          1    0.645275   0.645275\n",
      "28          on_test_batch_end        105    0.141632   0.001349\n",
      "25   on_test_model_type_start          3    0.055852   0.018617\n",
      "17    on_validation_epoch_end          4    0.038894   0.009724\n",
      "11         on_train_batch_end         40    0.034968   0.000874\n",
      "16    on_validation_batch_end         40    0.031930   0.000798\n",
      "31                on_test_end          1    0.019947   0.019947\n",
      "29     on_test_model_type_end          3    0.007977   0.002659\n",
      "12         on_train_epoch_end          4    0.006020   0.001505\n",
      "6        on_train_epoch_start          4    0.005985   0.001496\n",
      "13  on_validation_epoch_start          4    0.005947   0.001487\n",
      "23              on_test_start          1    0.003989   0.003989\n",
      "32         on_summarize_model          1    0.002991   0.002991\n",
      "0          on_configure_model          1    0.001996   0.001996\n",
      "1               on_data_start          1    0.000998   0.000998\n",
      "30          on_test_model_end          1    0.000998   0.000998\n",
      "26        on_test_batch_start        105    0.000998   0.000010\n",
      "7        on_train_batch_start         40    0.000998   0.000025\n",
      "9           on_after_backward         40    0.000997   0.000025\n",
      "22                 on_fit_end          1    0.000997   0.000997\n",
      "14  on_validation_batch_start         40    0.000996   0.000025\n",
      "18    on_before_fit_epoch_end          4    0.000000   0.000000\n",
      "19           on_fit_epoch_end          4    0.000000   0.000000\n",
      "20       on_before_save_model          1    0.000000   0.000000\n",
      "8          on_before_backward         40    0.000000   0.000000\n",
      "5          on_fit_epoch_start          4    0.000000   0.000000\n",
      "3                on_fit_start          1    0.000000   0.000000\n",
      "2                 on_data_end          1    0.000000   0.000000\n"
     ]
    }
   ],
   "source": [
    "# %% test a specific model\n",
    "from src.interface import ModelTrainer\n",
    "ModelTrainer.main(stage = 0 , resume = 0 , checkname= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.interface import ModelTrainer\n",
    "ModelTrainer.main(stage = 0 , resume = 0 , checkname= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "from src.interface import DataModule\n",
    "DataModule.prepare_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
