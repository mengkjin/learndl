{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False 2.2.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available() , torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[44m24-05-30 19:41:33|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mModel Specifics:\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-30 19:41:33|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Data] at Thu May 30 19:41:33 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Process Queue : Data + Fit + Test\n",
      "--Model_name is set to tra_day.1!\n",
      "Callback : ResetOptimizer(num_reset=2,trigger=40,recover_level=1.0,speedup2x=True) , reset optimizer on some epoch (can speedup scheduler)\n",
      "Callback : CallbackTimer(verbosity=2) , record time cost of callback hooks\n",
      "Callback : EarlyStoppage(patience=20) , stop fitting when validation score cease to improve\n",
      "Callback : ValidationConverge(patience=5,eps=1e-05) , stop fitting when valid_score converge\n",
      "Callback : EarlyExitRetrain(earliest=10,max_attempt=4,lr_multiplier=[1, 0.1, 10, 0.01, 100, 1]) , retrain with new lr if fitting stopped too early\n",
      "Callback : NanLossRetrain(max_attempt=4) , retrain if fitting encounters nan loss\n",
      "Callback : BatchDisplay(verbosity=2) , display batch progress bar\n",
      "Callback : StatusDisplay(verbosity=2) , display epoch and event information\n",
      "Callback : SpecCB_TRA() , in TRA fill [y] [hist_loss] in batch_data.kwargs , update hist_loss in data.buffer\n",
      "{'random_seed': None,\n",
      " 'model_name': 'tra_day.1',\n",
      " 'model_module': 'tra',\n",
      " 'model_data_type': 'day',\n",
      " 'model_types': ['best', 'swalast', 'swabest'],\n",
      " 'labels': ['std_lag1_10', 'std_lag1_20'],\n",
      " 'beg_date': 20170103,\n",
      " 'end_date': 99991231,\n",
      " 'sample_method': 'sequential',\n",
      " 'shuffle_option': 'epoch',\n",
      " 'lgbm_ensembler': False}\n",
      "{'hidden_dim': [32],\n",
      " 'seqlens': [{'day': 30, '30m': 30, 'dms': 30}],\n",
      " 'hist_loss_seq_len': [60],\n",
      " 'hist_loss_horizon': [20],\n",
      " 'num_states': [3],\n",
      " 'dropout': [0.1],\n",
      " 'rnn_layers': [2],\n",
      " 'rnn_type': ['lstm']}\n",
      "try using /home/mengkjin/Workspace/learndl/data/DataSet/day.20240509.pt , success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-05-30 19:41:36|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Data], Cost 2.5 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-30 19:41:36|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Fit] at Thu May 30 19:41:36 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n",
      "loss function of [pearson] calculated and success!\n",
      "penalty function of [hidden_corr] calculated and success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mFirstBite Ep#  0 : loss  1.01474, train 0.00138, valid 0.01279, best 0.0128, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  5 : loss  0.94300, train 0.07806, valid 0.08231, best 0.0860, lr2.5e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 10 : loss  0.90798, train 0.11390, valid 0.12313, best 0.1231, lr1.9e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 15 : loss  0.88064, train 0.13627, valid 0.12708, best 0.1319, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 20 : loss  0.87834, train 0.13659, valid 0.14512, best 0.1451, lr9.4e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 25 : loss  0.86554, train 0.14881, valid 0.14097, best 0.1451, lr3.1e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 30 : loss  0.86379, train 0.15013, valid 0.14280, best 0.1451, lr1.6e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 35 : loss  0.86194, train 0.15254, valid 0.13904, best 0.1451, lr3.1e-04\u001b[0m\n",
      "\u001b[32mReset learn rate and scheduler at the end of epoch 39 , effective at epoch 40\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 40 : loss  0.85851, train 0.15632, valid 0.14163, best 0.1451, lr1.3e-03\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-30 19:46:05|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mtra_day.1 #0 @20170103|FirstBite Ep# 41 EarlyStop|Train 0.1563 Valid 0.1416 BestVal 0.1416|Cost  4.4Min,  6.3Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-30 19:53:08|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mtra_day.1 #0 @20170704|FirstBite Ep# 63 EarlyStop|Train 0.1576 Valid 0.1327 BestVal 0.1327|Cost  7.0Min,  6.6Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-30 19:58:38|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mtra_day.1 #0 @20171226|FirstBite Ep# 48 EarlyStop|Train 0.1554 Valid 0.1435 BestVal 0.1435|Cost  5.4Min,  6.7Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-30 20:09:08|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mtra_day.1 #0 @20180627|FirstBite Ep# 92 EarlyStop|Train 0.1908 Valid 0.1416 BestVal 0.1416|Cost 10.5Min,  6.7Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-30 20:18:36|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mtra_day.1 #0 @20181220|FirstBite Ep# 84 EarlyStop|Train 0.1864 Valid 0.1448 BestVal 0.1448|Cost  9.4Min,  6.7Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-30 20:28:49|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mtra_day.1 #0 @20190624|FirstBite Ep# 87 EarlyStop|Train 0.1867 Valid 0.1358 BestVal 0.1358|Cost 10.2Min,  6.9Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-30 20:38:45|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mtra_day.1 #0 @20191217|FirstBite Ep# 85 EarlyStop|Train 0.1864 Valid 0.1249 BestVal 0.1249|Cost  9.9Min,  6.9Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-30 20:48:01|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mtra_day.1 #0 @20200617|FirstBite Ep# 75 EarlyStop|Train 0.1783 Valid 0.1169 BestVal 0.1169|Cost  9.2Min,  7.3Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-30 21:00:20|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mtra_day.1 #0 @20201214|FirstBite Ep#100 EarlyStop|Train 0.1860 Valid 0.1007 BestVal 0.1007|Cost 12.3Min,  7.3Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-30 21:10:28|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mtra_day.1 #0 @20210615|FirstBite Ep# 82 EarlyStop|Train 0.1762 Valid 0.0913 BestVal 0.0913|Cost 10.1Min,  7.3Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-30 21:21:18|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mtra_day.1 #0 @20211209|FirstBite Ep# 89 EarlyStop|Train 0.1787 Valid 0.0878 BestVal 0.0878|Cost 10.8Min,  7.2Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-30 21:33:02|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mtra_day.1 #0 @20220613|FirstBite Ep# 95 EarlyStop|Train 0.1620 Valid 0.0853 BestVal 0.0853|Cost 11.7Min,  7.3Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-30 21:40:28|MOD:time        |\u001b[0m: \u001b[1m\u001b[31mMain Process Finished! Cost 1 Hours 58 Minutes 54.6 Seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchMetric(loss=tensor([nan], device='cuda:0', grad_fn=<AddBackward0>), score=0.0802483931183815, losses=tensor([0.8885], device='cuda:0', grad_fn=<ExpBackward0>))\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "nan loss here",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m API\n\u001b[0;32m----> 2\u001b[0m \u001b[43mAPI\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresume\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/learndl/src/API/trainer.py:52\u001b[0m, in \u001b[0;36mTrainer.main\u001b[0;34m(cls, stage, resume, checkname, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m app \u001b[38;5;241m=\u001b[39m use_trainer(stage \u001b[38;5;241m=\u001b[39m stage , resume \u001b[38;5;241m=\u001b[39m resume , checkname \u001b[38;5;241m=\u001b[39m checkname , \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m BigTimer(app\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mcritical , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMain Process\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 52\u001b[0m     \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/learndl/src/classes/mod.py:404\u001b[0m, in \u001b[0;36mBaseTrainer.main_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_configure_model()\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage_queue: \n\u001b[0;32m--> 404\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstage_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_summarize_model()\n",
      "File \u001b[0;32m~/Workspace/learndl/src/classes/mod.py:419\u001b[0m, in \u001b[0;36mBaseTrainer.stage_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_fit_start()\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mmodel_date , \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mmodel_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_iter:\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_fit_end()\n",
      "File \u001b[0;32m~/Workspace/learndl/src/API/trainer.py:80\u001b[0m, in \u001b[0;36mNetTrainer.fit_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_idx , \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader):\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_train_batch_start()\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_train_batch_end()\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_train_epoch_end()\n",
      "File \u001b[0;32m~/Workspace/learndl/src/classes/mod.py:119\u001b[0m, in \u001b[0;36mBaseCB.hook_wrapper.<locals>.wrapper_with\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_with\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mat_enter(hook_name)\n\u001b[0;32m--> 119\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mat_exit(hook_name)\n",
      "File \u001b[0;32m~/Workspace/learndl/src/classes/mod.py:444\u001b[0m, in \u001b[0;36mBaseTrainer.on_train_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_forward()\n\u001b[0;32m--> 444\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_backward()\n",
      "File \u001b[0;32m~/Workspace/learndl/src/API/trainer.py:61\u001b[0m, in \u001b[0;36mNetTrainer.batch_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_metrics\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massert_nan\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mcollect_batch_metric()\n",
      "File \u001b[0;32m~/Workspace/learndl/src/util/metric.py:122\u001b[0m, in \u001b[0;36mMetrics.calculate\u001b[0;34m(self, dataset, batch_data, batch_output, net, assert_nan, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m penalty_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnet\u001b[39m\u001b[38;5;124m'\u001b[39m:net,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre\u001b[39m\u001b[38;5;124m'\u001b[39m:pred,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m:label,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mother}\n\u001b[1;32m    121\u001b[0m mt_param \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(net , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_multiloss_params\u001b[39m\u001b[38;5;124m'\u001b[39m)() \u001b[38;5;28;01mif\u001b[39;00m net \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(net , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_multiloss_params\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_from_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpenalty_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmt_param\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massert_nan\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/learndl/src/util/metric.py:156\u001b[0m, in \u001b[0;36mMetrics.calculate_from_tensor\u001b[0;34m(self, dataset, label, pred, weight, penalty_kwargs, multiloss_param, assert_nan)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput)\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnan loss here\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorator_display\u001b[39m(\u001b[38;5;28mcls\u001b[39m , func , mtype , mkey):\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmetric_display\u001b[39m(mtype , mkey):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m DISPLAY_RECORD[mtype]\u001b[38;5;241m.\u001b[39mget(mkey , \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[0;31mException\u001b[0m: nan loss here"
     ]
    }
   ],
   "source": [
    "from src import API\n",
    "API.Trainer.main(stage = 0 , resume = 0 , checkname= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import API\n",
    "API.DataAPI.reconstruct_train_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
