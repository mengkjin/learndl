{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False 2.2.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available() , torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mengkjin/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-26 19:44:55|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mModel Specifics:\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-26 19:44:55|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Data] at Sun May 26 19:44:55 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Process Queue : Data + Fit + Test\n",
      "--Model_name is set to gru_day.1!\n",
      "Callback : DynamicDataLink() , assign and unlink dynamic data in tra networks\n",
      "Callback : ResetOptimizer(num_reset=2,trigger=40,recover_level=1.0,speedup2x=True) , reset optimizer on some epoch (can speedup scheduler)\n",
      "Callback : CallbackTimer(verbosity=2) , record time cost of callback hooks\n",
      "Callback : EarlyStoppage(patience=20) , stop fitting when validation score cease to improve\n",
      "Callback : ValidationConverge(patience=5,eps=1e-05) , stop fitting when valid_score converge\n",
      "Callback : EarlyExitRetrain(earliest=10,max_attempt=4,lr_multiplier=[1, 0.1, 10, 0.01, 100, 1]) , retrain with new lr if fitting stopped too early\n",
      "Callback : NanLossRetrain(max_attempt=4) , retrain if fitting encounters nan loss\n",
      "Callback : BatchDisplay(verbosity=2) , display batch progress bar\n",
      "Callback : StatusDisplay(verbosity=2) , display epoch and event information\n",
      "{'random_seed': None,\n",
      " 'model_name': 'gru_day.1',\n",
      " 'model_module': 'gru',\n",
      " 'model_data_type': 'day',\n",
      " 'model_types': ['best', 'swalast', 'swabest'],\n",
      " 'labels': ['std_lag1_10', 'std_lag1_20'],\n",
      " 'beg_date': 20170103,\n",
      " 'end_date': 99991231,\n",
      " 'sample_method': 'train_shuffle',\n",
      " 'shuffle_option': 'epoch',\n",
      " 'lgbm_ensembler': False}\n",
      "{'hidden_dim': [32],\n",
      " 'seqlens': [{'day': 30, '30m': 30, 'dms': 30}],\n",
      " 'tra_seqlens': [{'hist_loss': 40}],\n",
      " 'dropout': [0.1],\n",
      " 'enc_in': [True],\n",
      " 'enc_att': [False],\n",
      " 'rnn_type': ['gru'],\n",
      " 'rnn_att': [False],\n",
      " 'rnn_layers': [2],\n",
      " 'dec_mlp_layers': [2],\n",
      " 'num_output': [2],\n",
      " 'which_output': [0, 1, -1],\n",
      " 'kernel_size': [3],\n",
      " 'hidden_as_factor': [True],\n",
      " 'ordered_param_group': [False]}\n",
      "try using /home/mengkjin/Workspace/learndl/data/DataSet/day.20240509.pt , success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-05-26 19:44:58|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Data], Cost 2.5 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-26 19:44:58|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Fit] at Sun May 26 19:44:58 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n",
      "score function of [spearman] calculated and success!\n",
      "loss function of [pearson] calculated and success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mFirstBite Ep#  0 : loss  4.02626, train-0.01077, valid-0.02450, best-0.0245, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  5 : loss  2.88181, train 0.13157, valid 0.14108, best 0.1411, lr2.5e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 10 : loss  2.81686, train 0.14579, valid 0.15150, best 0.1528, lr1.9e-03\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src import API\n",
    "API.Trainer.main(stage = 0 , resume = 0 , checkname= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0160)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([0.0102, 0.0219])\n",
    "v = torch.nanmean(a , dim = -1)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seqlens': [{'day': 30, '30m': 30, 'dms': 30}],\n",
       " 'objective': ['regression'],\n",
       " 'linear_tree': [True],\n",
       " 'learning_rate': [0.3],\n",
       " 'lambda_l2': ['1e-05'],\n",
       " 'alpha': ['1e-07'],\n",
       " 'num_leaves': [31],\n",
       " 'max_depth': [6],\n",
       " 'min_sum_hessian_in_leaf': [1],\n",
       " 'feature_fraction': [0.6],\n",
       " 'bagging_fraction': [0.75],\n",
       " 'force_col_wise': [True],\n",
       " 'monotone_constraints': [1]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.environ import PATH\n",
    "PATH.read_yaml('./configs/model_lgbm.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device name: NVIDIA GeForce RTX 4090\n",
      "predict is False , Data Processing start!\n",
      "4 datas :['y', 'day', '30m', 'risk']\n",
      "y blocks loading start!\n",
      " --> labels blocks reading [ret10_lag] DataBase...... finished! Cost 18.86 secs\n",
      " --> labels blocks reading [ret20_lag] DataBase...... finished! Cost 20.08 secs\n",
      " --> labels blocks merging (2)...... finished! Cost 2.88 secs\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 67.78 secs\n",
      "y blocks loading finished! Cost 120.52 secs\n",
      "y blocks process...... finished! Cost 45.61 secs\n",
      "y blocks masking...... finished! Cost 0.81 secs\n",
      "y blocks saving ...... finished! Cost 3.76 secs\n",
      "y blocks norming...... finished! Cost 0.00 secs\n",
      "y finished! Cost 170.98 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "day blocks loading start!\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 28.95 secs\n",
      "day blocks loading finished! Cost 28.98 secs\n",
      "day blocks process...... finished! Cost 3.27 secs\n",
      "day blocks masking...... finished! Cost 0.86 secs\n",
      "day blocks saving ...... finished! Cost 3.56 secs\n",
      "day blocks norming...... finished! Cost 7.99 secs\n",
      "day finished! Cost 44.82 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "30m blocks loading start!\n",
      " --> trade blocks reading [30min] DataBase...... finished! Cost 67.25 secs\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 24.67 secs\n",
      "30m blocks loading finished! Cost 92.86 secs\n",
      "30m blocks process...... finished! Cost 32.48 secs\n",
      "30m blocks masking...... finished! Cost 2.42 secs\n",
      "30m blocks saving ...... finished! Cost 40.51 secs\n",
      "30m blocks norming...... finished! Cost 3.77 secs\n",
      "30m finished! Cost 172.21 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "risk blocks loading start!\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 32.95 secs\n",
      "risk blocks loading finished! Cost 32.97 secs\n",
      "risk blocks process...... finished! Cost 0.00 secs\n",
      "risk blocks masking...... finished! Cost 0.89 secs\n",
      "risk blocks saving ...... finished! Cost 5.45 secs\n",
      "risk blocks norming...... finished! Cost 0.00 secs\n",
      "risk finished! Cost 39.42 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "Data Processing Finished! Cost 427.43 Seconds\n",
      "predict is True , Data Processing start!\n",
      "4 datas :['y', 'day', '30m', 'risk']\n",
      "y blocks loading start!\n",
      " --> labels blocks reading [ret10_lag] DataBase...... finished! Cost 0.71 secs\n",
      " --> labels blocks reading [ret20_lag] DataBase...... finished! Cost 0.66 secs\n",
      " --> labels blocks merging (2)...... finished! Cost 0.09 secs\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 2.77 secs\n",
      "y blocks loading finished! Cost 4.44 secs\n",
      "y blocks process...... finished! Cost 1.94 secs\n",
      "y blocks masking...... finished! Cost 0.07 secs\n",
      "y blocks saving ...... finished! Cost 0.13 secs\n",
      "y blocks norming...... finished! Cost 0.00 secs\n",
      "y finished! Cost 6.68 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "day blocks loading start!\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 1.09 secs\n",
      "day blocks loading finished! Cost 1.09 secs\n",
      "day blocks process...... finished! Cost 0.10 secs\n",
      "day blocks masking...... finished! Cost 0.07 secs\n",
      "day blocks saving ...... finished! Cost 0.28 secs\n",
      "day blocks norming...... finished! Cost 0.00 secs\n",
      "day finished! Cost 1.65 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "30m blocks loading start!\n",
      " --> trade blocks reading [30min] DataBase...... finished! Cost 4.47 secs\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 0.97 secs\n",
      "30m blocks loading finished! Cost 5.49 secs\n",
      "30m blocks process...... finished! Cost 1.39 secs\n",
      "30m blocks masking...... finished! Cost 0.12 secs\n",
      "30m blocks saving ...... finished! Cost 2.08 secs\n",
      "30m blocks norming...... finished! Cost 0.00 secs\n",
      "30m finished! Cost 9.20 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "risk blocks loading start!\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 1.49 secs\n",
      "risk blocks loading finished! Cost 1.49 secs\n",
      "risk blocks process...... finished! Cost 0.00 secs\n",
      "risk blocks masking...... finished! Cost 0.08 secs\n",
      "risk blocks saving ...... finished! Cost 0.21 secs\n",
      "risk blocks norming...... finished! Cost 0.00 secs\n",
      "risk finished! Cost 1.88 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "Data Processing Finished! Cost 19.42 Seconds\n"
     ]
    }
   ],
   "source": [
    "from src import API\n",
    "API.DataAPI.reconstruct_train_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
