{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False 2.2.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available() , torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[44m24-05-29 17:58:28|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mModel Specifics:\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-29 17:58:28|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Data] at Wed May 29 17:58:28 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Process Queue : Data + Fit + Test\n",
      "--Model_name is set to tra_day_ShortTest!\n",
      "Callback : ResetOptimizer(num_reset=2,trigger=40,recover_level=1.0,speedup2x=True) , reset optimizer on some epoch (can speedup scheduler)\n",
      "Callback : CallbackTimer(verbosity=10) , record time cost of callback hooks\n",
      "Callback : EarlyStoppage(patience=20) , stop fitting when validation score cease to improve\n",
      "Callback : ValidationConverge(patience=5,eps=1e-05) , stop fitting when valid_score converge\n",
      "Callback : EarlyExitRetrain(earliest=10,max_attempt=4,lr_multiplier=[1, 0.1, 10, 0.01, 100, 1]) , retrain with new lr if fitting stopped too early\n",
      "Callback : NanLossRetrain(max_attempt=4) , retrain if fitting encounters nan loss\n",
      "Callback : BatchDisplay(verbosity=10) , display batch progress bar\n",
      "Callback : StatusDisplay(verbosity=10) , display epoch and event information\n",
      "Callback : SpecCB_TRA() , in TRA fill [y] [hist_loss] in batch_data.kwargs , update hist_loss in data.buffer\n",
      "{'random_seed': None,\n",
      " 'model_name': 'tra_day_ShortTest',\n",
      " 'model_module': 'tra',\n",
      " 'model_data_type': 'day',\n",
      " 'model_types': ['best', 'swalast', 'swabest'],\n",
      " 'labels': ['std_lag1_10', 'std_lag1_20'],\n",
      " 'beg_date': 20170101,\n",
      " 'end_date': 20170228,\n",
      " 'sample_method': 'sequential',\n",
      " 'shuffle_option': 'epoch',\n",
      " 'lgbm_ensembler': False}\n",
      "{'hidden_dim': [32],\n",
      " 'seqlens': [{'day': 30, '30m': 30, 'dms': 30}],\n",
      " 'hist_loss_seq_len': [60],\n",
      " 'hist_loss_horizon': [20],\n",
      " 'num_states': [3],\n",
      " 'dropout': [0.1],\n",
      " 'rnn_layers': [2],\n",
      " 'rnn_type': ['lstm']}\n",
      "try using d:\\Coding\\learndl\\learndl\\data\\DataSet/day.20240315.pt , success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-05-29 17:58:31|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Data], Cost 2.4 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-29 17:58:31|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Fit] at Wed May 29 17:58:31 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Ep#  0 loss : 1.02465:   2%|▏         | 1/48 [00:00<00:12,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score function of [spearman] calculated and success!\n",
      "loss function of [mse] calculated and success!\n",
      "penalty function of [hidden_corr] calculated and success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Ep#  0 loss : 1.02176: 100%|██████████| 48/48 [00:09<00:00,  4.83it/s]\n",
      "Valid Ep#  0 score : 0.01377: 100%|██████████| 12/12 [00:00<00:00, 12.69it/s] \n",
      "\u001b[32mFirstBite Ep#  0 : loss  1.02193, train 0.00261, valid-0.01300, best-0.0130, lr1.3e-03\u001b[0m\n",
      "Train Ep#  1 loss : 1.01555: 100%|██████████| 48/48 [00:09<00:00,  4.88it/s]\n",
      "Valid Ep#  1 score : -0.00135: 100%|██████████| 12/12 [00:00<00:00, 13.57it/s]\n",
      "\u001b[32mFirstBite Ep#  1 : loss  1.01572, train 0.01530, valid 0.00873, best 0.0087, lr2.5e-03\u001b[0m\n",
      "Train Ep#  2 loss : 1.00981: 100%|██████████| 48/48 [00:09<00:00,  5.13it/s]\n",
      "Valid Ep#  2 score : 0.00882: 100%|██████████| 12/12 [00:00<00:00, 14.36it/s] \n",
      "\u001b[32mFirstBite Ep#  2 : loss  1.01352, train 0.03089, valid 0.01611, best 0.0161, lr3.8e-03\u001b[0m\n",
      "Train Ep#  3 loss : 1.01886: 100%|██████████| 48/48 [00:08<00:00,  5.78it/s]\n",
      "Valid Ep#  3 score : -0.01170: 100%|██████████| 12/12 [00:00<00:00, 15.84it/s]\n",
      "\u001b[32mFirstBite Ep#  3 : loss  1.01302, train 0.03806, valid 0.03524, best 0.0352, lr5.0e-03\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-29 17:59:14|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mtra_day_ShortTest #0 @20170103|FirstBite Ep#  4 Max Epoch|Train 0.0381 Valid 0.0352 BestVal 0.0352|Cost  0.7Min,  8.2Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-29 17:59:14|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Fit], Cost 0.0 Hours, 0.7 Min/model, 10.8 Sec/Epoch\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-29 17:59:14|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Test] at Wed May 29 17:59:14 2024!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-29 17:59:14|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mEach Model Date Testing Mean Score(spearman):\u001b[0m\n",
      "\u001b[32mModels            0       0       0\u001b[0m\n",
      "\u001b[32mOutput         best swalast swabest\u001b[0m\n",
      "Test best 20170228 score : -0.01405: 100%|██████████| 94/94 [00:06<00:00, 14.77it/s]\n",
      "Test swalast 20170228 score : -0.04003: 100%|██████████| 94/94 [00:06<00:00, 14.28it/s]\n",
      "Test swabest 20170228 score : 0.00721: 100%|██████████| 94/94 [00:06<00:00, 13.89it/s] \n",
      "\u001b[32m20170103     0.0086  0.0154 -0.0177\u001b[0m\n",
      "\u001b[32mAllTimeAvg   0.0086  0.0154 -0.0177\u001b[0m\n",
      "\u001b[32mAllTimeSum     0.30    0.54   -0.62\u001b[0m\n",
      "\u001b[32mStd          0.0305  0.0302  0.0363\u001b[0m\n",
      "\u001b[32mTValue         1.68    3.02   -2.89\u001b[0m\n",
      "\u001b[32mAnnIR        1.3904  2.4977 -2.3905\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-29 17:59:35|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Test], Cost 20.9 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-29 17:59:35|MOD:time        |\u001b[0m: \u001b[1m\u001b[31mMain Process Finished! Cost 1 Minutes 6.5 Seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    hook_name  num_calls  total_time  avg_time\n",
      "10             on_train_batch        192   34.800170  0.181251\n",
      "27              on_test_batch        282   15.573823  0.055226\n",
      "15        on_validation_batch         48    2.700895  0.056269\n",
      "4          on_fit_model_start          1    2.096335  2.096335\n",
      "24        on_test_model_start          1    1.148355  1.148355\n",
      "25   on_test_model_type_start          3    0.023086  0.007695\n",
      "21           on_fit_model_end          1    0.022537  0.022537\n",
      "17    on_validation_epoch_end          4    0.019749  0.004937\n",
      "8          on_before_backward        192    0.015623  0.000081\n",
      "12         on_train_epoch_end          4    0.002507  0.000627\n",
      "26        on_test_batch_start        282    0.002506  0.000009\n",
      "7        on_train_batch_start        192    0.002009  0.000010\n",
      "20       on_before_save_model          1    0.000520  0.000520\n",
      "23              on_test_start          1    0.000013  0.000013\n",
      "28          on_test_batch_end        282    0.000000  0.000000\n",
      "29     on_test_model_type_end          3    0.000000  0.000000\n",
      "30          on_test_model_end          1    0.000000  0.000000\n",
      "31                on_test_end          1    0.000000  0.000000\n",
      "22                 on_fit_end          1    0.000000  0.000000\n",
      "0          on_configure_model          1    0.000000  0.000000\n",
      "16    on_validation_batch_end         48    0.000000  0.000000\n",
      "19           on_fit_epoch_end          4    0.000000  0.000000\n",
      "18    on_before_fit_epoch_end          4    0.000000  0.000000\n",
      "1               on_data_start          1    0.000000  0.000000\n",
      "14  on_validation_batch_start         48    0.000000  0.000000\n",
      "13  on_validation_epoch_start          4    0.000000  0.000000\n",
      "11         on_train_batch_end        192    0.000000  0.000000\n",
      "9           on_after_backward        192    0.000000  0.000000\n",
      "6        on_train_epoch_start          4    0.000000  0.000000\n",
      "5          on_fit_epoch_start          4    0.000000  0.000000\n",
      "3                on_fit_start          1    0.000000  0.000000\n",
      "2                 on_data_end          1    0.000000  0.000000\n",
      "32         on_summarize_model          1    0.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "from src import API\n",
    "API.Trainer.main(stage = 0 , resume = 0 , checkname= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    " \n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.sqrt_d_model = math.sqrt(d_model)\n",
    " \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        # 计算点积\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / self.sqrt_d_model\n",
    "        \n",
    "        # 掩码处理，如掩蔽未来信息在自注意力中的应用\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        # 应用softmax函数\n",
    "        attention_weights = F.softmax(scores, dim=-1)\n",
    "        \n",
    "        # 使用dropout增加模型的泛化能力\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "        \n",
    "        # 加权求和得到输出\n",
    "        output = torch.matmul(attention_weights, V)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "bs = 20\n",
    "hidden_dim = 16\n",
    "h2 = 8\n",
    "factor_num = 10\n",
    "\n",
    "a = torch.rand(bs , hidden_dim)\n",
    "q = torch.nn.Parameter(torch.rand(h2))\n",
    "k = torch.nn.Linear(hidden_dim,h2,bias=False)(a)\n",
    "v = torch.nn.Linear(hidden_dim,h2,bias=False)(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.nn.ReLU()((q * k) / q.norm() / k.norm(dim=-1,keepdim=True)) + 1e-6\n",
    "a = a / a.sum(-1 , keepdim=True)\n",
    "(a * v).sum(0).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Features shape : torch.Size([40, 32])\n",
      "Portoflio shape : torch.Size([40, 100])\n",
      "mu_post shape : torch.Size([1, 64]) , sigma_post shape : torch.Size([1, 64])\n",
      "A post factor sample : tensor([[ 1.0287,  0.6462, -0.0442,  1.1449, -0.3113,  1.5007, -0.6798,  2.5814,\n",
      "          1.5795,  1.4307,  0.6464,  0.9147,  0.3010,  0.8725,  1.3673,  1.0741,\n",
      "          1.0826,  0.0390,  1.6443,  1.0617,  1.1597,  1.4367,  1.7134, -0.5356,\n",
      "         -0.6769, -1.5016,  1.0472,  1.2781,  0.1810,  1.5498,  2.5867,  1.1622,\n",
      "          0.4741,  0.7150,  1.0427, -0.2219,  1.0836, -0.8425,  0.5996,  1.2462,\n",
      "          0.7252,  1.2713,  0.8382,  1.7843,  1.5991,  0.0106,  1.2709, -1.1145,\n",
      "          0.9098,  1.1036,  2.3179,  1.6863,  2.7604,  0.8293,  1.1856,  1.1063,\n",
      "         -0.9258,  0.4866,  3.0375,  0.4554, -0.1498,  1.6770,  1.8241,  1.0082]],\n",
      "       grad_fn=<AddBackward0>) \n",
      "Beta shape : torch.Size([40, 64])\n",
      "mu_alpha shape : torch.Size([40, 1]) , sigma_alpha shape : torch.Size([40, 1])\n",
      "stock_returns shape : torch.Size([40, 1]) , mu_alpha shape : torch.Size([40, 1]) , sigma_alpha shape : torch.Size([40, 1])\n",
      "mu_prior shape : torch.Size([64, 1]) , sigma_prior shape : torch.Size([64, 1])\n",
      "y_hat for training shape : torch.Size([40, 1]) , loss_KL is : {'loss_KL': tensor(0.4042, grad_fn=<MulBackward0>)}\n",
      "y_hat for eval shape : torch.Size([40, 1])\n"
     ]
    }
   ],
   "source": [
    "%run \"src/nn/factorVAE.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.norm(dim = 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seqlens': [{'day': 30, '30m': 30, 'dms': 30}],\n",
       " 'objective': ['regression'],\n",
       " 'linear_tree': [True],\n",
       " 'learning_rate': [0.3],\n",
       " 'lambda_l2': ['1e-05'],\n",
       " 'alpha': ['1e-07'],\n",
       " 'num_leaves': [31],\n",
       " 'max_depth': [6],\n",
       " 'min_sum_hessian_in_leaf': [1],\n",
       " 'feature_fraction': [0.6],\n",
       " 'bagging_fraction': [0.75],\n",
       " 'force_col_wise': [True],\n",
       " 'monotone_constraints': [1]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.environ import PATH\n",
    "PATH.read_yaml('./configs/model_lgbm.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device name: NVIDIA GeForce RTX 4090\n",
      "predict is False , Data Processing start!\n",
      "4 datas :['y', 'day', '30m', 'risk']\n",
      "y blocks loading start!\n",
      " --> labels blocks reading [ret10_lag] DataBase...... finished! Cost 18.86 secs\n",
      " --> labels blocks reading [ret20_lag] DataBase...... finished! Cost 20.08 secs\n",
      " --> labels blocks merging (2)...... finished! Cost 2.88 secs\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 67.78 secs\n",
      "y blocks loading finished! Cost 120.52 secs\n",
      "y blocks process...... finished! Cost 45.61 secs\n",
      "y blocks masking...... finished! Cost 0.81 secs\n",
      "y blocks saving ...... finished! Cost 3.76 secs\n",
      "y blocks norming...... finished! Cost 0.00 secs\n",
      "y finished! Cost 170.98 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "day blocks loading start!\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 28.95 secs\n",
      "day blocks loading finished! Cost 28.98 secs\n",
      "day blocks process...... finished! Cost 3.27 secs\n",
      "day blocks masking...... finished! Cost 0.86 secs\n",
      "day blocks saving ...... finished! Cost 3.56 secs\n",
      "day blocks norming...... finished! Cost 7.99 secs\n",
      "day finished! Cost 44.82 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "30m blocks loading start!\n",
      " --> trade blocks reading [30min] DataBase...... finished! Cost 67.25 secs\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 24.67 secs\n",
      "30m blocks loading finished! Cost 92.86 secs\n",
      "30m blocks process...... finished! Cost 32.48 secs\n",
      "30m blocks masking...... finished! Cost 2.42 secs\n",
      "30m blocks saving ...... finished! Cost 40.51 secs\n",
      "30m blocks norming...... finished! Cost 3.77 secs\n",
      "30m finished! Cost 172.21 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "risk blocks loading start!\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 32.95 secs\n",
      "risk blocks loading finished! Cost 32.97 secs\n",
      "risk blocks process...... finished! Cost 0.00 secs\n",
      "risk blocks masking...... finished! Cost 0.89 secs\n",
      "risk blocks saving ...... finished! Cost 5.45 secs\n",
      "risk blocks norming...... finished! Cost 0.00 secs\n",
      "risk finished! Cost 39.42 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "Data Processing Finished! Cost 427.43 Seconds\n",
      "predict is True , Data Processing start!\n",
      "4 datas :['y', 'day', '30m', 'risk']\n",
      "y blocks loading start!\n",
      " --> labels blocks reading [ret10_lag] DataBase...... finished! Cost 0.71 secs\n",
      " --> labels blocks reading [ret20_lag] DataBase...... finished! Cost 0.66 secs\n",
      " --> labels blocks merging (2)...... finished! Cost 0.09 secs\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 2.77 secs\n",
      "y blocks loading finished! Cost 4.44 secs\n",
      "y blocks process...... finished! Cost 1.94 secs\n",
      "y blocks masking...... finished! Cost 0.07 secs\n",
      "y blocks saving ...... finished! Cost 0.13 secs\n",
      "y blocks norming...... finished! Cost 0.00 secs\n",
      "y finished! Cost 6.68 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "day blocks loading start!\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 1.09 secs\n",
      "day blocks loading finished! Cost 1.09 secs\n",
      "day blocks process...... finished! Cost 0.10 secs\n",
      "day blocks masking...... finished! Cost 0.07 secs\n",
      "day blocks saving ...... finished! Cost 0.28 secs\n",
      "day blocks norming...... finished! Cost 0.00 secs\n",
      "day finished! Cost 1.65 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "30m blocks loading start!\n",
      " --> trade blocks reading [30min] DataBase...... finished! Cost 4.47 secs\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 0.97 secs\n",
      "30m blocks loading finished! Cost 5.49 secs\n",
      "30m blocks process...... finished! Cost 1.39 secs\n",
      "30m blocks masking...... finished! Cost 0.12 secs\n",
      "30m blocks saving ...... finished! Cost 2.08 secs\n",
      "30m blocks norming...... finished! Cost 0.00 secs\n",
      "30m finished! Cost 9.20 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "risk blocks loading start!\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 1.49 secs\n",
      "risk blocks loading finished! Cost 1.49 secs\n",
      "risk blocks process...... finished! Cost 0.00 secs\n",
      "risk blocks masking...... finished! Cost 0.08 secs\n",
      "risk blocks saving ...... finished! Cost 0.21 secs\n",
      "risk blocks norming...... finished! Cost 0.00 secs\n",
      "risk finished! Cost 1.88 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "Data Processing Finished! Cost 19.42 Seconds\n"
     ]
    }
   ],
   "source": [
    "from src import API\n",
    "API.DataAPI.reconstruct_train_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
