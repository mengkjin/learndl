{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 2.1.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available() , torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mengkjin/Workspace/learndl/src/nn_model/util/logger.py:22: ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/mengkjin/Workspace/learndl/logs/logs/rnn_log.log' mode='a' encoding='utf-8'>\n",
      "  log.removeHandler(log.handlers[-1])\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 06:19:57|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mModel Specifics:\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-08-06 06:19:57|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Data] at Tue Aug  6 06:19:57 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "risk_att_gru nn\n",
      "--Process Queue : Data + Fit + Test\n",
      "--Start Training New!\n",
      "--Model_name is set to risk_att_gru_day.5!\n",
      "Callback : ResetOptimizer(num_reset=2,trigger=40,recover_level=1.0,speedup2x=True,kwargs={}) , reset optimizer on some epoch (can speedup scheduler)\n",
      "Callback : CallbackTimer(verbosity=2,kwargs={}) , record time cost of callback hooks\n",
      "Callback : EarlyStoppage(patience=20,kwargs={}) , stop fitting when validation score cease to improve\n",
      "Callback : ValidationConverge(patience=5,eps=1e-05,kwargs={}) , stop fitting when valid_score converge\n",
      "Callback : EarlyExitRetrain(earliest=10,max_attempt=4,lr_multiplier=[1, 0.1, 10, 0.01, 100, 1],kwargs={}) , retrain with new lr if fitting stopped too early\n",
      "Callback : NanLossRetrain(max_attempt=4,kwargs={}) , retrain if fitting encounters nan loss\n",
      "Callback : BatchDisplay(verbosity=2,kwargs={}) , display batch progress bar\n",
      "Callback : StatusDisplay(verbosity=2,kwargs={}) , display epoch and event information\n",
      "Callback : GroupReturnAnalysis(group_num=20,kwargs={}) , record and concat each model to Alpha model instance\n",
      "Callback : DetailedAlphaAnalysis(use_num=avg,kwargs={}) , record and concat each model to Alpha model instance\n",
      "{'model_name': 'risk_att_gru_day.5',\n",
      " 'model_module': 'risk_att_gru',\n",
      " 'model.types': ['best'],\n",
      " 'model.lgbm_ensembler': False,\n",
      " 'data.type': 'day+style+indus',\n",
      " 'data.labels': ['std_lag1_10', 'rtn_lag1_10'],\n",
      " 'random_seed': None,\n",
      " 'beg_date': 20170103,\n",
      " 'end_date': 99991231,\n",
      " 'sample_method': 'sequential',\n",
      " 'shuffle_option': 'epoch'}\n",
      "{'hidden_dim': [64, 64, 32, 32],\n",
      " 'seqlens': [{'day': 30, 'indus': 1, 'style': 1}],\n",
      " 'dropout': [0.1],\n",
      " 'rnn_layers': [3, 2, 3, 2],\n",
      " 'indus_dim': [8],\n",
      " 'indus_embed': [False],\n",
      " 'hidden_as_factor': [True],\n",
      " 'model.types': ['best']}\n",
      "try using /home/mengkjin/Workspace/learndl/data/DataSet/day+style+indus.20240703.pt , success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-08-06 06:20:02|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Data], Cost 5.0 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-08-06 06:20:02|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Fit] at Tue Aug  6 06:20:02 2024!\u001b[0m\n",
      "/home/mengkjin/Workspace/learndl/src/nn_model/classes/mod.py:345: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  self.logger.warn(f'First Iterance: ({self.status.model_date} , {self.status.model_num})')\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 06:20:02|MOD:mod         |\u001b[0m: \u001b[1m\u001b[34mFirst Iterance: (20170103 , 0)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n",
      "Pre-Norming method of [style] : {'divlast': False, 'histnorm': False}\n",
      "Pre-Norming method of [indus] : {'divlast': False, 'histnorm': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mFirstBite Ep#  0 : loss  1.01965, train-0.02352, valid-0.05340, best-0.0534, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  5 : loss  0.88802, train 0.13760, valid 0.14034, best 0.1403, lr2.5e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 10 : loss  0.85080, train 0.17248, valid 0.14400, best 0.1533, lr1.9e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 15 : loss  0.82769, train 0.19538, valid 0.15469, best 0.1547, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 20 : loss  0.82379, train 0.19928, valid 0.14742, best 0.1550, lr9.4e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 25 : loss  0.80184, train 0.22240, valid 0.15226, best 0.1583, lr3.1e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 30 : loss  0.79513, train 0.23077, valid 0.14968, best 0.1583, lr1.6e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 35 : loss  0.79060, train 0.23526, valid 0.14374, best 0.1583, lr3.1e-04\u001b[0m\n",
      "\u001b[32mReset learn rate and scheduler at the end of epoch 39 , effective at epoch 40, and will speedup2x\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 40 : loss  0.78290, train 0.24382, valid 0.14725, best 0.1583, lr1.3e-03\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 06:23:53|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #0 @20170103|FirstBite Ep# 42 EarlyStop|Train 0.2228 Valid 0.1563 BestVal 0.1563|Cost  3.7Min,  5.2Sec/Ep\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  0 : loss  1.00396, train-0.00856, valid-0.00740, best-0.0074, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  5 : loss  0.87830, train 0.14110, valid 0.15984, best 0.1598, lr2.5e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 10 : loss  0.84767, train 0.17294, valid 0.15695, best 0.1731, lr1.9e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 15 : loss  0.82949, train 0.19128, valid 0.17173, best 0.1742, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 20 : loss  0.82711, train 0.19306, valid 0.16398, best 0.1742, lr9.4e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 25 : loss  0.80894, train 0.21273, valid 0.16147, best 0.1742, lr3.1e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 30 : loss  0.80398, train 0.21809, valid 0.15744, best 0.1742, lr1.6e-04\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 06:26:53|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #1 @20170103|FirstBite Ep# 34 EarlyStop|Train 0.2244 Valid 0.1543 BestVal 0.1543|Cost  3.0Min,  5.1Sec/Ep\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  0 : loss  0.98344, train 0.02116, valid 0.04061, best 0.0406, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  5 : loss  0.89079, train 0.13271, valid 0.14051, best 0.1405, lr2.5e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 10 : loss  0.85484, train 0.16839, valid 0.15173, best 0.1544, lr1.9e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 15 : loss  0.83785, train 0.18551, valid 0.14832, best 0.1544, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 20 : loss  0.83714, train 0.18672, valid 0.13216, best 0.1544, lr9.4e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 25 : loss  0.82380, train 0.19952, valid 0.14195, best 0.1544, lr3.1e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 27 : loss  0.82534, train 0.19845, valid 0.13459, best 0.1544, lr6.3e-04, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  0 : loss  1.04198, train-0.04739, valid-0.06280, best-0.0628, lr1.3e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  5 : loss  0.92316, train 0.09528, valid 0.10272, best 0.1027, lr2.5e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 10 : loss  0.90206, train 0.12149, valid 0.11805, best 0.1180, lr1.9e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 15 : loss  0.88780, train 0.13698, valid 0.14368, best 0.1437, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 20 : loss  0.88513, train 0.14027, valid 0.15225, best 0.1523, lr9.4e-05\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 25 : loss  0.87954, train 0.14679, valid 0.14657, best 0.1523, lr3.1e-05\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 27 : loss  0.88068, train 0.14594, valid 0.15066, best 0.1523, lr6.3e-05, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  0 : loss  0.96920, train 0.03823, valid 0.04713, best 0.0471, lr1.3e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  5 : loss  0.95611, train 0.05762, valid 0.07934, best 0.0957, lr2.5e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 10 : loss  0.94206, train 0.07302, valid 0.10358, best 0.1048, lr1.9e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 15 : loss  0.95846, train 0.05557, valid 0.07373, best 0.1048, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 20 : loss  0.96159, train 0.05282, valid 0.05369, best 0.1048, lr9.4e-03\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 25 : loss  0.95553, train 0.06026, valid 0.06823, best 0.1048, lr3.1e-03\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 27 : loss  0.95575, train 0.05878, valid 0.06452, best 0.1048, lr6.3e-03, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep#  0 : loss  0.98241, train 0.02089, valid 0.04204, best 0.0420, lr1.3e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep#  5 : loss  0.95087, train 0.05921, valid 0.08620, best 0.0862, lr2.5e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 10 : loss  0.94652, train 0.06370, valid 0.09065, best 0.0908, lr1.9e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 15 : loss  0.94148, train 0.06857, valid 0.09102, best 0.0921, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 20 : loss  0.94084, train 0.06920, valid 0.08727, best 0.0921, lr9.5e-06\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 25 : loss  0.93902, train 0.07258, valid 0.08804, best 0.0921, lr3.2e-06\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 27 : loss  0.93858, train 0.07164, valid 0.09052, best 0.0921, lr6.3e-06, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep#  0 : loss  0.99671, train 0.00650, valid 0.02122, best 0.0212, lr1.3e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep#  5 : loss  0.99718, train 0.01256, valid 0.01761, best 0.0525, lr2.5e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 10 : loss  0.99924, train 0.00511, valid 0.03579, best 0.0525, lr1.9e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 15 : loss  0.99890, train 0.01084, valid 0.03029, best 0.0525, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 20 : loss  0.99186, train 0.01837, valid 0.03269, best 0.0525, lr9.4e-02\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 25 : loss  0.98889, train 0.01829, valid 0.01471, best 0.0525, lr3.1e-02\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 06:38:46|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #2 @20170103|Retrain#4 Ep#140 EarlyStop|Train 0.0173 Valid 0.0199 BestVal 0.1544|Cost 11.9Min,  5.0Sec/Ep\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  0 : loss  0.98904, train 0.01465, valid 0.04320, best 0.0432, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  5 : loss  0.88268, train 0.13901, valid 0.14955, best 0.1496, lr2.5e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 10 : loss  0.85239, train 0.16954, valid 0.16005, best 0.1635, lr1.9e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 15 : loss  0.83563, train 0.18756, valid 0.15230, best 0.1635, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 20 : loss  0.83472, train 0.18741, valid 0.14629, best 0.1635, lr9.4e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 25 : loss  0.82308, train 0.19985, valid 0.15423, best 0.1635, lr3.1e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 27 : loss  0.82418, train 0.19911, valid 0.15485, best 0.1635, lr6.3e-04, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  0 : loss  1.00230, train-0.00080, valid 0.02095, best 0.0209, lr1.3e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  5 : loss  0.91824, train 0.09679, valid 0.10178, best 0.1018, lr2.5e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 10 : loss  0.90157, train 0.11490, valid 0.10219, best 0.1131, lr1.9e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 15 : loss  0.88931, train 0.12782, valid 0.12584, best 0.1258, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 20 : loss  0.88642, train 0.13006, valid 0.12847, best 0.1303, lr9.4e-05\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 25 : loss  0.88121, train 0.13629, valid 0.12639, best 0.1303, lr3.1e-05\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 27 : loss  0.88095, train 0.13711, valid 0.12163, best 0.1303, lr6.3e-05, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  0 : loss  0.98657, train 0.01169, valid 0.01135, best 0.0113, lr1.3e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  5 : loss  0.96998, train 0.04445, valid 0.08914, best 0.1088, lr2.5e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 10 : loss  0.95479, train 0.06079, valid 0.09077, best 0.1088, lr1.9e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 15 : loss  0.95980, train 0.05378, valid 0.08989, best 0.1088, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 20 : loss  0.95653, train 0.05868, valid 0.09628, best 0.1088, lr9.4e-03\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 25 : loss  0.94722, train 0.06945, valid 0.09246, best 0.1088, lr3.1e-03\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 27 : loss  0.94744, train 0.06872, valid 0.09692, best 0.1088, lr6.3e-03, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep#  0 : loss  0.98369, train 0.02340, valid 0.03002, best 0.0300, lr1.3e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep#  5 : loss  0.95828, train 0.05107, valid 0.06808, best 0.0681, lr2.5e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 10 : loss  0.95461, train 0.05576, valid 0.07175, best 0.0717, lr1.9e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 15 : loss  0.94881, train 0.06140, valid 0.08070, best 0.0807, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 20 : loss  0.94775, train 0.06263, valid 0.08426, best 0.0843, lr9.5e-06\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 25 : loss  0.94667, train 0.06452, valid 0.08419, best 0.0854, lr3.2e-06\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 27 : loss  0.94654, train 0.06483, valid 0.08211, best 0.0862, lr6.3e-06, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep#  0 : loss  1.01322, train-0.01578, valid-0.03988, best-0.0399, lr1.3e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep#  5 : loss  0.99493, train 0.01749, valid 0.04998, best 0.0568, lr2.5e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 10 : loss  0.99429, train 0.00860, valid 0.05240, best 0.0568, lr1.9e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 15 : loss  0.99658, train 0.00630, valid 0.04902, best 0.0568, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 20 : loss  0.99310, train 0.01069, valid 0.04645, best 0.0568, lr9.4e-02\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 25 : loss  0.99509, train 0.01065, valid 0.03617, best 0.0568, lr3.1e-02\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 06:50:16|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #3 @20170103|Retrain#4 Ep#140 EarlyStop|Train 0.0113 Valid 0.0273 BestVal 0.1635|Cost 11.5Min,  4.9Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 06:53:05|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #0 @20170704|FirstBite Ep# 32 EarlyStop|Train 0.2323 Valid 0.1457 BestVal 0.1457|Cost  2.7Min,  4.9Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 07:04:24|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #1 @20170704|Retrain#4 Ep#135 EarlyStop|Train 0.0500 Valid 0.0525 BestVal 0.1589|Cost 11.3Min,  5.0Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 07:16:40|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #2 @20170704|Retrain#4 Ep#140 EarlyStop|Train 0.0004 Valid 0.0089 BestVal 0.1642|Cost 12.3Min,  5.2Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 07:19:20|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #3 @20170704|FirstBite Ep# 32 EarlyStop|Train 0.2010 Valid 0.1606 BestVal 0.1606|Cost  2.7Min,  4.8Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 07:24:24|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #0 @20171226|FirstBite Ep# 55 EarlyStop|Train 0.2479 Valid 0.1260 BestVal 0.1260|Cost  4.9Min,  5.3Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 07:29:57|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #1 @20171226|FirstBite Ep# 67 EarlyStop|Train 0.2500 Valid 0.1142 BestVal 0.1142|Cost  5.5Min,  4.9Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 07:35:39|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #2 @20171226|FirstBite Ep# 66 EarlyStop|Train 0.2048 Valid 0.1088 BestVal 0.1088|Cost  5.7Min,  5.1Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 07:38:58|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #3 @20171226|FirstBite Ep# 40 EarlyStop|Train 0.2089 Valid 0.1486 BestVal 0.1486|Cost  3.3Min,  4.8Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 07:50:46|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #0 @20180627|Retrain#4 Ep#135 EarlyStop|Train 0.0010 Valid 0.0151 BestVal 0.1712|Cost 11.7Min,  5.2Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 07:55:24|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #1 @20180627|FirstBite Ep# 62 EarlyStop|Train 0.2644 Valid 0.1294 BestVal 0.1294|Cost  4.6Min,  4.4Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 07:58:23|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #2 @20180627|FirstBite Ep# 34 EarlyStop|Train 0.2039 Valid 0.1447 BestVal 0.1447|Cost  3.0Min,  5.1Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 08:02:00|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #3 @20180627|FirstBite Ep# 42 EarlyStop|Train 0.2062 Valid 0.1384 BestVal 0.1384|Cost  3.6Min,  5.0Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 08:06:29|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #0 @20181220|FirstBite Ep# 43 EarlyStop|Train 0.1949 Valid 0.0910 BestVal 0.0910|Cost  4.4Min,  6.0Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 08:19:51|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #1 @20181220|Retrain#4 Ep#155 EarlyStop|Train 0.0269 Valid 0.0076 BestVal 0.1633|Cost 13.4Min,  5.1Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 08:22:45|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #2 @20181220|FirstBite Ep# 33 EarlyStop|Train 0.2123 Valid 0.1585 BestVal 0.1585|Cost  2.9Min,  5.1Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 08:25:59|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #3 @20181220|FirstBite Ep# 39 EarlyStop|Train 0.2131 Valid 0.1456 BestVal 0.1456|Cost  3.2Min,  4.8Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 08:29:10|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #0 @20190624|FirstBite Ep# 35 EarlyStop|Train 0.2434 Valid 0.1287 BestVal 0.1287|Cost  3.1Min,  5.1Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 08:32:25|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #1 @20190624|FirstBite Ep# 38 EarlyStop|Train 0.2438 Valid 0.1360 BestVal 0.1360|Cost  3.2Min,  5.0Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 08:35:45|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #2 @20190624|FirstBite Ep# 38 EarlyStop|Train 0.2201 Valid 0.1378 BestVal 0.1378|Cost  3.3Min,  5.1Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 08:38:41|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #3 @20190624|FirstBite Ep# 35 EarlyStop|Train 0.2154 Valid 0.1362 BestVal 0.1362|Cost  2.9Min,  4.8Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 08:43:21|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #0 @20191217|FirstBite Ep# 51 EarlyStop|Train 0.2388 Valid 0.1343 BestVal 0.1343|Cost  4.6Min,  5.3Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 08:46:46|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #1 @20191217|FirstBite Ep# 40 EarlyStop|Train 0.2423 Valid 0.1347 BestVal 0.1347|Cost  3.4Min,  5.0Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 08:49:55|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #2 @20191217|FirstBite Ep# 35 EarlyStop|Train 0.2154 Valid 0.1295 BestVal 0.1295|Cost  3.1Min,  5.2Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 08:55:43|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #3 @20191217|FirstBite Ep# 67 EarlyStop|Train 0.2233 Valid 0.1314 BestVal 0.1314|Cost  5.8Min,  5.1Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 08:59:25|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #0 @20200617|FirstBite Ep# 39 EarlyStop|Train 0.2493 Valid 0.1155 BestVal 0.1155|Cost  3.6Min,  5.4Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 09:03:23|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #1 @20200617|FirstBite Ep# 45 EarlyStop|Train 0.1936 Valid 0.1055 BestVal 0.1055|Cost  4.0Min,  5.2Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 09:07:00|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #2 @20200617|FirstBite Ep# 38 EarlyStop|Train 0.2225 Valid 0.1159 BestVal 0.1159|Cost  3.6Min,  5.5Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 09:12:17|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #3 @20200617|FirstBite Ep# 63 EarlyStop|Train 0.2194 Valid 0.1270 BestVal 0.1270|Cost  5.3Min,  4.9Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 09:16:27|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #0 @20201214|FirstBite Ep# 43 EarlyStop|Train 0.2094 Valid 0.1095 BestVal 0.1095|Cost  4.0Min,  5.5Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 09:19:32|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #1 @20201214|FirstBite Ep# 37 EarlyStop|Train 0.2422 Valid 0.1190 BestVal 0.1190|Cost  3.1Min,  4.9Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 09:23:08|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #2 @20201214|FirstBite Ep# 40 EarlyStop|Train 0.2210 Valid 0.1133 BestVal 0.1133|Cost  3.6Min,  5.2Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 09:28:20|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #3 @20201214|FirstBite Ep# 62 EarlyStop|Train 0.2311 Valid 0.1154 BestVal 0.1154|Cost  5.2Min,  4.9Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 09:32:19|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #0 @20210615|FirstBite Ep# 41 EarlyStop|Train 0.2548 Valid 0.1022 BestVal 0.1022|Cost  3.8Min,  5.5Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 09:35:13|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #1 @20210615|FirstBite Ep# 34 EarlyStop|Train 0.2416 Valid 0.0997 BestVal 0.0997|Cost  2.9Min,  4.9Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 09:38:04|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #2 @20210615|FirstBite Ep# 33 EarlyStop|Train 0.2093 Valid 0.0912 BestVal 0.0912|Cost  2.8Min,  5.0Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 09:41:41|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #3 @20210615|FirstBite Ep# 42 EarlyStop|Train 0.2069 Valid 0.0980 BestVal 0.0980|Cost  3.6Min,  5.0Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 09:45:39|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #0 @20211209|FirstBite Ep# 41 EarlyStop|Train 0.2496 Valid 0.0771 BestVal 0.0771|Cost  3.8Min,  5.5Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 09:50:05|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #1 @20211209|FirstBite Ep# 51 EarlyStop|Train 0.2444 Valid 0.0879 BestVal 0.0879|Cost  4.4Min,  5.1Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 10:01:20|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #2 @20211209|Retrain#1 Ep#121 EarlyStop|Train 0.1856 Valid 0.0871 BestVal 0.0841|Cost 11.2Min,  5.5Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 10:04:09|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #3 @20211209|FirstBite Ep# 33 EarlyStop|Train 0.2140 Valid 0.0878 BestVal 0.0878|Cost  2.8Min,  4.9Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 10:08:58|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #0 @20220613|FirstBite Ep# 51 EarlyStop|Train 0.2313 Valid 0.0958 BestVal 0.0958|Cost  4.7Min,  5.4Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 10:21:02|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #1 @20220613|Retrain#4 Ep#140 EarlyStop|Train 0.0218 Valid 0.0246 BestVal 0.0970|Cost 12.1Min,  5.1Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 10:34:04|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #2 @20220613|Retrain#4 Ep#145 EarlyStop|Train 0.0087 Valid 0.0107 BestVal 0.0988|Cost 13.0Min,  5.3Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 10:39:03|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #3 @20220613|FirstBite Ep# 58 EarlyStop|Train 0.2228 Valid 0.0867 BestVal 0.0867|Cost  5.0Min,  5.0Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 10:43:54|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #0 @20221206|FirstBite Ep# 50 EarlyStop|Train 0.2352 Valid 0.0944 BestVal 0.0944|Cost  4.7Min,  5.6Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 10:55:44|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #1 @20221206|Retrain#4 Ep#135 EarlyStop|Train 0.0333 Valid 0.0555 BestVal 0.0956|Cost 11.8Min,  5.2Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 11:07:23|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #2 @20221206|Retrain#4 Ep#130 EarlyStop|Train 0.0453 Valid 0.0522 BestVal 0.1017|Cost 11.6Min,  5.3Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 11:15:08|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #3 @20221206|Retrain#2 Ep# 92 EarlyStop|Train 0.1521 Valid 0.0905 BestVal 0.0984|Cost  7.7Min,  5.0Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 11:26:48|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #0 @20230606|Retrain#4 Ep#120 EarlyStop|Train 0.0090 Valid 0.0213 BestVal 0.1196|Cost 11.5Min,  5.7Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 11:37:23|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #1 @20230606|Retrain#4 Ep#120 EarlyStop|Train 0.0027 Valid 0.0098 BestVal 0.1161|Cost 10.6Min,  5.2Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 11:49:32|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #2 @20230606|Retrain#4 Ep#133 EarlyStop|Train 0.0421 Valid 0.0457 BestVal 0.1096|Cost 12.1Min,  5.4Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 11:59:22|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #3 @20230606|Retrain#4 Ep#115 EarlyStop|Train 0.0107 Valid 0.0256 BestVal 0.1089|Cost  9.8Min,  5.1Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 12:14:06|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #0 @20231201|Retrain#4 Ep#145 EarlyStop|Train 0.0007 Valid-0.0081 BestVal 0.1191|Cost 14.6Min,  6.0Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 12:18:03|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #1 @20231201|FirstBite Ep# 41 EarlyStop|Train 0.2188 Valid 0.0979 BestVal 0.0979|Cost  3.9Min,  5.6Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 12:29:15|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #2 @20231201|Retrain#4 Ep#120 EarlyStop|Train-0.0009 Valid-0.0089 BestVal 0.1178|Cost 11.2Min,  5.5Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 12:39:53|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #3 @20231201|Retrain#4 Ep#115 EarlyStop|Train 0.0145 Valid 0.0421 BestVal 0.1278|Cost 10.6Min,  5.5Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 12:43:36|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #0 @20240604|FirstBite Ep# 35 EarlyStop|Train 0.2150 Valid 0.1249 BestVal 0.1249|Cost  3.6Min,  6.0Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 12:58:06|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #1 @20240604|Retrain#4 Ep#155 EarlyStop|Train 0.0184 Valid 0.0377 BestVal 0.1289|Cost 14.5Min,  5.6Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 13:04:47|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #2 @20240604|FirstBite Ep# 64 EarlyStop|Train 0.1909 Valid 0.1220 BestVal 0.1220|Cost  6.7Min,  6.1Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 13:07:34|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.5 #3 @20240604|FirstBite Ep# 32 EarlyStop|Train 0.1906 Valid 0.1180 BestVal 0.1180|Cost  2.8Min,  5.0Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-08-06 13:07:34|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Fit], Cost 6.8 Hours, 6.4 Min/model, 5.4 Sec/Epoch\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-08-06 13:07:34|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Test] at Tue Aug  6 13:07:34 2024!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-08-06 13:08:54|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mTesting Mean Score(spearman):\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>risk_att_gru.0</th>\n",
       "      <th>risk_att_gru.1</th>\n",
       "      <th>risk_att_gru.2</th>\n",
       "      <th>risk_att_gru.3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>best</th>\n",
       "      <th>best</th>\n",
       "      <th>best</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20170103</th>\n",
       "      <td>0.139</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20170704</th>\n",
       "      <td>0.126</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20171226</th>\n",
       "      <td>0.126</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20180627</th>\n",
       "      <td>0.142</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20181220</th>\n",
       "      <td>0.089</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190624</th>\n",
       "      <td>0.111</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20191217</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20200617</th>\n",
       "      <td>0.101</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201214</th>\n",
       "      <td>0.088</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20210615</th>\n",
       "      <td>0.073</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20211209</th>\n",
       "      <td>0.108</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20220613</th>\n",
       "      <td>0.120</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20221206</th>\n",
       "      <td>0.085</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20230606</th>\n",
       "      <td>0.140</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20231201</th>\n",
       "      <td>0.146</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20240604</th>\n",
       "      <td>0.060</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg</th>\n",
       "      <td>0.112</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sum</th>\n",
       "      <td>205.113</td>\n",
       "      <td>210.254</td>\n",
       "      <td>197.098</td>\n",
       "      <td>203.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Std</th>\n",
       "      <td>0.081</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>59.284</td>\n",
       "      <td>61.828</td>\n",
       "      <td>55.932</td>\n",
       "      <td>59.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IR</th>\n",
       "      <td>6.787</td>\n",
       "      <td>7.079</td>\n",
       "      <td>6.404</td>\n",
       "      <td>6.804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         risk_att_gru.0 risk_att_gru.1 risk_att_gru.2 risk_att_gru.3\n",
       "              best           best           best           best     \n",
       "20170103       0.139          0.141          0.106          0.136   \n",
       "20170704       0.126          0.109          0.116          0.129   \n",
       "20171226       0.126          0.124          0.121          0.123   \n",
       "20180627       0.142          0.130          0.120          0.124   \n",
       "20181220       0.089          0.133          0.133          0.127   \n",
       "20190624       0.111          0.121          0.108          0.113   \n",
       "20191217       0.100          0.106          0.106          0.096   \n",
       "20200617       0.101          0.099          0.088          0.105   \n",
       "20201214       0.088          0.085          0.085          0.078   \n",
       "20210615       0.073          0.078          0.083          0.080   \n",
       "20211209       0.108          0.102          0.101          0.116   \n",
       "20220613       0.120          0.117          0.129          0.119   \n",
       "20221206       0.085          0.103          0.105          0.083   \n",
       "20230606       0.140          0.142          0.133          0.128   \n",
       "20231201       0.146          0.137          0.095          0.119   \n",
       "20240604       0.060          0.090          0.051          0.080   \n",
       "Avg            0.112          0.115          0.108          0.111   \n",
       "Sum          205.113        210.254        197.098        203.467   \n",
       "Std            0.081          0.080          0.082          0.080   \n",
       "T             59.284         61.828         55.932         59.426   \n",
       "IR             6.787          7.079          6.404          6.804   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-08-06 13:08:55|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Test], Cost 80.5 Secs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results are saved to /home/mengkjin/Workspace/learndl/model/risk_att_gru_day.5/detailed_analysis/test.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num</th>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>best</th>\n",
       "      <td>-2.024%</td>\n",
       "      <td>-0.852%</td>\n",
       "      <td>-0.574%</td>\n",
       "      <td>-0.336%</td>\n",
       "      <td>-0.205%</td>\n",
       "      <td>-0.179%</td>\n",
       "      <td>-0.039%</td>\n",
       "      <td>-0.031%</td>\n",
       "      <td>0.065%</td>\n",
       "      <td>0.074%</td>\n",
       "      <td>0.174%</td>\n",
       "      <td>0.235%</td>\n",
       "      <td>0.279%</td>\n",
       "      <td>0.332%</td>\n",
       "      <td>0.390%</td>\n",
       "      <td>0.430%</td>\n",
       "      <td>0.543%</td>\n",
       "      <td>0.556%</td>\n",
       "      <td>0.549%</td>\n",
       "      <td>0.668%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>best</th>\n",
       "      <td>-1.994%</td>\n",
       "      <td>-0.914%</td>\n",
       "      <td>-0.518%</td>\n",
       "      <td>-0.371%</td>\n",
       "      <td>-0.242%</td>\n",
       "      <td>-0.197%</td>\n",
       "      <td>-0.122%</td>\n",
       "      <td>0.003%</td>\n",
       "      <td>0.088%</td>\n",
       "      <td>0.102%</td>\n",
       "      <td>0.203%</td>\n",
       "      <td>0.257%</td>\n",
       "      <td>0.264%</td>\n",
       "      <td>0.356%</td>\n",
       "      <td>0.338%</td>\n",
       "      <td>0.421%</td>\n",
       "      <td>0.497%</td>\n",
       "      <td>0.546%</td>\n",
       "      <td>0.591%</td>\n",
       "      <td>0.754%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>best</th>\n",
       "      <td>-1.808%</td>\n",
       "      <td>-0.654%</td>\n",
       "      <td>-0.413%</td>\n",
       "      <td>-0.286%</td>\n",
       "      <td>-0.178%</td>\n",
       "      <td>-0.109%</td>\n",
       "      <td>-0.048%</td>\n",
       "      <td>0.004%</td>\n",
       "      <td>0.124%</td>\n",
       "      <td>0.093%</td>\n",
       "      <td>0.129%</td>\n",
       "      <td>0.153%</td>\n",
       "      <td>0.191%</td>\n",
       "      <td>0.287%</td>\n",
       "      <td>0.280%</td>\n",
       "      <td>0.383%</td>\n",
       "      <td>0.380%</td>\n",
       "      <td>0.419%</td>\n",
       "      <td>0.501%</td>\n",
       "      <td>0.600%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>best</th>\n",
       "      <td>-2.056%</td>\n",
       "      <td>-0.810%</td>\n",
       "      <td>-0.541%</td>\n",
       "      <td>-0.363%</td>\n",
       "      <td>-0.190%</td>\n",
       "      <td>-0.053%</td>\n",
       "      <td>-0.052%</td>\n",
       "      <td>-0.070%</td>\n",
       "      <td>0.126%</td>\n",
       "      <td>0.159%</td>\n",
       "      <td>0.234%</td>\n",
       "      <td>0.229%</td>\n",
       "      <td>0.288%</td>\n",
       "      <td>0.340%</td>\n",
       "      <td>0.342%</td>\n",
       "      <td>0.401%</td>\n",
       "      <td>0.449%</td>\n",
       "      <td>0.472%</td>\n",
       "      <td>0.488%</td>\n",
       "      <td>0.665%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "group       1        2        3        4        5        6        7        8        9       10      11      12      13      14      15      16      17      18      19      20  \n",
       "num type                                                                                                                                                                        \n",
       "0   best  -2.024%  -0.852%  -0.574%  -0.336%  -0.205%  -0.179%  -0.039%  -0.031%  0.065%  0.074%  0.174%  0.235%  0.279%  0.332%  0.390%  0.430%  0.543%  0.556%  0.549%  0.668%\n",
       "1   best  -1.994%  -0.914%  -0.518%  -0.371%  -0.242%  -0.197%  -0.122%   0.003%  0.088%  0.102%  0.203%  0.257%  0.264%  0.356%  0.338%  0.421%  0.497%  0.546%  0.591%  0.754%\n",
       "2   best  -1.808%  -0.654%  -0.413%  -0.286%  -0.178%  -0.109%  -0.048%   0.004%  0.124%  0.093%  0.129%  0.153%  0.191%  0.287%  0.280%  0.383%  0.380%  0.419%  0.501%  0.600%\n",
       "3   best  -2.056%  -0.810%  -0.541%  -0.363%  -0.190%  -0.053%  -0.052%  -0.070%  0.126%  0.159%  0.234%  0.229%  0.288%  0.340%  0.342%  0.401%  0.449%  0.472%  0.488%  0.665%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped Return Results are saved to /home/mengkjin/Workspace/learndl/model/risk_att_gru_day.5/detailed_analysis/group.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>factor_name</th>\n",
       "      <th>benchmark</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>pf</th>\n",
       "      <th>bm</th>\n",
       "      <th>excess</th>\n",
       "      <th>annualized</th>\n",
       "      <th>mdd</th>\n",
       "      <th>te</th>\n",
       "      <th>ir</th>\n",
       "      <th>calmar</th>\n",
       "      <th>turnover</th>\n",
       "      <th>mdd_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>best</td>\n",
       "      <td>csi300</td>\n",
       "      <td>20170104</td>\n",
       "      <td>20240718</td>\n",
       "      <td>142.48%</td>\n",
       "      <td>24.21%</td>\n",
       "      <td>118.27%</td>\n",
       "      <td>9.14%</td>\n",
       "      <td>4.83%</td>\n",
       "      <td>3.84%</td>\n",
       "      <td>2.383</td>\n",
       "      <td>1.895</td>\n",
       "      <td>147.097</td>\n",
       "      <td>20240508-20240718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>best</td>\n",
       "      <td>csi500</td>\n",
       "      <td>20170104</td>\n",
       "      <td>20240718</td>\n",
       "      <td>198.41%</td>\n",
       "      <td>-15.40%</td>\n",
       "      <td>213.80%</td>\n",
       "      <td>17.98%</td>\n",
       "      <td>10.56%</td>\n",
       "      <td>5.71%</td>\n",
       "      <td>3.149</td>\n",
       "      <td>1.702</td>\n",
       "      <td>147.212</td>\n",
       "      <td>20210331-20210915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best</td>\n",
       "      <td>csi1000</td>\n",
       "      <td>20170104</td>\n",
       "      <td>20240718</td>\n",
       "      <td>171.62%</td>\n",
       "      <td>-40.37%</td>\n",
       "      <td>211.99%</td>\n",
       "      <td>21.74%</td>\n",
       "      <td>11.97%</td>\n",
       "      <td>5.91%</td>\n",
       "      <td>3.681</td>\n",
       "      <td>1.816</td>\n",
       "      <td>147.372</td>\n",
       "      <td>20210408-20210915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  factor_name benchmark    start      end      pf       bm     excess  annualized   mdd     te     ir   calmar turnover     mdd_period    \n",
       "1     best       csi300  20170104  20240718  142.48%   24.21%  118.27%    9.14%     4.83%  3.84%  2.383  1.895  147.097  20240508-20240718\n",
       "2     best       csi500  20170104  20240718  198.41%  -15.40%  213.80%   17.98%    10.56%  5.71%  3.149  1.702  147.212  20210331-20210915\n",
       "0     best      csi1000  20170104  20240718  171.62%  -40.37%  211.99%   21.74%    11.97%  5.91%  3.681  1.816  147.372  20210408-20210915"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-08-06 13:32:08|MOD:time        |\u001b[0m: \u001b[1m\u001b[31mMain Process Finished! Cost 7 Hours 12 Minutes 10.9 Seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytic datas are saved to /home/mengkjin/Workspace/learndl/model/risk_att_gru_day.5/detailed_analysis/perf.xlsx\n",
      "Analytic plots are saved to /home/mengkjin/Workspace/learndl/model/risk_att_gru_day.5/detailed_analysis/plot.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.nn_model.trainer.trainers.net.NetTrainer at 0x7c645d54bdf0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.api import Trainer  \n",
    "app = Trainer.initialize(stage = 0 , resume = 0 , checkname= 1)\n",
    "app.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device name: NVIDIA GeForce RTX 4090\n",
      "try using /home/mengkjin/Workspace/learndl/data/DataSet/30m.20240703.pt , success!\n",
      "Load  2 DataBlocks...... finished! Cost 1.08 secs\n",
      "Align 2 DataBlocks...... finished! Cost 0.76 secs\n",
      "Pre-Norming method of [30m] : {'divlast': False, 'histnorm': True}\n"
     ]
    }
   ],
   "source": [
    "from src.api import HiddenExtractor\n",
    "extractor = HiddenExtractor('resnet_gru_30m' , model_nums=[1] , model_types=['best'])\n",
    "extractor.extract_hidden('update' , deploy = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device name: NVIDIA GeForce RTX 4090\n",
      "predict is False , Data Processing start!\n",
      "6 datas :['y', 'day', '30m', 'style', 'indus', 'week']\n",
      "y blocks loading start!\n",
      " --> labels blocks reading [ret10_lag] DataBase...... finished! Cost 19.78 secs\n",
      " --> labels blocks reading [ret20_lag] DataBase...... finished! Cost 18.38 secs\n",
      " --> labels blocks merging (2)...... finished! Cost 3.39 secs\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 67.56 secs\n",
      "y blocks loading finished! Cost 120.07 secs\n",
      "y blocks process...... finished! Cost 46.25 secs\n",
      "y blocks masking...... finished! Cost 0.76 secs\n",
      "y blocks saving ...... finished! Cost 3.51 secs\n",
      "y blocks norming...... finished! Cost 0.00 secs\n",
      "y finished! Cost 170.84 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "day blocks loading start!\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 29.59 secs\n",
      "day blocks loading finished! Cost 29.62 secs\n",
      "day blocks process...... finished! Cost 4.06 secs\n",
      "day blocks masking...... finished! Cost 0.86 secs\n",
      "day blocks saving ...... finished! Cost 3.50 secs\n",
      "day blocks norming...... finished! Cost 8.17 secs\n",
      "day finished! Cost 46.41 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "30m blocks loading start!\n",
      " --> trade blocks reading [30min] DataBase...... finished! Cost 66.96 secs\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 24.59 secs\n",
      "30m blocks loading finished! Cost 92.25 secs\n",
      "30m blocks process...... finished! Cost 37.03 secs\n",
      "30m blocks masking...... finished! Cost 2.11 secs\n",
      "30m blocks saving ...... finished! Cost 41.98 secs\n",
      "30m blocks norming...... finished! Cost 3.73 secs\n",
      "30m finished! Cost 177.29 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "style blocks loading start!\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 32.81 secs\n",
      "style blocks loading finished! Cost 32.83 secs\n",
      "style blocks process...... finished! Cost 0.00 secs\n",
      "style blocks masking...... finished! Cost 0.91 secs\n",
      "style blocks saving ...... finished! Cost 5.58 secs\n",
      "style blocks norming...... finished! Cost 0.00 secs\n",
      "style finished! Cost 39.52 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "indus blocks loading start!\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 59.46 secs\n",
      "indus blocks loading finished! Cost 59.46 secs\n",
      "indus blocks process...... finished! Cost 0.00 secs\n",
      "indus blocks masking...... finished! Cost 2.28 secs\n",
      "indus blocks saving ...... finished! Cost 29.85 secs\n",
      "indus blocks norming...... finished! Cost 0.00 secs\n",
      "indus finished! Cost 91.79 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "week blocks loading start!\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 25.89 secs\n",
      "week blocks loading finished! Cost 25.92 secs\n",
      "week blocks process...... finished! Cost 28.65 secs\n",
      "week blocks masking...... finished! Cost 2.27 secs\n",
      "week blocks saving ...... finished! Cost 25.41 secs\n",
      "week blocks norming...... finished! Cost 5.53 secs\n",
      "week finished! Cost 87.97 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "Data Processing Finished! Cost 613.81 Seconds\n",
      "predict is True , Data Processing start!\n",
      "6 datas :['y', 'day', '30m', 'style', 'indus', 'week']\n",
      "y blocks loading start!\n",
      " --> labels blocks reading [ret10_lag] DataBase...... finished! Cost 0.69 secs\n",
      " --> labels blocks reading [ret20_lag] DataBase...... finished! Cost 0.63 secs\n",
      " --> labels blocks merging (2)...... finished! Cost 0.10 secs\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 2.67 secs\n",
      "y blocks loading finished! Cost 4.30 secs\n",
      "y blocks process...... finished! Cost 2.01 secs\n",
      "y blocks masking...... finished! Cost 0.07 secs\n",
      "y blocks saving ...... finished! Cost 0.13 secs\n",
      "y blocks norming...... finished! Cost 0.00 secs\n",
      "y finished! Cost 6.68 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "day blocks loading start!\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 1.08 secs\n",
      "day blocks loading finished! Cost 1.08 secs\n",
      "day blocks process...... finished! Cost 0.10 secs\n",
      "day blocks masking...... finished! Cost 0.07 secs\n",
      "day blocks saving ...... finished! Cost 0.14 secs\n",
      "day blocks norming...... finished! Cost 0.00 secs\n",
      "day finished! Cost 1.56 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "30m blocks loading start!\n",
      " --> trade blocks reading [30min] DataBase...... finished! Cost 4.71 secs\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 0.99 secs\n",
      "30m blocks loading finished! Cost 5.75 secs\n",
      "30m blocks process...... finished! Cost 1.50 secs\n",
      "30m blocks masking...... finished! Cost 0.12 secs\n",
      "30m blocks saving ...... finished! Cost 1.39 secs\n",
      "30m blocks norming...... finished! Cost 0.00 secs\n",
      "30m finished! Cost 8.93 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "style blocks loading start!\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 1.49 secs\n",
      "style blocks loading finished! Cost 1.49 secs\n",
      "style blocks process...... finished! Cost 0.00 secs\n",
      "style blocks masking...... finished! Cost 0.07 secs\n",
      "style blocks saving ...... finished! Cost 0.20 secs\n",
      "style blocks norming...... finished! Cost 0.00 secs\n",
      "style finished! Cost 1.91 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "indus blocks loading start!\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 2.61 secs\n",
      "indus blocks loading finished! Cost 2.61 secs\n",
      "indus blocks process...... finished! Cost 0.00 secs\n",
      "indus blocks masking...... finished! Cost 0.10 secs\n",
      "indus blocks saving ...... finished! Cost 1.08 secs\n",
      "indus blocks norming...... finished! Cost 0.00 secs\n",
      "indus finished! Cost 3.98 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "week blocks loading start!\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 2.14 secs\n",
      "week blocks loading finished! Cost 2.15 secs\n",
      "week blocks process...... finished! Cost 1.57 secs\n",
      "week blocks masking...... finished! Cost 0.14 secs\n",
      "week blocks saving ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[44m24-07-20 01:02:48|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mModel Specifics:\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-07-20 01:02:48|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Data] at Sat Jul 20 01:02:48 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... finished! Cost 1.81 secs\n",
      "week blocks norming...... finished! Cost 0.00 secs\n",
      "week finished! Cost 5.83 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "Data Processing Finished! Cost 28.90 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "--Process Queue : Data + Fit + Test\n",
      "--Confirm Resume Training!\n",
      "--Model_name is set to gru_day!\n",
      "Callback : ResetOptimizer(num_reset=2,trigger=40,recover_level=1.0,speedup2x=True,kwargs={}) , reset optimizer on some epoch (can speedup scheduler)\n",
      "Callback : CallbackTimer(verbosity=2,kwargs={}) , record time cost of callback hooks\n",
      "Callback : EarlyStoppage(patience=20,kwargs={}) , stop fitting when validation score cease to improve\n",
      "Callback : ValidationConverge(patience=5,eps=1e-05,kwargs={}) , stop fitting when valid_score converge\n",
      "Callback : EarlyExitRetrain(earliest=10,max_attempt=4,lr_multiplier=[1, 0.1, 10, 0.01, 100, 1],kwargs={}) , retrain with new lr if fitting stopped too early\n",
      "Callback : NanLossRetrain(max_attempt=4,kwargs={}) , retrain if fitting encounters nan loss\n",
      "Callback : BatchDisplay(verbosity=2,kwargs={}) , display batch progress bar\n",
      "Callback : StatusDisplay(verbosity=2,kwargs={}) , display epoch and event information\n",
      "Callback : DetailedAlphaAnalysis(use_num=avg,kwargs={}) , record and concat each model to Alpha model instance\n",
      "Callback : GroupReturnAnalysis(group_num=20,kwargs={}) , record and concat each model to Alpha model instance\n",
      "{'model_name': 'gru_day',\n",
      " 'model_module': 'gru',\n",
      " 'model.types': ['best', 'swalast', 'swabest'],\n",
      " 'model.lgbm_ensembler': False,\n",
      " 'data.type': 'day',\n",
      " 'data.labels': ['std_lag1_10'],\n",
      " 'random_seed': None,\n",
      " 'beg_date': 20170103,\n",
      " 'end_date': 99991231,\n",
      " 'sample_method': 'sequential',\n",
      " 'shuffle_option': 'epoch'}\n",
      "{'hidden_dim': [32, 64],\n",
      " 'seqlens': [{'day': 30, '30m': 30, 'dms': 30}],\n",
      " 'tra_seqlens': [{'hist_loss': 40}],\n",
      " 'dropout': [0.1],\n",
      " 'enc_in': [True],\n",
      " 'enc_att': [False],\n",
      " 'rnn_type': ['lstm'],\n",
      " 'rnn_att': [False],\n",
      " 'rnn_layers': [2],\n",
      " 'dec_mlp_layers': [2],\n",
      " 'num_output': [1],\n",
      " 'kernel_size': [3],\n",
      " 'hidden_as_factor': [False],\n",
      " 'ordered_param_group': [False],\n",
      " 'tra_num_states': [5]}\n",
      "Load  1 DataBlocks...... finished! Cost 0.34 secs\n",
      "Align 1 DataBlocks...... finished! Cost 0.98 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-07-20 01:02:50|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Data], Cost 2.5 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-07-20 01:02:50|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Fit] at Sat Jul 20 01:02:50 2024!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-20 01:02:50|MOD:mod         |\u001b[0m: \u001b[1m\u001b[34mFirst Iterance: (20170103 , 0)\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-07-20 01:02:50|MOD:time        |\u001b[0m: \u001b[1m\u001b[31mMain Process Finished! Cost 2.5 Seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load  1 DataBlocks...... finished! Cost 0.02 secs\n",
      "Align 1 DataBlocks...... finished! Cost 0.05 secs\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'data.hidden'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataAPI , Trainer\n\u001b[1;32m      2\u001b[0m DataAPI\u001b[38;5;241m.\u001b[39mreconstruct_train_data()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mTrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/learndl/src/nn_model/trainer/trainers/api.py:35\u001b[0m, in \u001b[0;36mTrainer.update_models\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m REG_MODELS:\n\u001b[1;32m     34\u001b[0m     config_path \u001b[38;5;241m=\u001b[39m TrainConfig\u001b[38;5;241m.\u001b[39mget_config_path(model\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresume\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/learndl/src/nn_model/trainer/trainers/basic.py:225\u001b[0m, in \u001b[0;36mTrainerModule.go\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgo\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m BigTimer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mcritical , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMain Process\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 225\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Workspace/learndl/src/nn_model/classes/mod.py:329\u001b[0m, in \u001b[0;36mBaseTrainer.main_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_configure_model()\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage_queue: \n\u001b[0;32m--> 329\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstage_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_summarize_model()\n",
      "File \u001b[0;32m~/Workspace/learndl/src/nn_model/classes/mod.py:346\u001b[0m, in \u001b[0;36mBaseTrainer.stage_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mfit_iter_num \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    345\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFirst Iterance: (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mmodel_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m , \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mmodel_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_fit_end()\n",
      "File \u001b[0;32m~/Workspace/learndl/src/nn_model/trainer/trainers/aggregator.py:171\u001b[0m, in \u001b[0;36mAggregatorTrainer.fit_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_fit_model_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_idx , \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mtrain_dataloader() , \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mval_dataloader())):\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mdataset_train()\n",
      "File \u001b[0;32m~/Workspace/learndl/src/nn_model/classes/mod.py:44\u001b[0m, in \u001b[0;36mBaseCB.hook_wrapper.<locals>.wrapper_with\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_with\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mat_enter(hook_name)\n\u001b[0;32m---> 44\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mat_exit(hook_name)\n",
      "File \u001b[0;32m~/Workspace/learndl/src/nn_model/trainer/trainers/aggregator.py:199\u001b[0m, in \u001b[0;36mAggregatorTrainer.on_fit_model_start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_fit_model_start\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_param\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Workspace/learndl/src/nn_model/trainer/trainers/aggregator.py:56\u001b[0m, in \u001b[0;36mAggregatorDataModule.setup\u001b[0;34m(self, stage, param, model_date)\u001b[0m\n\u001b[1;32m     54\u001b[0m hidden_df : pd\u001b[38;5;241m.\u001b[39mDataFrame \u001b[38;5;241m|\u001b[39m Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     55\u001b[0m ds_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m stage \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hidden_key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata.hidden\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m     57\u001b[0m     model_name , model_num , model_type \u001b[38;5;241m=\u001b[39m hidden_key\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     58\u001b[0m     hidden_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(PATH\u001b[38;5;241m.\u001b[39mhidden , model_name , \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.feather\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Workspace/learndl/src/nn_model/util/config.py:245\u001b[0m, in \u001b[0;36mTrainConfig.__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[0;32m--> 245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m , k): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/learndl/src/nn_model/util/config.py:78\u001b[0m, in \u001b[0;36mTrainParam.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m , key : \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParam\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'data.hidden'"
     ]
    }
   ],
   "source": [
    "from src.api import DataAPI , Trainer\n",
    "DataAPI.reconstruct_train_data()\n",
    "Trainer.update_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device name: NVIDIA GeForce RTX 4090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:10:43|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mModel Specifics:\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:10:43|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Data] at Mon Jun 24 01:10:43 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Process Queue : Data + Fit + Test\n",
      "--Confirm Resume Training!\n",
      "--Model_name is set to gru_day!\n",
      "Callback : ResetOptimizer(num_reset=2,trigger=40,recover_level=1.0,speedup2x=True) , reset optimizer on some epoch (can speedup scheduler)\n",
      "Callback : CallbackTimer(verbosity=2) , record time cost of callback hooks\n",
      "Callback : EarlyStoppage(patience=20) , stop fitting when validation score cease to improve\n",
      "Callback : ValidationConverge(patience=5,eps=1e-05) , stop fitting when valid_score converge\n",
      "Callback : EarlyExitRetrain(earliest=5,max_attempt=4,lr_multiplier=[1, 0.1, 10, 0.01, 100]) , retrain with new lr if fitting stopped too early\n",
      "Callback : NanLossRetrain(max_attempt=4) , retrain if fitting encounters nan loss\n",
      "Callback : BatchDisplay(verbosity=2) , display batch progress bar\n",
      "Callback : StatusDisplay(verbosity=2) , display epoch and event information\n",
      "{'random_seed': None,\n",
      " 'model_name': 'gruRES_day',\n",
      " 'model_module': 'gru',\n",
      " 'model_data_type': 'day',\n",
      " 'model_types': ['best', 'swalast', 'swabest'],\n",
      " 'labels': ['std_lag1_10'],\n",
      " 'beg_date': 20170103,\n",
      " 'end_date': 99991231,\n",
      " 'sample_method': 'train_shuffle',\n",
      " 'shuffle_option': 'epoch',\n",
      " 'lgbm_ensembler': False}\n",
      "{'hidden_dim': [32, 64],\n",
      " 'seqlens': [{'day': 30, '30m': 30, 'dms': 30}],\n",
      " 'tra_seqlens': [{'hist_loss': 40}],\n",
      " 'dropout': [0.1],\n",
      " 'enc_in': [True],\n",
      " 'enc_att': [False],\n",
      " 'rnn_type': ['lstm'],\n",
      " 'rnn_att': [False],\n",
      " 'rnn_layers': [2],\n",
      " 'dec_mlp_layers': [2],\n",
      " 'num_output': [1],\n",
      " 'kernel_size': [3],\n",
      " 'hidden_as_factor': [False],\n",
      " 'ordered_param_group': [False],\n",
      " 'tra_num_states': [5]}\n",
      "Load  2 DataBlocks...... finished! Cost 2.40 secs\n",
      "Align 2 DataBlocks...... finished! Cost 2.86 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:10:51|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Data], Cost 7.9 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:10:51|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Fit] at Mon Jun 24 01:10:51 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n",
      "score function of [spearman] calculated and success!\n",
      "loss function of [pearson] calculated and success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mFirstBite Ep#  0 : loss  0.99770, train 0.00391, valid 0.03668, best 0.0367, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  5 : loss  0.87023, train 0.12798, valid 0.09558, best 0.0956, lr2.5e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 10 : loss  0.85418, train 0.14255, valid 0.08890, best 0.0956, lr1.9e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 15 : loss  0.84138, train 0.15293, valid 0.08662, best 0.0956, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 20 : loss  0.83995, train 0.15505, valid 0.09025, best 0.0956, lr9.4e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 25 : loss  0.83040, train 0.16270, valid 0.08154, best 0.0956, lr3.1e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 25 : loss  0.83040, train 0.16270, valid 0.08154, best 0.0956, lr3.1e-04, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  0 : loss  0.99907, train 0.00307, valid-0.00235, best-0.0024, lr1.3e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  5 : loss  0.89798, train 0.10238, valid 0.07134, best 0.0839, lr2.5e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 10 : loss  0.88484, train 0.11407, valid 0.08712, best 0.0892, lr1.9e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 15 : loss  0.87704, train 0.12033, valid 0.08682, best 0.0892, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 20 : loss  0.87598, train 0.12115, valid 0.08665, best 0.0892, lr9.4e-05\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 25 : loss  0.87235, train 0.12489, valid 0.08559, best 0.0892, lr3.1e-05\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 25 : loss  0.87235, train 0.12489, valid 0.08559, best 0.0892, lr3.1e-05, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  0 : loss  1.00802, train-0.01361, valid-0.04341, best-0.0434, lr1.3e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  5 : loss  0.90600, train 0.09749, valid 0.08519, best 0.0985, lr2.5e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 10 : loss  0.88704, train 0.11519, valid 0.10017, best 0.1002, lr1.9e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 15 : loss  0.88873, train 0.11359, valid 0.09794, best 0.1002, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 20 : loss  0.89135, train 0.11055, valid 0.09254, best 0.1002, lr9.4e-03\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 25 : loss  0.88877, train 0.11064, valid 0.09957, best 0.1021, lr3.1e-03\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 30 : loss  0.88839, train 0.10964, valid 0.08501, best 0.1021, lr1.6e-03\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 35 : loss  0.88399, train 0.11418, valid 0.08975, best 0.1021, lr3.1e-03\u001b[0m\n",
      "\u001b[32mReset learn rate and scheduler at the end of epoch 39 , effective at epoch 40\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 40 : loss  0.88123, train 0.11494, valid 0.09168, best 0.1021, lr1.3e-02\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:16:36|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mgruRES_day #1 @20231201|Retrain#2 Ep# 96 EarlyStop|Train 0.1037 Valid 0.0934 BestVal 0.0956|Cost  5.7Min,  3.5Sec/Ep\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  0 : loss  1.00213, train-0.00346, valid-0.02870, best-0.0287, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  5 : loss  0.88101, train 0.11998, valid 0.10566, best 0.1118, lr2.5e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 10 : loss  0.86625, train 0.13116, valid 0.09471, best 0.1118, lr1.9e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 15 : loss  0.85764, train 0.13868, valid 0.09772, best 0.1118, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 20 : loss  0.85723, train 0.13898, valid 0.10404, best 0.1118, lr9.4e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 24 : loss  0.85347, train 0.14217, valid 0.09795, best 0.1118, lr1.6e-04, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  0 : loss  0.99619, train 0.00640, valid 0.02634, best 0.0263, lr1.3e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  5 : loss  0.91904, train 0.07677, valid 0.07904, best 0.0790, lr2.5e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 10 : loss  0.90607, train 0.09211, valid 0.09041, best 0.0904, lr1.9e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 15 : loss  0.89860, train 0.10379, valid 0.09553, best 0.0956, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 20 : loss  0.89763, train 0.10523, valid 0.09337, best 0.0956, lr9.4e-05\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 24 : loss  0.89522, train 0.10913, valid 0.09689, best 0.0970, lr1.6e-05, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  0 : loss  1.00127, train-0.00532, valid-0.02776, best-0.0278, lr1.3e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  5 : loss  0.90841, train 0.09496, valid 0.09364, best 0.1105, lr2.5e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 10 : loss  0.88931, train 0.11243, valid 0.09934, best 0.1105, lr1.9e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 15 : loss  0.88411, train 0.11520, valid 0.09632, best 0.1105, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 20 : loss  0.88303, train 0.11682, valid 0.10441, best 0.1105, lr9.4e-03\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 24 : loss  0.87640, train 0.12191, valid 0.10175, best 0.1105, lr1.6e-03, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep#  0 : loss  0.99942, train 0.00330, valid 0.03781, best 0.0378, lr1.3e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep#  5 : loss  0.96270, train 0.04376, valid 0.07316, best 0.0732, lr2.5e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 10 : loss  0.95829, train 0.04798, valid 0.07296, best 0.0736, lr1.9e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 15 : loss  0.95190, train 0.05224, valid 0.07273, best 0.0736, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 20 : loss  0.95024, train 0.05357, valid 0.07160, best 0.0736, lr9.5e-06\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 24 : loss  0.94829, train 0.05503, valid 0.07283, best 0.0736, lr1.7e-06, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep#  0 : loss  0.99623, train 0.00749, valid 0.03126, best 0.0313, lr1.3e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep#  5 : loss  0.97201, train 0.03669, valid 0.04230, best 0.0540, lr2.5e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 10 : loss  0.97588, train 0.03329, valid 0.03690, best 0.0540, lr1.9e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 15 : loss  0.97586, train 0.03358, valid 0.04005, best 0.0540, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 20 : loss  0.97032, train 0.04237, valid 0.04644, best 0.0540, lr9.4e-02\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:22:42|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mgruRES_day #0 @20240604|Retrain#4 Ep#125 EarlyStop|Train 0.0369 Valid 0.0350 BestVal 0.1118|Cost  6.0Min,  2.9Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:24:48|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mgruRES_day #1 @20240604|FirstBite Ep# 34 EarlyStop|Train 0.1667 Valid 0.0877 BestVal 0.0877|Cost  2.1Min,  3.6Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:24:48|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Fit], Cost 0.2 Hours, 4.7 Min/model, 3.3 Sec/Epoch\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:24:48|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Test] at Mon Jun 24 01:24:48 2024!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:24:48|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mEach Model Date Testing Mean Score(spearman):\u001b[0m\n",
      "\u001b[32mModels            0       0       0       1       1       1\u001b[0m\n",
      "\u001b[32mOutput         best swalast swabest    best swalast swabest\u001b[0m\n",
      "\u001b[32m20170103     0.1536  0.1525  0.1520  0.1525  0.1521  0.1520\u001b[0m\n",
      "\u001b[32m20170704     0.1373  0.1327  0.1365  0.1413  0.1373  0.1405\u001b[0m\n",
      "\u001b[32m20171226     0.1305  0.1323  0.1329  0.1291  0.1298  0.1300\u001b[0m\n",
      "\u001b[32m20180627     0.1225  0.1186  0.1223  0.1226  0.1210  0.1236\u001b[0m\n",
      "\u001b[32m20181220     0.0998  0.0990  0.1004  0.0958  0.0981  0.0987\u001b[0m\n",
      "\u001b[32m20190624     0.0970  0.0955  0.0972  0.0920  0.0908  0.0924\u001b[0m\n",
      "\u001b[32m20191217     0.1011  0.0991  0.1005  0.1042  0.1048  0.1047\u001b[0m\n",
      "\u001b[32m20200617     0.0970  0.0963  0.0978  0.0947  0.0927  0.0946\u001b[0m\n",
      "\u001b[32m20201214     0.0837  0.0792  0.0842  0.0759  0.0766  0.0739\u001b[0m\n",
      "\u001b[32m20210615     0.0605  0.0572  0.0608  0.0689  0.0666  0.0662\u001b[0m\n",
      "\u001b[32m20211209     0.0935  0.0954  0.0962  0.1084  0.1106  0.1084\u001b[0m\n",
      "\u001b[32m20220613     0.0931  0.0909  0.0813  0.0857  0.0829  0.0876\u001b[0m\n",
      "\u001b[32m20221206     0.0650  0.0616  0.0635  0.0580  0.0576  0.0497\u001b[0m\n",
      "\u001b[32m20230606     0.0906  0.0857  0.0872  0.0868  0.0885  0.0856\u001b[0m\n",
      "\u001b[32m20231201     0.1217  0.1221  0.1235  0.1082  0.1025  0.1008\u001b[0m\n",
      "\u001b[32m20240604    -0.0130  0.0400 -0.0266  0.0401  0.0503  0.0572\u001b[0m\n",
      "\u001b[32mAllTimeAvg   0.1024  0.1008  0.1016  0.1012  0.1005  0.1003\u001b[0m\n",
      "\u001b[32mAllTimeSum   185.48  182.66  184.04  183.36  182.05  181.72\u001b[0m\n",
      "\u001b[32mStd          0.0668  0.0665  0.0669  0.0666  0.0656  0.0665\u001b[0m\n",
      "\u001b[32mTValue        65.23   64.56   64.64   64.69   65.24   64.18\u001b[0m\n",
      "\u001b[32mAnnIR        7.5077  7.4304  7.4389  7.4445  7.5079  7.3860\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:25:46|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Test], Cost 57.6 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:25:46|MOD:time        |\u001b[0m: \u001b[1m\u001b[31mMain Process Finished! Cost 15 Minutes 3.3 Seconds\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:25:46|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mModel Specifics:\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:25:46|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Data] at Mon Jun 24 01:25:46 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Process Queue : Data + Fit + Test\n",
      "--Confirm Resume Training!\n",
      "--Model_name is set to gruRTN_day!\n",
      "Callback : ResetOptimizer(num_reset=2,trigger=40,recover_level=1.0,speedup2x=True) , reset optimizer on some epoch (can speedup scheduler)\n",
      "Callback : CallbackTimer(verbosity=2) , record time cost of callback hooks\n",
      "Callback : EarlyStoppage(patience=20) , stop fitting when validation score cease to improve\n",
      "Callback : ValidationConverge(patience=5,eps=1e-05) , stop fitting when valid_score converge\n",
      "Callback : EarlyExitRetrain(earliest=5,max_attempt=4,lr_multiplier=[1, 0.1, 10, 0.01, 100]) , retrain with new lr if fitting stopped too early\n",
      "Callback : NanLossRetrain(max_attempt=4) , retrain if fitting encounters nan loss\n",
      "Callback : BatchDisplay(verbosity=2) , display batch progress bar\n",
      "Callback : StatusDisplay(verbosity=2) , display epoch and event information\n",
      "{'random_seed': None,\n",
      " 'model_name': 'gruRTN_day',\n",
      " 'model_module': 'gru',\n",
      " 'model_data_type': 'day',\n",
      " 'model_types': ['best', 'swalast', 'swabest'],\n",
      " 'labels': ['rtn_lag1_10'],\n",
      " 'beg_date': 20170103,\n",
      " 'end_date': 99991231,\n",
      " 'sample_method': 'train_shuffle',\n",
      " 'shuffle_option': 'epoch',\n",
      " 'lgbm_ensembler': False}\n",
      "{'hidden_dim': [32, 64],\n",
      " 'seqlens': [{'day': 30, '30m': 30, 'dms': 30}],\n",
      " 'tra_seqlens': [{'hist_loss': 40}],\n",
      " 'dropout': [0.1],\n",
      " 'enc_in': [True],\n",
      " 'enc_att': [False],\n",
      " 'rnn_type': ['lstm'],\n",
      " 'rnn_att': [False],\n",
      " 'rnn_layers': [2],\n",
      " 'dec_mlp_layers': [2],\n",
      " 'num_output': [1],\n",
      " 'kernel_size': [3],\n",
      " 'hidden_as_factor': [False],\n",
      " 'ordered_param_group': [False],\n",
      " 'tra_num_states': [5]}\n",
      "try using /home/mengkjin/Workspace/learndl/data/DataSet/day.20240605.pt , success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:25:48|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Data], Cost 2.1 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:25:48|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Fit] at Mon Jun 24 01:25:48 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mFirstBite Ep#  0 : loss  1.00382, train-0.00516, valid-0.03649, best-0.0365, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  5 : loss  0.86311, train 0.13764, valid 0.09228, best 0.0923, lr2.5e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 10 : loss  0.84547, train 0.15544, valid 0.09630, best 0.0963, lr1.9e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 15 : loss  0.83038, train 0.17066, valid 0.08826, best 0.0963, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 20 : loss  0.82732, train 0.17363, valid 0.08575, best 0.0963, lr9.4e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 25 : loss  0.81729, train 0.18370, valid 0.08407, best 0.0963, lr3.1e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 30 : loss  0.81421, train 0.18647, valid 0.08262, best 0.0963, lr1.6e-04\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:27:46|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mgruRTN_day #1 @20231201|FirstBite Ep# 31 EarlyStop|Train 0.1865 Valid 0.0826 BestVal 0.0826|Cost  1.9Min,  3.6Sec/Ep\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  0 : loss  1.00293, train-0.00341, valid-0.00344, best-0.0034, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  5 : loss  0.87709, train 0.12551, valid 0.08796, best 0.1129, lr2.5e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 10 : loss  0.86180, train 0.13731, valid 0.10436, best 0.1129, lr1.9e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 15 : loss  0.85287, train 0.14587, valid 0.10502, best 0.1129, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 20 : loss  0.85180, train 0.14778, valid 0.09660, best 0.1129, lr9.4e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 23 : loss  0.84699, train 0.15223, valid 0.10093, best 0.1129, lr1.0e-07, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  0 : loss  0.99854, train 0.00457, valid 0.01988, best 0.0199, lr1.3e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  5 : loss  0.92030, train 0.08103, valid 0.08255, best 0.0825, lr2.5e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 10 : loss  0.90702, train 0.09389, valid 0.08568, best 0.0857, lr1.9e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 15 : loss  0.89605, train 0.10568, valid 0.10030, best 0.1003, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 20 : loss  0.89414, train 0.10746, valid 0.09676, best 0.1003, lr9.4e-05\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 23 : loss  0.89076, train 0.11050, valid 0.09963, best 0.1003, lr1.0e-07, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  0 : loss  0.99821, train 0.00317, valid 0.04276, best 0.0428, lr1.3e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  5 : loss  0.91434, train 0.07999, valid 0.07219, best 0.1080, lr2.5e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 10 : loss  0.89327, train 0.10612, valid 0.08880, best 0.1080, lr1.9e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 15 : loss  0.88616, train 0.11392, valid 0.08959, best 0.1080, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 20 : loss  0.88396, train 0.11643, valid 0.09105, best 0.1080, lr9.4e-03\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 23 : loss  0.87573, train 0.12499, valid 0.08870, best 0.1080, lr1.0e-07, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep#  0 : loss  1.00152, train 0.00047, valid 0.02760, best 0.0276, lr1.3e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep#  5 : loss  0.96801, train 0.04157, valid 0.06108, best 0.0611, lr2.5e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 10 : loss  0.95807, train 0.04909, valid 0.05827, best 0.0611, lr1.9e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 15 : loss  0.95065, train 0.05443, valid 0.05588, best 0.0611, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 20 : loss  0.94877, train 0.05559, valid 0.05718, best 0.0611, lr9.5e-06\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 23 : loss  0.94672, train 0.05714, valid 0.05652, best 0.0611, lr1.0e-07, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep#  0 : loss  1.00047, train-0.00169, valid-0.00940, best-0.0094, lr1.3e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep#  5 : loss  0.97745, train 0.03642, valid 0.05397, best 0.0540, lr2.5e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 10 : loss  0.96087, train 0.04016, valid 0.04625, best 0.0540, lr1.9e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 15 : loss  0.97887, train 0.02974, valid 0.04515, best 0.0592, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 20 : loss  0.97797, train 0.03105, valid 0.02864, best 0.0592, lr9.4e-02\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:33:42|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mgruRTN_day #0 @20240604|Retrain#4 Ep#120 EarlyStop|Train 0.0324 Valid 0.0466 BestVal 0.1129|Cost  5.9Min,  2.9Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:35:37|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mgruRTN_day #1 @20240604|FirstBite Ep# 31 EarlyStop|Train 0.1916 Valid 0.0938 BestVal 0.0938|Cost  1.9Min,  3.6Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:35:37|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Fit], Cost 0.2 Hours, 3.3 Min/model, 3.2 Sec/Epoch\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:35:37|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Test] at Mon Jun 24 01:35:37 2024!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:35:37|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mEach Model Date Testing Mean Score(spearman):\u001b[0m\n",
      "\u001b[32mModels            0       0       0       1       1       1\u001b[0m\n",
      "\u001b[32mOutput         best swalast swabest    best swalast swabest\u001b[0m\n",
      "\u001b[32m20170103     0.1415  0.1404  0.1427  0.1449  0.1435  0.1447\u001b[0m\n",
      "\u001b[32m20170704     0.1344  0.1262  0.1345  0.1305  0.1318  0.1309\u001b[0m\n",
      "\u001b[32m20171226     0.1443  0.1441  0.1454  0.1443  0.1440  0.1482\u001b[0m\n",
      "\u001b[32m20180627     0.1204  0.1149  0.1163  0.1097  0.1025  0.1077\u001b[0m\n",
      "\u001b[32m20181220     0.1134  0.1100  0.1116  0.1024  0.1004  0.1035\u001b[0m\n",
      "\u001b[32m20190624     0.0928  0.0923  0.0936  0.0977  0.0973  0.0969\u001b[0m\n",
      "\u001b[32m20191217     0.1172  0.1181  0.1180  0.1052  0.1068  0.1165\u001b[0m\n",
      "\u001b[32m20200617     0.0920  0.0939  0.0939  0.0902  0.0826  0.0929\u001b[0m\n",
      "\u001b[32m20201214     0.0986  0.0984  0.0981  0.0939  0.0944  0.0957\u001b[0m\n",
      "\u001b[32m20210615     0.0696  0.0720  0.0718  0.0754  0.0735  0.0734\u001b[0m\n",
      "\u001b[32m20211209     0.1126  0.1152  0.1148  0.1102  0.1128  0.1136\u001b[0m\n",
      "\u001b[32m20220613     0.1110  0.1046  0.1063  0.1074  0.1058  0.1127\u001b[0m\n",
      "\u001b[32m20221206     0.0574  0.0559  0.0579  0.0602  0.0553  0.0578\u001b[0m\n",
      "\u001b[32m20230606     0.0824  0.0776  0.0835  0.0856  0.0771  0.0824\u001b[0m\n",
      "\u001b[32m20231201     0.1327  0.1357  0.1289  0.1284  0.1280  0.1267\u001b[0m\n",
      "\u001b[32m20240604    -0.0291  0.0381  0.0338  0.0062  0.0266  0.0194\u001b[0m\n",
      "\u001b[32mAllTimeAvg   0.1071  0.1062  0.1073  0.1051  0.1032  0.1063\u001b[0m\n",
      "\u001b[32mAllTimeSum   194.08  192.38  194.48  190.38  187.02  192.67\u001b[0m\n",
      "\u001b[32mStd          0.0877  0.0881  0.0874  0.0877  0.0868  0.0861\u001b[0m\n",
      "\u001b[32mTValue        51.97   51.28   52.26   51.01   50.60   52.58\u001b[0m\n",
      "\u001b[32mAnnIR        5.9810  5.9022  6.0149  5.8711  5.8230  6.0509\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:36:32|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Test], Cost 54.9 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:36:32|MOD:time        |\u001b[0m: \u001b[1m\u001b[31mMain Process Finished! Cost 10 Minutes 45.7 Seconds\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:36:32|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mModel Specifics:\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:36:32|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Data] at Mon Jun 24 01:36:32 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Process Queue : Data + Fit + Test\n",
      "--Confirm Resume Training!\n",
      "--Model_name is set to gruRES_day!\n",
      "Callback : ResetOptimizer(num_reset=2,trigger=40,recover_level=1.0,speedup2x=True) , reset optimizer on some epoch (can speedup scheduler)\n",
      "Callback : CallbackTimer(verbosity=2) , record time cost of callback hooks\n",
      "Callback : EarlyStoppage(patience=20) , stop fitting when validation score cease to improve\n",
      "Callback : ValidationConverge(patience=5,eps=1e-05) , stop fitting when valid_score converge\n",
      "Callback : EarlyExitRetrain(earliest=5,max_attempt=4,lr_multiplier=[1, 0.1, 10, 0.01, 100]) , retrain with new lr if fitting stopped too early\n",
      "Callback : NanLossRetrain(max_attempt=4) , retrain if fitting encounters nan loss\n",
      "Callback : BatchDisplay(verbosity=2) , display batch progress bar\n",
      "Callback : StatusDisplay(verbosity=2) , display epoch and event information\n",
      "{'random_seed': None,\n",
      " 'model_name': 'gruRES_day',\n",
      " 'model_module': 'gru',\n",
      " 'model_data_type': 'day',\n",
      " 'model_types': ['best', 'swalast', 'swabest'],\n",
      " 'labels': ['res_lag1_10'],\n",
      " 'beg_date': 20170103,\n",
      " 'end_date': 99991231,\n",
      " 'sample_method': 'train_shuffle',\n",
      " 'shuffle_option': 'epoch',\n",
      " 'lgbm_ensembler': False}\n",
      "{'hidden_dim': [32, 64],\n",
      " 'seqlens': [{'day': 30, '30m': 30, 'dms': 30}],\n",
      " 'tra_seqlens': [{'hist_loss': 40}],\n",
      " 'dropout': [0.1],\n",
      " 'enc_in': [True],\n",
      " 'enc_att': [False],\n",
      " 'rnn_type': ['lstm'],\n",
      " 'rnn_att': [False],\n",
      " 'rnn_layers': [2],\n",
      " 'dec_mlp_layers': [2],\n",
      " 'num_output': [1],\n",
      " 'kernel_size': [3],\n",
      " 'hidden_as_factor': [False],\n",
      " 'ordered_param_group': [False],\n",
      " 'tra_num_states': [5]}\n",
      "try using /home/mengkjin/Workspace/learndl/data/DataSet/day.20240605.pt , success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:36:34|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Data], Cost 2.0 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:36:34|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Fit] at Mon Jun 24 01:36:34 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mFirstBite Ep#  0 : loss  1.01252, train-0.01521, valid-0.03742, best-0.0374, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  5 : loss  0.91026, train 0.08135, valid 0.03185, best 0.0599, lr2.5e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 10 : loss  0.89291, train 0.09436, valid 0.04522, best 0.0599, lr1.9e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 15 : loss  0.87755, train 0.10648, valid 0.03959, best 0.0599, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 20 : loss  0.87426, train 0.10831, valid 0.03543, best 0.0599, lr9.4e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 21 : loss  0.87082, train 0.11088, valid 0.03980, best 0.0599, lr6.3e-04, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  0 : loss  0.99637, train 0.00462, valid 0.03106, best 0.0311, lr1.3e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  5 : loss  0.94196, train 0.05698, valid 0.03578, best 0.0560, lr2.5e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 10 : loss  0.92553, train 0.06750, valid 0.03080, best 0.0560, lr1.9e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 15 : loss  0.91653, train 0.07499, valid 0.03537, best 0.0560, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 20 : loss  0.91509, train 0.07561, valid 0.04185, best 0.0560, lr9.4e-05\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 21 : loss  0.91403, train 0.07721, valid 0.04641, best 0.0560, lr6.3e-05, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  0 : loss  1.00549, train-0.00683, valid-0.02416, best-0.0242, lr1.3e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  5 : loss  0.94359, train 0.04867, valid 0.02798, best 0.0514, lr2.5e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 10 : loss  0.93368, train 0.05600, valid 0.02787, best 0.0514, lr1.9e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 15 : loss  0.92716, train 0.06278, valid 0.03398, best 0.0514, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 20 : loss  0.92646, train 0.06384, valid 0.04303, best 0.0514, lr9.4e-03\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 21 : loss  0.92585, train 0.06408, valid 0.03492, best 0.0514, lr6.3e-03, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep#  0 : loss  1.01260, train-0.01493, valid-0.03974, best-0.0397, lr1.3e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep#  5 : loss  0.96876, train 0.02948, valid 0.04494, best 0.0477, lr2.5e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 10 : loss  0.96445, train 0.03233, valid 0.04554, best 0.0477, lr1.9e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 15 : loss  0.96098, train 0.03497, valid 0.04404, best 0.0477, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 20 : loss  0.96022, train 0.03574, valid 0.04354, best 0.0477, lr9.5e-06\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 21 : loss  0.95992, train 0.03628, valid 0.04487, best 0.0477, lr6.3e-06, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep#  0 : loss  0.99746, train 0.00225, valid-0.00306, best-0.0031, lr1.3e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep#  5 : loss  0.97511, train 0.02839, valid 0.01301, best 0.0537, lr2.5e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 10 : loss  0.96875, train 0.03070, valid 0.01638, best 0.0537, lr1.9e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 15 : loss  0.96160, train 0.03236, valid 0.03529, best 0.0537, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 20 : loss  0.96655, train 0.02830, valid 0.04237, best 0.0537, lr9.4e-02\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:43:22|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mgruRES_day #1 @20231201|Retrain#4 Ep#110 EarlyStop|Train 0.0293 Valid 0.0368 BestVal 0.0599|Cost  6.7Min,  3.6Sec/Ep\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  0 : loss  0.99752, train 0.00292, valid 0.02356, best 0.0236, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  5 : loss  0.92738, train 0.06719, valid 0.04180, best 0.0533, lr2.5e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 10 : loss  0.90904, train 0.07964, valid 0.02435, best 0.0533, lr1.9e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 15 : loss  0.89805, train 0.08672, valid 0.03391, best 0.0533, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 20 : loss  0.89733, train 0.08698, valid 0.03455, best 0.0533, lr9.4e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 21 : loss  0.89541, train 0.08806, valid 0.04139, best 0.0533, lr6.3e-04, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  0 : loss  1.00733, train-0.00926, valid-0.03680, best-0.0368, lr1.3e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  5 : loss  0.95510, train 0.04285, valid 0.05432, best 0.0549, lr2.5e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 10 : loss  0.94688, train 0.04934, valid 0.04339, best 0.0549, lr1.9e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 15 : loss  0.93907, train 0.05436, valid 0.03791, best 0.0549, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 20 : loss  0.93641, train 0.05594, valid 0.03422, best 0.0549, lr9.4e-05\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 22 : loss  0.93590, train 0.05702, valid 0.04172, best 0.0549, lr3.1e-05, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  0 : loss  0.99719, train 0.00375, valid 0.01564, best 0.0156, lr1.3e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  5 : loss  0.94177, train 0.04812, valid 0.03631, best 0.0465, lr2.5e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 10 : loss  0.93093, train 0.05774, valid 0.03864, best 0.0465, lr1.9e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 15 : loss  0.92785, train 0.05940, valid 0.02965, best 0.0465, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 20 : loss  0.92459, train 0.06304, valid 0.03018, best 0.0465, lr9.4e-03\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 22 : loss  0.92154, train 0.06476, valid 0.03223, best 0.0465, lr3.1e-03, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep#  0 : loss  0.99855, train 0.00161, valid 0.01776, best 0.0178, lr1.3e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep#  5 : loss  0.97299, train 0.02829, valid 0.05143, best 0.0514, lr2.5e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 10 : loss  0.96918, train 0.02884, valid 0.05178, best 0.0518, lr1.9e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 15 : loss  0.96640, train 0.02942, valid 0.05233, best 0.0523, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 20 : loss  0.96524, train 0.02948, valid 0.05201, best 0.0523, lr9.5e-06\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 22 : loss  0.96442, train 0.03008, valid 0.05196, best 0.0523, lr3.2e-06, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep#  0 : loss  1.00164, train-0.00223, valid-0.02355, best-0.0236, lr1.3e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep#  5 : loss  0.97856, train 0.02428, valid 0.02481, best 0.0474, lr2.5e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 10 : loss  0.97707, train 0.02539, valid 0.04388, best 0.0474, lr1.9e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 15 : loss  0.97920, train 0.02491, valid 0.01606, best 0.0474, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 20 : loss  0.97573, train 0.02385, valid 0.01877, best 0.0474, lr9.4e-02\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:48:54|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mgruRES_day #0 @20240604|Retrain#4 Ep#114 EarlyStop|Train 0.0265 Valid 0.0202 BestVal 0.0549|Cost  5.5Min,  2.9Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:56:07|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mgruRES_day #1 @20240604|Retrain#4 Ep#115 EarlyStop|Train 0.0274 Valid 0.0224 BestVal 0.0568|Cost  7.2Min,  3.7Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:56:07|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Fit], Cost 0.3 Hours, 6.5 Min/model, 3.5 Sec/Epoch\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:56:07|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Test] at Mon Jun 24 01:56:07 2024!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:56:07|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mEach Model Date Testing Mean Score(spearman):\u001b[0m\n",
      "\u001b[32mModels            0       0       0       1       1       1\u001b[0m\n",
      "\u001b[32mOutput         best swalast swabest    best swalast swabest\u001b[0m\n",
      "\u001b[32m20170103     0.1107  0.1119  0.1114  0.1060  0.1068  0.1081\u001b[0m\n",
      "\u001b[32m20170704     0.0937  0.0946  0.0972  0.0970  0.0989  0.0993\u001b[0m\n",
      "\u001b[32m20171226     0.0889  0.0892  0.0893  0.0901  0.0905  0.0905\u001b[0m\n",
      "\u001b[32m20180627     0.0713  0.0712  0.0713  0.0738  0.0715  0.0736\u001b[0m\n",
      "\u001b[32m20181220     0.0733  0.0742  0.0746  0.0740  0.0741  0.0728\u001b[0m\n",
      "\u001b[32m20190624     0.0702  0.0701  0.0703  0.0663  0.0672  0.0681\u001b[0m\n",
      "\u001b[32m20191217     0.0774  0.0745  0.0763  0.0789  0.0759  0.0750\u001b[0m\n",
      "\u001b[32m20200617     0.0555  0.0563  0.0570  0.0597  0.0579  0.0592\u001b[0m\n",
      "\u001b[32m20201214     0.0610  0.0605  0.0609  0.0619  0.0606  0.0642\u001b[0m\n",
      "\u001b[32m20210615     0.0406  0.0406  0.0438  0.0459  0.0475  0.0477\u001b[0m\n",
      "\u001b[32m20211209     0.0568  0.0572  0.0567  0.0561  0.0556  0.0573\u001b[0m\n",
      "\u001b[32m20220613     0.0457  0.0450  0.0465  0.0447  0.0461  0.0462\u001b[0m\n",
      "\u001b[32m20221206     0.0241  0.0235  0.0277  0.0287  0.0243  0.0296\u001b[0m\n",
      "\u001b[32m20230606     0.0589  0.0451  0.0425  0.0361  0.0324  0.0353\u001b[0m\n",
      "\u001b[32m20231201     0.0291  0.0323  0.0298  0.0140  0.0078  0.0160\u001b[0m\n",
      "\u001b[32m20240604    -0.0728 -0.0680 -0.0678 -0.0540  0.0016 -0.0326\u001b[0m\n",
      "\u001b[32mAllTimeAvg   0.0629  0.0622  0.0628  0.0614  0.0608  0.0622\u001b[0m\n",
      "\u001b[32mAllTimeSum   113.98  112.74  113.82  111.32  110.09  112.77\u001b[0m\n",
      "\u001b[32mStd          0.0537  0.0507  0.0500  0.0504  0.0493  0.0490\u001b[0m\n",
      "\u001b[32mTValue        49.87   52.28   53.42   51.92   52.51   54.01\u001b[0m\n",
      "\u001b[32mAnnIR        5.7394  6.0170  6.1485  5.9749  6.0436  6.2161\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:57:02|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Test], Cost 55.3 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:57:02|MOD:time        |\u001b[0m: \u001b[1m\u001b[31mMain Process Finished! Cost 20 Minutes 30.0 Seconds\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.api import Trainer\n",
    "Trainer.update_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
