{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 2.1.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available() , torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mengkjin/Workspace/learndl/src/nn_model/util/logger.py:22: ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/mengkjin/Workspace/learndl/logs/logs/rnn_log.log' mode='a' encoding='utf-8'>\n",
      "  log.removeHandler(log.handlers[-1])\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 07:25:24|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mModel Specifics:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-07-26 07:25:24|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Data] at Fri Jul 26 07:25:24 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "risk_att_gru nn\n",
      "--Process Queue : Data + Fit + Test\n",
      "--Start Training New!\n",
      "--Model_name is set to risk_att_gru_day.3!\n",
      "Callback : ResetOptimizer(num_reset=2,trigger=40,recover_level=1.0,speedup2x=True,kwargs={}) , reset optimizer on some epoch (can speedup scheduler)\n",
      "Callback : CallbackTimer(verbosity=2,kwargs={}) , record time cost of callback hooks\n",
      "Callback : EarlyStoppage(patience=20,kwargs={}) , stop fitting when validation score cease to improve\n",
      "Callback : ValidationConverge(patience=5,eps=1e-05,kwargs={}) , stop fitting when valid_score converge\n",
      "Callback : EarlyExitRetrain(earliest=10,max_attempt=4,lr_multiplier=[1, 0.1, 10, 0.01, 100, 1],kwargs={}) , retrain with new lr if fitting stopped too early\n",
      "Callback : NanLossRetrain(max_attempt=4,kwargs={}) , retrain if fitting encounters nan loss\n",
      "Callback : BatchDisplay(verbosity=2,kwargs={}) , display batch progress bar\n",
      "Callback : StatusDisplay(verbosity=2,kwargs={}) , display epoch and event information\n",
      "Callback : GroupReturnAnalysis(group_num=20,kwargs={}) , record and concat each model to Alpha model instance\n",
      "Callback : DetailedAlphaAnalysis(use_num=avg,kwargs={}) , record and concat each model to Alpha model instance\n",
      "{'model_name': 'risk_att_gru_day.3',\n",
      " 'model_module': 'risk_att_gru',\n",
      " 'model.types': ['best'],\n",
      " 'model.lgbm_ensembler': False,\n",
      " 'data.type': 'day+style+indus',\n",
      " 'data.labels': ['std_lag1_10', 'rtn_lag1_10'],\n",
      " 'random_seed': None,\n",
      " 'beg_date': 20170103,\n",
      " 'end_date': 99991231,\n",
      " 'sample_method': 'sequential',\n",
      " 'shuffle_option': 'epoch'}\n",
      "{'hidden_dim': [64],\n",
      " 'seqlens': [{'day': 30, 'indus': 1, 'style': 1}],\n",
      " 'dropout': [0.1],\n",
      " 'rnn_layers': [2],\n",
      " 'indus_dim': [8],\n",
      " 'indus_embed': [True, False],\n",
      " 'kernel_size': [3],\n",
      " 'hidden_as_factor': [True],\n",
      " 'model.types': ['best']}\n",
      "try using /home/mengkjin/Workspace/learndl/data/DataSet/day+style+indus.20240703.pt , success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-07-26 07:25:29|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Data], Cost 4.8 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-07-26 07:25:29|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Fit] at Fri Jul 26 07:25:29 2024!\u001b[0m\n",
      "/home/mengkjin/Workspace/learndl/src/nn_model/classes/mod.py:345: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  self.logger.warn(f'First Iterance: ({self.status.model_date} , {self.status.model_num})')\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 07:25:29|MOD:mod         |\u001b[0m: \u001b[1m\u001b[34mFirst Iterance: (20170103 , 0)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n",
      "Pre-Norming method of [style] : {'divlast': False, 'histnorm': False}\n",
      "Pre-Norming method of [indus] : {'divlast': False, 'histnorm': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mFirstBite Ep#  0 : loss  0.98041, train 0.02388, valid 0.03539, best 0.0354, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  5 : loss  0.88595, train 0.13428, valid 0.16668, best 0.1667, lr2.5e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 10 : loss  0.85289, train 0.16754, valid 0.17548, best 0.1755, lr1.9e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 15 : loss  0.83180, train 0.18957, valid 0.17452, best 0.1755, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 20 : loss  0.82883, train 0.19266, valid 0.16918, best 0.1755, lr9.4e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 25 : loss  0.81025, train 0.21356, valid 0.16181, best 0.1755, lr3.1e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 30 : loss  0.80618, train 0.21759, valid 0.15903, best 0.1755, lr1.6e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 30 : loss  0.80618, train 0.21759, valid 0.15903, best 0.1755, lr1.6e-04, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  0 : loss  0.99393, train 0.00796, valid 0.03206, best 0.0321, lr1.3e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  5 : loss  0.90602, train 0.11433, valid 0.11021, best 0.1129, lr2.5e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 10 : loss  0.88521, train 0.13718, valid 0.13286, best 0.1367, lr1.9e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 15 : loss  0.87040, train 0.15170, valid 0.14886, best 0.1594, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 20 : loss  0.86984, train 0.15116, valid 0.15425, best 0.1594, lr9.4e-05\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 25 : loss  0.86272, train 0.15898, valid 0.15800, best 0.1637, lr3.1e-05\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 30 : loss  0.86067, train 0.16020, valid 0.15875, best 0.1637, lr1.6e-05\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 30 : loss  0.86067, train 0.16020, valid 0.15875, best 0.1637, lr1.6e-05, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  0 : loss  1.00841, train-0.00872, valid-0.00752, best-0.0075, lr1.3e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  5 : loss  0.99110, train 0.01287, valid 0.08021, best 0.1143, lr2.5e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 10 : loss  0.95750, train 0.05691, valid 0.10799, best 0.1143, lr1.9e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 15 : loss  0.95319, train 0.06177, valid 0.10091, best 0.1143, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 20 : loss  0.95202, train 0.06189, valid 0.10322, best 0.1143, lr9.4e-03\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 25 : loss  0.94170, train 0.07530, valid 0.11404, best 0.1143, lr3.1e-03\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 30 : loss  0.93691, train 0.07852, valid 0.11618, best 0.1179, lr1.6e-03\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 30 : loss  0.93691, train 0.07852, valid 0.11618, best 0.1179, lr1.6e-03, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep#  0 : loss  0.99471, train 0.00833, valid 0.00027, best 0.0003, lr1.3e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep#  5 : loss  0.93698, train 0.07459, valid 0.09193, best 0.0919, lr2.5e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 10 : loss  0.93026, train 0.08174, valid 0.09438, best 0.0944, lr1.9e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 15 : loss  0.92282, train 0.09007, valid 0.09663, best 0.1002, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 20 : loss  0.92173, train 0.09162, valid 0.09711, best 0.1002, lr9.5e-06\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 25 : loss  0.91959, train 0.09311, valid 0.09685, best 0.1002, lr3.2e-06\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 30 : loss  0.91913, train 0.09432, valid 0.09860, best 0.1002, lr1.7e-06\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 30 : loss  0.91913, train 0.09432, valid 0.09860, best 0.1002, lr1.7e-06, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep#  0 : loss  0.99215, train 0.01011, valid 0.00349, best 0.0035, lr1.3e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep#  5 : loss  0.99880, train 0.00641, valid 0.06968, best 0.0782, lr2.5e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 10 : loss  0.99908, train 0.00151, valid 0.06937, best 0.0782, lr1.9e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 15 : loss  0.99951, train 0.00490, valid 0.05985, best 0.0782, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 20 : loss  1.00096, train 0.00079, valid 0.05397, best 0.0782, lr9.4e-02\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 25 : loss  1.00050, train 0.00359, valid 0.05223, best 0.0782, lr3.1e-02\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 30 : loss  0.99009, train 0.01906, valid 0.07153, best 0.0782, lr1.6e-02\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 07:39:44|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #0 @20170103|Retrain#4 Ep#155 EarlyStop|Train 0.0191 Valid 0.0715 BestVal 0.1755|Cost 14.0Min,  5.4Sec/Ep\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  0 : loss  1.01093, train-0.01538, valid-0.02018, best-0.0202, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  5 : loss  0.87612, train 0.14552, valid 0.15269, best 0.1527, lr2.5e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 10 : loss  0.84592, train 0.17636, valid 0.16093, best 0.1680, lr1.9e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 15 : loss  0.82704, train 0.19664, valid 0.15243, best 0.1680, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 20 : loss  0.82555, train 0.19727, valid 0.14593, best 0.1680, lr9.4e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 25 : loss  0.80684, train 0.21711, valid 0.15468, best 0.1680, lr3.1e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 28 : loss  0.80875, train 0.21547, valid 0.15393, best 0.1680, lr4.7e-04, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  0 : loss  0.99110, train 0.01225, valid 0.01827, best 0.0183, lr1.3e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  5 : loss  0.91137, train 0.10659, valid 0.10080, best 0.1034, lr2.5e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 10 : loss  0.88847, train 0.12986, valid 0.11879, best 0.1274, lr1.9e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 15 : loss  0.87430, train 0.14454, valid 0.13599, best 0.1381, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 20 : loss  0.87435, train 0.14546, valid 0.12682, best 0.1381, lr9.4e-05\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 25 : loss  0.86611, train 0.15321, valid 0.13685, best 0.1413, lr3.1e-05\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 28 : loss  0.86610, train 0.15349, valid 0.14295, best 0.1430, lr4.7e-05, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  0 : loss  0.98459, train 0.02253, valid 0.01737, best 0.0174, lr1.3e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  5 : loss  0.97444, train 0.03692, valid 0.03013, best 0.1265, lr2.5e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 10 : loss  0.95350, train 0.06037, valid 0.08247, best 0.1265, lr1.9e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 15 : loss  0.95073, train 0.06471, valid 0.10756, best 0.1265, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 20 : loss  0.94582, train 0.06622, valid 0.09860, best 0.1265, lr9.4e-03\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 25 : loss  0.94046, train 0.07358, valid 0.10114, best 0.1265, lr3.1e-03\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 28 : loss  0.94362, train 0.07013, valid 0.09411, best 0.1265, lr4.7e-03, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep#  0 : loss  1.02285, train-0.02462, valid-0.04509, best-0.0451, lr1.3e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep#  5 : loss  0.94112, train 0.07184, valid 0.08975, best 0.0898, lr2.5e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 10 : loss  0.93303, train 0.07979, valid 0.09375, best 0.0941, lr1.9e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 15 : loss  0.92535, train 0.08714, valid 0.09854, best 0.0985, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 20 : loss  0.92360, train 0.08812, valid 0.08977, best 0.0985, lr9.5e-06\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 25 : loss  0.92148, train 0.09061, valid 0.09492, best 0.0985, lr3.2e-06\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 28 : loss  0.91954, train 0.09292, valid 0.09746, best 0.0985, lr4.8e-06, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep#  0 : loss  0.99491, train 0.01008, valid 0.02519, best 0.0252, lr1.3e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep#  5 : loss  0.99707, train 0.00649, valid 0.04566, best 0.0526, lr2.5e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 10 : loss  1.00032, train 0.00161, valid 0.03980, best 0.0526, lr1.9e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 15 : loss  0.99339, train 0.01133, valid 0.05437, best 0.0665, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 20 : loss  0.98994, train 0.01568, valid 0.03804, best 0.0665, lr9.4e-02\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 25 : loss  0.98757, train 0.02063, valid 0.03363, best 0.0665, lr3.1e-02\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 07:52:04|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #1 @20170103|Retrain#4 Ep#145 EarlyStop|Train 0.0188 Valid 0.0548 BestVal 0.1680|Cost 12.3Min,  5.0Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 07:55:25|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #0 @20170704|FirstBite Ep# 32 EarlyStop|Train 0.2210 Valid 0.1580 BestVal 0.1580|Cost  3.1Min,  5.6Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 07:58:39|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #1 @20170704|FirstBite Ep# 38 EarlyStop|Train 0.2321 Valid 0.1557 BestVal 0.1557|Cost  3.2Min,  4.9Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 08:01:57|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #0 @20171226|FirstBite Ep# 35 EarlyStop|Train 0.2255 Valid 0.1470 BestVal 0.1470|Cost  3.0Min,  5.1Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 08:14:38|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #1 @20171226|Retrain#4 Ep#150 EarlyStop|Train 0.0124 Valid 0.0264 BestVal 0.1708|Cost 12.6Min,  5.0Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 08:18:24|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #0 @20180627|FirstBite Ep# 40 EarlyStop|Train 0.2366 Valid 0.1342 BestVal 0.1342|Cost  3.5Min,  5.1Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 08:21:16|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #1 @20180627|FirstBite Ep# 35 EarlyStop|Train 0.2404 Valid 0.1530 BestVal 0.1530|Cost  2.8Min,  4.6Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 08:25:46|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #0 @20181220|FirstBite Ep# 48 EarlyStop|Train 0.2256 Valid 0.1545 BestVal 0.1545|Cost  4.3Min,  5.2Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 08:29:12|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #1 @20181220|FirstBite Ep# 40 EarlyStop|Train 0.2402 Valid 0.1543 BestVal 0.1543|Cost  3.4Min,  4.9Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 08:32:36|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #0 @20190624|FirstBite Ep# 35 EarlyStop|Train 0.2337 Valid 0.1333 BestVal 0.1333|Cost  3.1Min,  5.2Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 08:36:07|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #1 @20190624|FirstBite Ep# 41 EarlyStop|Train 0.2483 Valid 0.1334 BestVal 0.1334|Cost  3.4Min,  4.9Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 08:39:53|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #0 @20191217|FirstBite Ep# 40 EarlyStop|Train 0.2389 Valid 0.1339 BestVal 0.1339|Cost  3.5Min,  5.2Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 08:43:13|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #1 @20191217|FirstBite Ep# 39 EarlyStop|Train 0.2400 Valid 0.1285 BestVal 0.1285|Cost  3.3Min,  4.9Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 08:46:38|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #0 @20200617|FirstBite Ep# 35 EarlyStop|Train 0.2394 Valid 0.1270 BestVal 0.1270|Cost  3.2Min,  5.3Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 08:50:23|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #1 @20200617|FirstBite Ep# 43 EarlyStop|Train 0.2116 Valid 0.1136 BestVal 0.1136|Cost  3.7Min,  5.0Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 08:56:18|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #0 @20201214|FirstBite Ep# 63 EarlyStop|Train 0.2450 Valid 0.1053 BestVal 0.1053|Cost  5.7Min,  5.3Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 08:59:37|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #1 @20201214|FirstBite Ep# 38 EarlyStop|Train 0.2476 Valid 0.1123 BestVal 0.1123|Cost  3.2Min,  5.0Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 09:13:36|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #0 @20210615|Retrain#4 Ep#150 EarlyStop|Train 0.0343 Valid 0.0307 BestVal 0.1082|Cost 13.7Min,  5.5Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 09:17:46|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #1 @20210615|FirstBite Ep# 48 EarlyStop|Train 0.2329 Valid 0.1013 BestVal 0.1013|Cost  4.1Min,  5.0Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 09:21:57|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #0 @20211209|FirstBite Ep# 43 EarlyStop|Train 0.2049 Valid 0.0837 BestVal 0.0837|Cost  3.9Min,  5.4Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 09:27:29|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #1 @20211209|FirstBite Ep# 67 EarlyStop|Train 0.2473 Valid 0.0810 BestVal 0.0810|Cost  5.5Min,  4.8Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 09:39:45|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #0 @20220613|Retrain#4 Ep#130 EarlyStop|Train 0.0041 Valid 0.0239 BestVal 0.0951|Cost 12.0Min,  5.5Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 09:42:40|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #1 @20220613|FirstBite Ep# 33 EarlyStop|Train 0.2290 Valid 0.0906 BestVal 0.0906|Cost  2.8Min,  5.0Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 09:55:37|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #0 @20221206|Retrain#4 Ep#145 EarlyStop|Train 0.0279 Valid 0.0342 BestVal 0.0965|Cost 12.7Min,  5.2Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 10:08:08|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #1 @20221206|Retrain#4 Ep#140 EarlyStop|Train 0.0118 Valid 0.0466 BestVal 0.1043|Cost 12.5Min,  5.3Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 10:22:19|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #0 @20230606|Retrain#4 Ep#130 EarlyStop|Train 0.0450 Valid 0.0442 BestVal 0.1114|Cost 13.9Min,  6.4Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 10:25:46|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #1 @20230606|FirstBite Ep# 40 EarlyStop|Train 0.2308 Valid 0.0982 BestVal 0.0982|Cost  3.4Min,  5.0Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 10:29:19|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #0 @20231201|FirstBite Ep# 34 EarlyStop|Train 0.2121 Valid 0.0928 BestVal 0.0928|Cost  3.3Min,  5.6Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 10:33:49|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #1 @20231201|FirstBite Ep# 50 EarlyStop|Train 0.2194 Valid 0.1129 BestVal 0.1129|Cost  4.4Min,  5.2Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 10:48:10|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #0 @20240604|Retrain#4 Ep#115 EarlyStop|Train 0.0462 Valid 0.0640 BestVal 0.1289|Cost 14.1Min,  7.3Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 11:00:36|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mrisk_att_gru_day.3 #1 @20240604|Retrain#4 Ep#135 EarlyStop|Train 0.0110 Valid 0.0259 BestVal 0.1328|Cost 12.4Min,  5.5Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-07-26 11:00:36|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Fit], Cost 3.6 Hours, 6.7 Min/model, 5.6 Sec/Epoch\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-07-26 11:00:36|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Test] at Fri Jul 26 11:00:36 2024!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-26 11:02:43|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mTesting Mean Score(spearman):\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>risk_att_gru.0</th>\n",
       "      <th>risk_att_gru.1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>best</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20170103</th>\n",
       "      <td>0.135</td>\n",
       "      <td>0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20170704</th>\n",
       "      <td>0.124</td>\n",
       "      <td>0.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20171226</th>\n",
       "      <td>0.128</td>\n",
       "      <td>0.134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20180627</th>\n",
       "      <td>0.134</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20181220</th>\n",
       "      <td>0.123</td>\n",
       "      <td>0.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190624</th>\n",
       "      <td>0.124</td>\n",
       "      <td>0.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20191217</th>\n",
       "      <td>0.095</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20200617</th>\n",
       "      <td>0.103</td>\n",
       "      <td>0.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201214</th>\n",
       "      <td>0.092</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20210615</th>\n",
       "      <td>0.083</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20211209</th>\n",
       "      <td>0.120</td>\n",
       "      <td>0.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20220613</th>\n",
       "      <td>0.118</td>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20221206</th>\n",
       "      <td>0.083</td>\n",
       "      <td>0.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20230606</th>\n",
       "      <td>0.143</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20231201</th>\n",
       "      <td>0.123</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20240604</th>\n",
       "      <td>0.069</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg</th>\n",
       "      <td>0.114</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sum</th>\n",
       "      <td>209.534</td>\n",
       "      <td>215.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Std</th>\n",
       "      <td>0.077</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>63.581</td>\n",
       "      <td>61.704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IR</th>\n",
       "      <td>7.279</td>\n",
       "      <td>7.064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         risk_att_gru.0 risk_att_gru.1\n",
       "              best           best     \n",
       "20170103       0.135          0.146   \n",
       "20170704       0.124          0.132   \n",
       "20171226       0.128          0.134   \n",
       "20180627       0.134          0.142   \n",
       "20181220       0.123          0.114   \n",
       "20190624       0.124          0.113   \n",
       "20191217       0.095          0.105   \n",
       "20200617       0.103          0.101   \n",
       "20201214       0.092          0.085   \n",
       "20210615       0.083          0.086   \n",
       "20211209       0.120          0.124   \n",
       "20220613       0.118          0.117   \n",
       "20221206       0.083          0.103   \n",
       "20230606       0.143          0.145   \n",
       "20231201       0.123          0.140   \n",
       "20240604       0.069          0.041   \n",
       "Avg            0.114          0.118   \n",
       "Sum          209.534        215.679   \n",
       "Std            0.077          0.082   \n",
       "T             63.581         61.704   \n",
       "IR             7.279          7.064   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-07-26 11:02:43|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Test], Cost 127.6 Secs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results are saved to /home/mengkjin/Workspace/learndl/model/risk_att_gru_day.3/detailed_analysis/test.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num</th>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>best</th>\n",
       "      <td>-2.081%</td>\n",
       "      <td>-0.861%</td>\n",
       "      <td>-0.497%</td>\n",
       "      <td>-0.320%</td>\n",
       "      <td>-0.206%</td>\n",
       "      <td>-0.158%</td>\n",
       "      <td>-0.040%</td>\n",
       "      <td>-0.024%</td>\n",
       "      <td>0.058%</td>\n",
       "      <td>0.114%</td>\n",
       "      <td>0.184%</td>\n",
       "      <td>0.242%</td>\n",
       "      <td>0.263%</td>\n",
       "      <td>0.319%</td>\n",
       "      <td>0.349%</td>\n",
       "      <td>0.445%</td>\n",
       "      <td>0.451%</td>\n",
       "      <td>0.551%</td>\n",
       "      <td>0.524%</td>\n",
       "      <td>0.749%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>best</th>\n",
       "      <td>-2.022%</td>\n",
       "      <td>-0.761%</td>\n",
       "      <td>-0.502%</td>\n",
       "      <td>-0.287%</td>\n",
       "      <td>-0.244%</td>\n",
       "      <td>-0.122%</td>\n",
       "      <td>0.005%</td>\n",
       "      <td>-0.016%</td>\n",
       "      <td>0.037%</td>\n",
       "      <td>0.104%</td>\n",
       "      <td>0.096%</td>\n",
       "      <td>0.168%</td>\n",
       "      <td>0.263%</td>\n",
       "      <td>0.324%</td>\n",
       "      <td>0.390%</td>\n",
       "      <td>0.400%</td>\n",
       "      <td>0.423%</td>\n",
       "      <td>0.511%</td>\n",
       "      <td>0.643%</td>\n",
       "      <td>0.650%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "group       1        2        3        4        5        6        7        8        9       10      11      12      13      14      15      16      17      18      19      20  \n",
       "num type                                                                                                                                                                        \n",
       "0   best  -2.081%  -0.861%  -0.497%  -0.320%  -0.206%  -0.158%  -0.040%  -0.024%  0.058%  0.114%  0.184%  0.242%  0.263%  0.319%  0.349%  0.445%  0.451%  0.551%  0.524%  0.749%\n",
       "1   best  -2.022%  -0.761%  -0.502%  -0.287%  -0.244%  -0.122%   0.005%  -0.016%  0.037%  0.104%  0.096%  0.168%  0.263%  0.324%  0.390%  0.400%  0.423%  0.511%  0.643%  0.650%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped Return Results are saved to /home/mengkjin/Workspace/learndl/model/risk_att_gru_day.3/detailed_analysis/group.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>factor_name</th>\n",
       "      <th>benchmark</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>pf</th>\n",
       "      <th>bm</th>\n",
       "      <th>excess</th>\n",
       "      <th>annualized</th>\n",
       "      <th>mdd</th>\n",
       "      <th>te</th>\n",
       "      <th>ir</th>\n",
       "      <th>calmar</th>\n",
       "      <th>turnover</th>\n",
       "      <th>mdd_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>best</td>\n",
       "      <td>csi300</td>\n",
       "      <td>20170104</td>\n",
       "      <td>20240718</td>\n",
       "      <td>100.92%</td>\n",
       "      <td>24.21%</td>\n",
       "      <td>76.71%</td>\n",
       "      <td>6.46%</td>\n",
       "      <td>5.89%</td>\n",
       "      <td>3.84%</td>\n",
       "      <td>1.683</td>\n",
       "      <td>1.096</td>\n",
       "      <td>147.095</td>\n",
       "      <td>20201117-20211210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>best</td>\n",
       "      <td>csi500</td>\n",
       "      <td>20170104</td>\n",
       "      <td>20240718</td>\n",
       "      <td>154.15%</td>\n",
       "      <td>-15.40%</td>\n",
       "      <td>169.55%</td>\n",
       "      <td>15.49%</td>\n",
       "      <td>14.86%</td>\n",
       "      <td>5.94%</td>\n",
       "      <td>2.608</td>\n",
       "      <td>1.043</td>\n",
       "      <td>147.263</td>\n",
       "      <td>20210317-20210915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best</td>\n",
       "      <td>csi1000</td>\n",
       "      <td>20170104</td>\n",
       "      <td>20240718</td>\n",
       "      <td>131.51%</td>\n",
       "      <td>-40.37%</td>\n",
       "      <td>171.88%</td>\n",
       "      <td>19.20%</td>\n",
       "      <td>14.62%</td>\n",
       "      <td>5.99%</td>\n",
       "      <td>3.204</td>\n",
       "      <td>1.313</td>\n",
       "      <td>147.337</td>\n",
       "      <td>20210429-20210915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  factor_name benchmark    start      end      pf       bm     excess  annualized   mdd     te     ir   calmar turnover     mdd_period    \n",
       "1     best       csi300  20170104  20240718  100.92%   24.21%   76.71%    6.46%     5.89%  3.84%  1.683  1.096  147.095  20201117-20211210\n",
       "2     best       csi500  20170104  20240718  154.15%  -15.40%  169.55%   15.49%    14.86%  5.94%  2.608  1.043  147.263  20210317-20210915\n",
       "0     best      csi1000  20170104  20240718  131.51%  -40.37%  171.88%   19.20%    14.62%  5.99%  3.204  1.313  147.337  20210429-20210915"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-07-26 11:25:16|MOD:time        |\u001b[0m: \u001b[1m\u001b[31mMain Process Finished! Cost 3 Hours 59 Minutes 51.7 Seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytic datas are saved to /home/mengkjin/Workspace/learndl/model/risk_att_gru_day.3/detailed_analysis/perf.xlsx\n",
      "Analytic plots are saved to /home/mengkjin/Workspace/learndl/model/risk_att_gru_day.3/detailed_analysis/plot.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.nn_model.trainer.trainers.net.NetTrainer at 0x797a19f96110>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.api import Trainer  \n",
    "app = Trainer.initialize(stage = 0 , resume = 0 , checkname= 1)\n",
    "app.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device name: NVIDIA GeForce RTX 4090\n",
      "try using /home/mengkjin/Workspace/learndl/data/DataSet/30m.20240703.pt , success!\n",
      "Load  2 DataBlocks...... finished! Cost 1.08 secs\n",
      "Align 2 DataBlocks...... finished! Cost 0.76 secs\n",
      "Pre-Norming method of [30m] : {'divlast': False, 'histnorm': True}\n"
     ]
    }
   ],
   "source": [
    "from src.api import HiddenExtractor\n",
    "extractor = HiddenExtractor('resnet_gru_30m' , model_nums=[1] , model_types=['best'])\n",
    "extractor.extract_hidden('update' , deploy = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device name: NVIDIA GeForce RTX 4090\n",
      "predict is False , Data Processing start!\n",
      "6 datas :['y', 'day', '30m', 'style', 'indus', 'week']\n",
      "y blocks loading start!\n",
      " --> labels blocks reading [ret10_lag] DataBase...... finished! Cost 19.78 secs\n",
      " --> labels blocks reading [ret20_lag] DataBase...... finished! Cost 18.38 secs\n",
      " --> labels blocks merging (2)...... finished! Cost 3.39 secs\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 67.56 secs\n",
      "y blocks loading finished! Cost 120.07 secs\n",
      "y blocks process...... finished! Cost 46.25 secs\n",
      "y blocks masking...... finished! Cost 0.76 secs\n",
      "y blocks saving ...... finished! Cost 3.51 secs\n",
      "y blocks norming...... finished! Cost 0.00 secs\n",
      "y finished! Cost 170.84 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "day blocks loading start!\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 29.59 secs\n",
      "day blocks loading finished! Cost 29.62 secs\n",
      "day blocks process...... finished! Cost 4.06 secs\n",
      "day blocks masking...... finished! Cost 0.86 secs\n",
      "day blocks saving ...... finished! Cost 3.50 secs\n",
      "day blocks norming...... finished! Cost 8.17 secs\n",
      "day finished! Cost 46.41 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "30m blocks loading start!\n",
      " --> trade blocks reading [30min] DataBase...... finished! Cost 66.96 secs\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 24.59 secs\n",
      "30m blocks loading finished! Cost 92.25 secs\n",
      "30m blocks process...... finished! Cost 37.03 secs\n",
      "30m blocks masking...... finished! Cost 2.11 secs\n",
      "30m blocks saving ...... finished! Cost 41.98 secs\n",
      "30m blocks norming...... finished! Cost 3.73 secs\n",
      "30m finished! Cost 177.29 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "style blocks loading start!\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 32.81 secs\n",
      "style blocks loading finished! Cost 32.83 secs\n",
      "style blocks process...... finished! Cost 0.00 secs\n",
      "style blocks masking...... finished! Cost 0.91 secs\n",
      "style blocks saving ...... finished! Cost 5.58 secs\n",
      "style blocks norming...... finished! Cost 0.00 secs\n",
      "style finished! Cost 39.52 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "indus blocks loading start!\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 59.46 secs\n",
      "indus blocks loading finished! Cost 59.46 secs\n",
      "indus blocks process...... finished! Cost 0.00 secs\n",
      "indus blocks masking...... finished! Cost 2.28 secs\n",
      "indus blocks saving ...... finished! Cost 29.85 secs\n",
      "indus blocks norming...... finished! Cost 0.00 secs\n",
      "indus finished! Cost 91.79 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "week blocks loading start!\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 25.89 secs\n",
      "week blocks loading finished! Cost 25.92 secs\n",
      "week blocks process...... finished! Cost 28.65 secs\n",
      "week blocks masking...... finished! Cost 2.27 secs\n",
      "week blocks saving ...... finished! Cost 25.41 secs\n",
      "week blocks norming...... finished! Cost 5.53 secs\n",
      "week finished! Cost 87.97 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "Data Processing Finished! Cost 613.81 Seconds\n",
      "predict is True , Data Processing start!\n",
      "6 datas :['y', 'day', '30m', 'style', 'indus', 'week']\n",
      "y blocks loading start!\n",
      " --> labels blocks reading [ret10_lag] DataBase...... finished! Cost 0.69 secs\n",
      " --> labels blocks reading [ret20_lag] DataBase...... finished! Cost 0.63 secs\n",
      " --> labels blocks merging (2)...... finished! Cost 0.10 secs\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 2.67 secs\n",
      "y blocks loading finished! Cost 4.30 secs\n",
      "y blocks process...... finished! Cost 2.01 secs\n",
      "y blocks masking...... finished! Cost 0.07 secs\n",
      "y blocks saving ...... finished! Cost 0.13 secs\n",
      "y blocks norming...... finished! Cost 0.00 secs\n",
      "y finished! Cost 6.68 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "day blocks loading start!\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 1.08 secs\n",
      "day blocks loading finished! Cost 1.08 secs\n",
      "day blocks process...... finished! Cost 0.10 secs\n",
      "day blocks masking...... finished! Cost 0.07 secs\n",
      "day blocks saving ...... finished! Cost 0.14 secs\n",
      "day blocks norming...... finished! Cost 0.00 secs\n",
      "day finished! Cost 1.56 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "30m blocks loading start!\n",
      " --> trade blocks reading [30min] DataBase...... finished! Cost 4.71 secs\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 0.99 secs\n",
      "30m blocks loading finished! Cost 5.75 secs\n",
      "30m blocks process...... finished! Cost 1.50 secs\n",
      "30m blocks masking...... finished! Cost 0.12 secs\n",
      "30m blocks saving ...... finished! Cost 1.39 secs\n",
      "30m blocks norming...... finished! Cost 0.00 secs\n",
      "30m finished! Cost 8.93 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "style blocks loading start!\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 1.49 secs\n",
      "style blocks loading finished! Cost 1.49 secs\n",
      "style blocks process...... finished! Cost 0.00 secs\n",
      "style blocks masking...... finished! Cost 0.07 secs\n",
      "style blocks saving ...... finished! Cost 0.20 secs\n",
      "style blocks norming...... finished! Cost 0.00 secs\n",
      "style finished! Cost 1.91 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "indus blocks loading start!\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 2.61 secs\n",
      "indus blocks loading finished! Cost 2.61 secs\n",
      "indus blocks process...... finished! Cost 0.00 secs\n",
      "indus blocks masking...... finished! Cost 0.10 secs\n",
      "indus blocks saving ...... finished! Cost 1.08 secs\n",
      "indus blocks norming...... finished! Cost 0.00 secs\n",
      "indus finished! Cost 3.98 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "week blocks loading start!\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 2.14 secs\n",
      "week blocks loading finished! Cost 2.15 secs\n",
      "week blocks process...... finished! Cost 1.57 secs\n",
      "week blocks masking...... finished! Cost 0.14 secs\n",
      "week blocks saving ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[44m24-07-20 01:02:48|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mModel Specifics:\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-07-20 01:02:48|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Data] at Sat Jul 20 01:02:48 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... finished! Cost 1.81 secs\n",
      "week blocks norming...... finished! Cost 0.00 secs\n",
      "week finished! Cost 5.83 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "Data Processing Finished! Cost 28.90 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "--Process Queue : Data + Fit + Test\n",
      "--Confirm Resume Training!\n",
      "--Model_name is set to gru_day!\n",
      "Callback : ResetOptimizer(num_reset=2,trigger=40,recover_level=1.0,speedup2x=True,kwargs={}) , reset optimizer on some epoch (can speedup scheduler)\n",
      "Callback : CallbackTimer(verbosity=2,kwargs={}) , record time cost of callback hooks\n",
      "Callback : EarlyStoppage(patience=20,kwargs={}) , stop fitting when validation score cease to improve\n",
      "Callback : ValidationConverge(patience=5,eps=1e-05,kwargs={}) , stop fitting when valid_score converge\n",
      "Callback : EarlyExitRetrain(earliest=10,max_attempt=4,lr_multiplier=[1, 0.1, 10, 0.01, 100, 1],kwargs={}) , retrain with new lr if fitting stopped too early\n",
      "Callback : NanLossRetrain(max_attempt=4,kwargs={}) , retrain if fitting encounters nan loss\n",
      "Callback : BatchDisplay(verbosity=2,kwargs={}) , display batch progress bar\n",
      "Callback : StatusDisplay(verbosity=2,kwargs={}) , display epoch and event information\n",
      "Callback : DetailedAlphaAnalysis(use_num=avg,kwargs={}) , record and concat each model to Alpha model instance\n",
      "Callback : GroupReturnAnalysis(group_num=20,kwargs={}) , record and concat each model to Alpha model instance\n",
      "{'model_name': 'gru_day',\n",
      " 'model_module': 'gru',\n",
      " 'model.types': ['best', 'swalast', 'swabest'],\n",
      " 'model.lgbm_ensembler': False,\n",
      " 'data.type': 'day',\n",
      " 'data.labels': ['std_lag1_10'],\n",
      " 'random_seed': None,\n",
      " 'beg_date': 20170103,\n",
      " 'end_date': 99991231,\n",
      " 'sample_method': 'sequential',\n",
      " 'shuffle_option': 'epoch'}\n",
      "{'hidden_dim': [32, 64],\n",
      " 'seqlens': [{'day': 30, '30m': 30, 'dms': 30}],\n",
      " 'tra_seqlens': [{'hist_loss': 40}],\n",
      " 'dropout': [0.1],\n",
      " 'enc_in': [True],\n",
      " 'enc_att': [False],\n",
      " 'rnn_type': ['lstm'],\n",
      " 'rnn_att': [False],\n",
      " 'rnn_layers': [2],\n",
      " 'dec_mlp_layers': [2],\n",
      " 'num_output': [1],\n",
      " 'kernel_size': [3],\n",
      " 'hidden_as_factor': [False],\n",
      " 'ordered_param_group': [False],\n",
      " 'tra_num_states': [5]}\n",
      "Load  1 DataBlocks...... finished! Cost 0.34 secs\n",
      "Align 1 DataBlocks...... finished! Cost 0.98 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-07-20 01:02:50|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Data], Cost 2.5 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-07-20 01:02:50|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Fit] at Sat Jul 20 01:02:50 2024!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-07-20 01:02:50|MOD:mod         |\u001b[0m: \u001b[1m\u001b[34mFirst Iterance: (20170103 , 0)\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-07-20 01:02:50|MOD:time        |\u001b[0m: \u001b[1m\u001b[31mMain Process Finished! Cost 2.5 Seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load  1 DataBlocks...... finished! Cost 0.02 secs\n",
      "Align 1 DataBlocks...... finished! Cost 0.05 secs\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'data.hidden'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataAPI , Trainer\n\u001b[1;32m      2\u001b[0m DataAPI\u001b[38;5;241m.\u001b[39mreconstruct_train_data()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mTrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/learndl/src/nn_model/trainer/trainers/api.py:35\u001b[0m, in \u001b[0;36mTrainer.update_models\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m REG_MODELS:\n\u001b[1;32m     34\u001b[0m     config_path \u001b[38;5;241m=\u001b[39m TrainConfig\u001b[38;5;241m.\u001b[39mget_config_path(model\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresume\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/learndl/src/nn_model/trainer/trainers/basic.py:225\u001b[0m, in \u001b[0;36mTrainerModule.go\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgo\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m BigTimer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mcritical , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMain Process\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 225\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Workspace/learndl/src/nn_model/classes/mod.py:329\u001b[0m, in \u001b[0;36mBaseTrainer.main_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_configure_model()\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage_queue: \n\u001b[0;32m--> 329\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstage_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_summarize_model()\n",
      "File \u001b[0;32m~/Workspace/learndl/src/nn_model/classes/mod.py:346\u001b[0m, in \u001b[0;36mBaseTrainer.stage_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mfit_iter_num \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    345\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFirst Iterance: (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mmodel_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m , \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mmodel_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_fit_end()\n",
      "File \u001b[0;32m~/Workspace/learndl/src/nn_model/trainer/trainers/aggregator.py:171\u001b[0m, in \u001b[0;36mAggregatorTrainer.fit_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_fit_model_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_idx , \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mtrain_dataloader() , \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mval_dataloader())):\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mdataset_train()\n",
      "File \u001b[0;32m~/Workspace/learndl/src/nn_model/classes/mod.py:44\u001b[0m, in \u001b[0;36mBaseCB.hook_wrapper.<locals>.wrapper_with\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_with\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mat_enter(hook_name)\n\u001b[0;32m---> 44\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mat_exit(hook_name)\n",
      "File \u001b[0;32m~/Workspace/learndl/src/nn_model/trainer/trainers/aggregator.py:199\u001b[0m, in \u001b[0;36mAggregatorTrainer.on_fit_model_start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_fit_model_start\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_param\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Workspace/learndl/src/nn_model/trainer/trainers/aggregator.py:56\u001b[0m, in \u001b[0;36mAggregatorDataModule.setup\u001b[0;34m(self, stage, param, model_date)\u001b[0m\n\u001b[1;32m     54\u001b[0m hidden_df : pd\u001b[38;5;241m.\u001b[39mDataFrame \u001b[38;5;241m|\u001b[39m Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     55\u001b[0m ds_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m stage \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hidden_key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata.hidden\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m     57\u001b[0m     model_name , model_num , model_type \u001b[38;5;241m=\u001b[39m hidden_key\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     58\u001b[0m     hidden_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(PATH\u001b[38;5;241m.\u001b[39mhidden , model_name , \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.feather\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Workspace/learndl/src/nn_model/util/config.py:245\u001b[0m, in \u001b[0;36mTrainConfig.__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[0;32m--> 245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m , k): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/learndl/src/nn_model/util/config.py:78\u001b[0m, in \u001b[0;36mTrainParam.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m , key : \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParam\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'data.hidden'"
     ]
    }
   ],
   "source": [
    "from src.api import DataAPI , Trainer\n",
    "DataAPI.reconstruct_train_data()\n",
    "Trainer.update_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device name: NVIDIA GeForce RTX 4090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:10:43|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mModel Specifics:\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:10:43|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Data] at Mon Jun 24 01:10:43 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Process Queue : Data + Fit + Test\n",
      "--Confirm Resume Training!\n",
      "--Model_name is set to gru_day!\n",
      "Callback : ResetOptimizer(num_reset=2,trigger=40,recover_level=1.0,speedup2x=True) , reset optimizer on some epoch (can speedup scheduler)\n",
      "Callback : CallbackTimer(verbosity=2) , record time cost of callback hooks\n",
      "Callback : EarlyStoppage(patience=20) , stop fitting when validation score cease to improve\n",
      "Callback : ValidationConverge(patience=5,eps=1e-05) , stop fitting when valid_score converge\n",
      "Callback : EarlyExitRetrain(earliest=5,max_attempt=4,lr_multiplier=[1, 0.1, 10, 0.01, 100]) , retrain with new lr if fitting stopped too early\n",
      "Callback : NanLossRetrain(max_attempt=4) , retrain if fitting encounters nan loss\n",
      "Callback : BatchDisplay(verbosity=2) , display batch progress bar\n",
      "Callback : StatusDisplay(verbosity=2) , display epoch and event information\n",
      "{'random_seed': None,\n",
      " 'model_name': 'gruRES_day',\n",
      " 'model_module': 'gru',\n",
      " 'model_data_type': 'day',\n",
      " 'model_types': ['best', 'swalast', 'swabest'],\n",
      " 'labels': ['std_lag1_10'],\n",
      " 'beg_date': 20170103,\n",
      " 'end_date': 99991231,\n",
      " 'sample_method': 'train_shuffle',\n",
      " 'shuffle_option': 'epoch',\n",
      " 'lgbm_ensembler': False}\n",
      "{'hidden_dim': [32, 64],\n",
      " 'seqlens': [{'day': 30, '30m': 30, 'dms': 30}],\n",
      " 'tra_seqlens': [{'hist_loss': 40}],\n",
      " 'dropout': [0.1],\n",
      " 'enc_in': [True],\n",
      " 'enc_att': [False],\n",
      " 'rnn_type': ['lstm'],\n",
      " 'rnn_att': [False],\n",
      " 'rnn_layers': [2],\n",
      " 'dec_mlp_layers': [2],\n",
      " 'num_output': [1],\n",
      " 'kernel_size': [3],\n",
      " 'hidden_as_factor': [False],\n",
      " 'ordered_param_group': [False],\n",
      " 'tra_num_states': [5]}\n",
      "Load  2 DataBlocks...... finished! Cost 2.40 secs\n",
      "Align 2 DataBlocks...... finished! Cost 2.86 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:10:51|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Data], Cost 7.9 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:10:51|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Fit] at Mon Jun 24 01:10:51 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n",
      "score function of [spearman] calculated and success!\n",
      "loss function of [pearson] calculated and success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mFirstBite Ep#  0 : loss  0.99770, train 0.00391, valid 0.03668, best 0.0367, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  5 : loss  0.87023, train 0.12798, valid 0.09558, best 0.0956, lr2.5e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 10 : loss  0.85418, train 0.14255, valid 0.08890, best 0.0956, lr1.9e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 15 : loss  0.84138, train 0.15293, valid 0.08662, best 0.0956, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 20 : loss  0.83995, train 0.15505, valid 0.09025, best 0.0956, lr9.4e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 25 : loss  0.83040, train 0.16270, valid 0.08154, best 0.0956, lr3.1e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 25 : loss  0.83040, train 0.16270, valid 0.08154, best 0.0956, lr3.1e-04, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  0 : loss  0.99907, train 0.00307, valid-0.00235, best-0.0024, lr1.3e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  5 : loss  0.89798, train 0.10238, valid 0.07134, best 0.0839, lr2.5e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 10 : loss  0.88484, train 0.11407, valid 0.08712, best 0.0892, lr1.9e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 15 : loss  0.87704, train 0.12033, valid 0.08682, best 0.0892, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 20 : loss  0.87598, train 0.12115, valid 0.08665, best 0.0892, lr9.4e-05\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 25 : loss  0.87235, train 0.12489, valid 0.08559, best 0.0892, lr3.1e-05\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 25 : loss  0.87235, train 0.12489, valid 0.08559, best 0.0892, lr3.1e-05, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  0 : loss  1.00802, train-0.01361, valid-0.04341, best-0.0434, lr1.3e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  5 : loss  0.90600, train 0.09749, valid 0.08519, best 0.0985, lr2.5e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 10 : loss  0.88704, train 0.11519, valid 0.10017, best 0.1002, lr1.9e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 15 : loss  0.88873, train 0.11359, valid 0.09794, best 0.1002, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 20 : loss  0.89135, train 0.11055, valid 0.09254, best 0.1002, lr9.4e-03\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 25 : loss  0.88877, train 0.11064, valid 0.09957, best 0.1021, lr3.1e-03\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 30 : loss  0.88839, train 0.10964, valid 0.08501, best 0.1021, lr1.6e-03\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 35 : loss  0.88399, train 0.11418, valid 0.08975, best 0.1021, lr3.1e-03\u001b[0m\n",
      "\u001b[32mReset learn rate and scheduler at the end of epoch 39 , effective at epoch 40\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 40 : loss  0.88123, train 0.11494, valid 0.09168, best 0.1021, lr1.3e-02\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:16:36|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mgruRES_day #1 @20231201|Retrain#2 Ep# 96 EarlyStop|Train 0.1037 Valid 0.0934 BestVal 0.0956|Cost  5.7Min,  3.5Sec/Ep\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  0 : loss  1.00213, train-0.00346, valid-0.02870, best-0.0287, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  5 : loss  0.88101, train 0.11998, valid 0.10566, best 0.1118, lr2.5e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 10 : loss  0.86625, train 0.13116, valid 0.09471, best 0.1118, lr1.9e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 15 : loss  0.85764, train 0.13868, valid 0.09772, best 0.1118, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 20 : loss  0.85723, train 0.13898, valid 0.10404, best 0.1118, lr9.4e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 24 : loss  0.85347, train 0.14217, valid 0.09795, best 0.1118, lr1.6e-04, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  0 : loss  0.99619, train 0.00640, valid 0.02634, best 0.0263, lr1.3e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  5 : loss  0.91904, train 0.07677, valid 0.07904, best 0.0790, lr2.5e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 10 : loss  0.90607, train 0.09211, valid 0.09041, best 0.0904, lr1.9e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 15 : loss  0.89860, train 0.10379, valid 0.09553, best 0.0956, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 20 : loss  0.89763, train 0.10523, valid 0.09337, best 0.0956, lr9.4e-05\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 24 : loss  0.89522, train 0.10913, valid 0.09689, best 0.0970, lr1.6e-05, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  0 : loss  1.00127, train-0.00532, valid-0.02776, best-0.0278, lr1.3e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  5 : loss  0.90841, train 0.09496, valid 0.09364, best 0.1105, lr2.5e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 10 : loss  0.88931, train 0.11243, valid 0.09934, best 0.1105, lr1.9e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 15 : loss  0.88411, train 0.11520, valid 0.09632, best 0.1105, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 20 : loss  0.88303, train 0.11682, valid 0.10441, best 0.1105, lr9.4e-03\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 24 : loss  0.87640, train 0.12191, valid 0.10175, best 0.1105, lr1.6e-03, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep#  0 : loss  0.99942, train 0.00330, valid 0.03781, best 0.0378, lr1.3e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep#  5 : loss  0.96270, train 0.04376, valid 0.07316, best 0.0732, lr2.5e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 10 : loss  0.95829, train 0.04798, valid 0.07296, best 0.0736, lr1.9e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 15 : loss  0.95190, train 0.05224, valid 0.07273, best 0.0736, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 20 : loss  0.95024, train 0.05357, valid 0.07160, best 0.0736, lr9.5e-06\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 24 : loss  0.94829, train 0.05503, valid 0.07283, best 0.0736, lr1.7e-06, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep#  0 : loss  0.99623, train 0.00749, valid 0.03126, best 0.0313, lr1.3e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep#  5 : loss  0.97201, train 0.03669, valid 0.04230, best 0.0540, lr2.5e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 10 : loss  0.97588, train 0.03329, valid 0.03690, best 0.0540, lr1.9e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 15 : loss  0.97586, train 0.03358, valid 0.04005, best 0.0540, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 20 : loss  0.97032, train 0.04237, valid 0.04644, best 0.0540, lr9.4e-02\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:22:42|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mgruRES_day #0 @20240604|Retrain#4 Ep#125 EarlyStop|Train 0.0369 Valid 0.0350 BestVal 0.1118|Cost  6.0Min,  2.9Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:24:48|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mgruRES_day #1 @20240604|FirstBite Ep# 34 EarlyStop|Train 0.1667 Valid 0.0877 BestVal 0.0877|Cost  2.1Min,  3.6Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:24:48|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Fit], Cost 0.2 Hours, 4.7 Min/model, 3.3 Sec/Epoch\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:24:48|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Test] at Mon Jun 24 01:24:48 2024!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:24:48|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mEach Model Date Testing Mean Score(spearman):\u001b[0m\n",
      "\u001b[32mModels            0       0       0       1       1       1\u001b[0m\n",
      "\u001b[32mOutput         best swalast swabest    best swalast swabest\u001b[0m\n",
      "\u001b[32m20170103     0.1536  0.1525  0.1520  0.1525  0.1521  0.1520\u001b[0m\n",
      "\u001b[32m20170704     0.1373  0.1327  0.1365  0.1413  0.1373  0.1405\u001b[0m\n",
      "\u001b[32m20171226     0.1305  0.1323  0.1329  0.1291  0.1298  0.1300\u001b[0m\n",
      "\u001b[32m20180627     0.1225  0.1186  0.1223  0.1226  0.1210  0.1236\u001b[0m\n",
      "\u001b[32m20181220     0.0998  0.0990  0.1004  0.0958  0.0981  0.0987\u001b[0m\n",
      "\u001b[32m20190624     0.0970  0.0955  0.0972  0.0920  0.0908  0.0924\u001b[0m\n",
      "\u001b[32m20191217     0.1011  0.0991  0.1005  0.1042  0.1048  0.1047\u001b[0m\n",
      "\u001b[32m20200617     0.0970  0.0963  0.0978  0.0947  0.0927  0.0946\u001b[0m\n",
      "\u001b[32m20201214     0.0837  0.0792  0.0842  0.0759  0.0766  0.0739\u001b[0m\n",
      "\u001b[32m20210615     0.0605  0.0572  0.0608  0.0689  0.0666  0.0662\u001b[0m\n",
      "\u001b[32m20211209     0.0935  0.0954  0.0962  0.1084  0.1106  0.1084\u001b[0m\n",
      "\u001b[32m20220613     0.0931  0.0909  0.0813  0.0857  0.0829  0.0876\u001b[0m\n",
      "\u001b[32m20221206     0.0650  0.0616  0.0635  0.0580  0.0576  0.0497\u001b[0m\n",
      "\u001b[32m20230606     0.0906  0.0857  0.0872  0.0868  0.0885  0.0856\u001b[0m\n",
      "\u001b[32m20231201     0.1217  0.1221  0.1235  0.1082  0.1025  0.1008\u001b[0m\n",
      "\u001b[32m20240604    -0.0130  0.0400 -0.0266  0.0401  0.0503  0.0572\u001b[0m\n",
      "\u001b[32mAllTimeAvg   0.1024  0.1008  0.1016  0.1012  0.1005  0.1003\u001b[0m\n",
      "\u001b[32mAllTimeSum   185.48  182.66  184.04  183.36  182.05  181.72\u001b[0m\n",
      "\u001b[32mStd          0.0668  0.0665  0.0669  0.0666  0.0656  0.0665\u001b[0m\n",
      "\u001b[32mTValue        65.23   64.56   64.64   64.69   65.24   64.18\u001b[0m\n",
      "\u001b[32mAnnIR        7.5077  7.4304  7.4389  7.4445  7.5079  7.3860\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:25:46|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Test], Cost 57.6 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:25:46|MOD:time        |\u001b[0m: \u001b[1m\u001b[31mMain Process Finished! Cost 15 Minutes 3.3 Seconds\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:25:46|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mModel Specifics:\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:25:46|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Data] at Mon Jun 24 01:25:46 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Process Queue : Data + Fit + Test\n",
      "--Confirm Resume Training!\n",
      "--Model_name is set to gruRTN_day!\n",
      "Callback : ResetOptimizer(num_reset=2,trigger=40,recover_level=1.0,speedup2x=True) , reset optimizer on some epoch (can speedup scheduler)\n",
      "Callback : CallbackTimer(verbosity=2) , record time cost of callback hooks\n",
      "Callback : EarlyStoppage(patience=20) , stop fitting when validation score cease to improve\n",
      "Callback : ValidationConverge(patience=5,eps=1e-05) , stop fitting when valid_score converge\n",
      "Callback : EarlyExitRetrain(earliest=5,max_attempt=4,lr_multiplier=[1, 0.1, 10, 0.01, 100]) , retrain with new lr if fitting stopped too early\n",
      "Callback : NanLossRetrain(max_attempt=4) , retrain if fitting encounters nan loss\n",
      "Callback : BatchDisplay(verbosity=2) , display batch progress bar\n",
      "Callback : StatusDisplay(verbosity=2) , display epoch and event information\n",
      "{'random_seed': None,\n",
      " 'model_name': 'gruRTN_day',\n",
      " 'model_module': 'gru',\n",
      " 'model_data_type': 'day',\n",
      " 'model_types': ['best', 'swalast', 'swabest'],\n",
      " 'labels': ['rtn_lag1_10'],\n",
      " 'beg_date': 20170103,\n",
      " 'end_date': 99991231,\n",
      " 'sample_method': 'train_shuffle',\n",
      " 'shuffle_option': 'epoch',\n",
      " 'lgbm_ensembler': False}\n",
      "{'hidden_dim': [32, 64],\n",
      " 'seqlens': [{'day': 30, '30m': 30, 'dms': 30}],\n",
      " 'tra_seqlens': [{'hist_loss': 40}],\n",
      " 'dropout': [0.1],\n",
      " 'enc_in': [True],\n",
      " 'enc_att': [False],\n",
      " 'rnn_type': ['lstm'],\n",
      " 'rnn_att': [False],\n",
      " 'rnn_layers': [2],\n",
      " 'dec_mlp_layers': [2],\n",
      " 'num_output': [1],\n",
      " 'kernel_size': [3],\n",
      " 'hidden_as_factor': [False],\n",
      " 'ordered_param_group': [False],\n",
      " 'tra_num_states': [5]}\n",
      "try using /home/mengkjin/Workspace/learndl/data/DataSet/day.20240605.pt , success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:25:48|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Data], Cost 2.1 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:25:48|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Fit] at Mon Jun 24 01:25:48 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mFirstBite Ep#  0 : loss  1.00382, train-0.00516, valid-0.03649, best-0.0365, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  5 : loss  0.86311, train 0.13764, valid 0.09228, best 0.0923, lr2.5e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 10 : loss  0.84547, train 0.15544, valid 0.09630, best 0.0963, lr1.9e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 15 : loss  0.83038, train 0.17066, valid 0.08826, best 0.0963, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 20 : loss  0.82732, train 0.17363, valid 0.08575, best 0.0963, lr9.4e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 25 : loss  0.81729, train 0.18370, valid 0.08407, best 0.0963, lr3.1e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 30 : loss  0.81421, train 0.18647, valid 0.08262, best 0.0963, lr1.6e-04\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:27:46|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mgruRTN_day #1 @20231201|FirstBite Ep# 31 EarlyStop|Train 0.1865 Valid 0.0826 BestVal 0.0826|Cost  1.9Min,  3.6Sec/Ep\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  0 : loss  1.00293, train-0.00341, valid-0.00344, best-0.0034, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  5 : loss  0.87709, train 0.12551, valid 0.08796, best 0.1129, lr2.5e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 10 : loss  0.86180, train 0.13731, valid 0.10436, best 0.1129, lr1.9e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 15 : loss  0.85287, train 0.14587, valid 0.10502, best 0.1129, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 20 : loss  0.85180, train 0.14778, valid 0.09660, best 0.1129, lr9.4e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 23 : loss  0.84699, train 0.15223, valid 0.10093, best 0.1129, lr1.0e-07, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  0 : loss  0.99854, train 0.00457, valid 0.01988, best 0.0199, lr1.3e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  5 : loss  0.92030, train 0.08103, valid 0.08255, best 0.0825, lr2.5e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 10 : loss  0.90702, train 0.09389, valid 0.08568, best 0.0857, lr1.9e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 15 : loss  0.89605, train 0.10568, valid 0.10030, best 0.1003, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 20 : loss  0.89414, train 0.10746, valid 0.09676, best 0.1003, lr9.4e-05\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 23 : loss  0.89076, train 0.11050, valid 0.09963, best 0.1003, lr1.0e-07, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  0 : loss  0.99821, train 0.00317, valid 0.04276, best 0.0428, lr1.3e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  5 : loss  0.91434, train 0.07999, valid 0.07219, best 0.1080, lr2.5e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 10 : loss  0.89327, train 0.10612, valid 0.08880, best 0.1080, lr1.9e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 15 : loss  0.88616, train 0.11392, valid 0.08959, best 0.1080, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 20 : loss  0.88396, train 0.11643, valid 0.09105, best 0.1080, lr9.4e-03\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 23 : loss  0.87573, train 0.12499, valid 0.08870, best 0.1080, lr1.0e-07, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep#  0 : loss  1.00152, train 0.00047, valid 0.02760, best 0.0276, lr1.3e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep#  5 : loss  0.96801, train 0.04157, valid 0.06108, best 0.0611, lr2.5e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 10 : loss  0.95807, train 0.04909, valid 0.05827, best 0.0611, lr1.9e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 15 : loss  0.95065, train 0.05443, valid 0.05588, best 0.0611, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 20 : loss  0.94877, train 0.05559, valid 0.05718, best 0.0611, lr9.5e-06\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 23 : loss  0.94672, train 0.05714, valid 0.05652, best 0.0611, lr1.0e-07, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep#  0 : loss  1.00047, train-0.00169, valid-0.00940, best-0.0094, lr1.3e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep#  5 : loss  0.97745, train 0.03642, valid 0.05397, best 0.0540, lr2.5e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 10 : loss  0.96087, train 0.04016, valid 0.04625, best 0.0540, lr1.9e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 15 : loss  0.97887, train 0.02974, valid 0.04515, best 0.0592, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 20 : loss  0.97797, train 0.03105, valid 0.02864, best 0.0592, lr9.4e-02\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:33:42|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mgruRTN_day #0 @20240604|Retrain#4 Ep#120 EarlyStop|Train 0.0324 Valid 0.0466 BestVal 0.1129|Cost  5.9Min,  2.9Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:35:37|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mgruRTN_day #1 @20240604|FirstBite Ep# 31 EarlyStop|Train 0.1916 Valid 0.0938 BestVal 0.0938|Cost  1.9Min,  3.6Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:35:37|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Fit], Cost 0.2 Hours, 3.3 Min/model, 3.2 Sec/Epoch\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:35:37|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Test] at Mon Jun 24 01:35:37 2024!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:35:37|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mEach Model Date Testing Mean Score(spearman):\u001b[0m\n",
      "\u001b[32mModels            0       0       0       1       1       1\u001b[0m\n",
      "\u001b[32mOutput         best swalast swabest    best swalast swabest\u001b[0m\n",
      "\u001b[32m20170103     0.1415  0.1404  0.1427  0.1449  0.1435  0.1447\u001b[0m\n",
      "\u001b[32m20170704     0.1344  0.1262  0.1345  0.1305  0.1318  0.1309\u001b[0m\n",
      "\u001b[32m20171226     0.1443  0.1441  0.1454  0.1443  0.1440  0.1482\u001b[0m\n",
      "\u001b[32m20180627     0.1204  0.1149  0.1163  0.1097  0.1025  0.1077\u001b[0m\n",
      "\u001b[32m20181220     0.1134  0.1100  0.1116  0.1024  0.1004  0.1035\u001b[0m\n",
      "\u001b[32m20190624     0.0928  0.0923  0.0936  0.0977  0.0973  0.0969\u001b[0m\n",
      "\u001b[32m20191217     0.1172  0.1181  0.1180  0.1052  0.1068  0.1165\u001b[0m\n",
      "\u001b[32m20200617     0.0920  0.0939  0.0939  0.0902  0.0826  0.0929\u001b[0m\n",
      "\u001b[32m20201214     0.0986  0.0984  0.0981  0.0939  0.0944  0.0957\u001b[0m\n",
      "\u001b[32m20210615     0.0696  0.0720  0.0718  0.0754  0.0735  0.0734\u001b[0m\n",
      "\u001b[32m20211209     0.1126  0.1152  0.1148  0.1102  0.1128  0.1136\u001b[0m\n",
      "\u001b[32m20220613     0.1110  0.1046  0.1063  0.1074  0.1058  0.1127\u001b[0m\n",
      "\u001b[32m20221206     0.0574  0.0559  0.0579  0.0602  0.0553  0.0578\u001b[0m\n",
      "\u001b[32m20230606     0.0824  0.0776  0.0835  0.0856  0.0771  0.0824\u001b[0m\n",
      "\u001b[32m20231201     0.1327  0.1357  0.1289  0.1284  0.1280  0.1267\u001b[0m\n",
      "\u001b[32m20240604    -0.0291  0.0381  0.0338  0.0062  0.0266  0.0194\u001b[0m\n",
      "\u001b[32mAllTimeAvg   0.1071  0.1062  0.1073  0.1051  0.1032  0.1063\u001b[0m\n",
      "\u001b[32mAllTimeSum   194.08  192.38  194.48  190.38  187.02  192.67\u001b[0m\n",
      "\u001b[32mStd          0.0877  0.0881  0.0874  0.0877  0.0868  0.0861\u001b[0m\n",
      "\u001b[32mTValue        51.97   51.28   52.26   51.01   50.60   52.58\u001b[0m\n",
      "\u001b[32mAnnIR        5.9810  5.9022  6.0149  5.8711  5.8230  6.0509\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:36:32|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Test], Cost 54.9 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:36:32|MOD:time        |\u001b[0m: \u001b[1m\u001b[31mMain Process Finished! Cost 10 Minutes 45.7 Seconds\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:36:32|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mModel Specifics:\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:36:32|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Data] at Mon Jun 24 01:36:32 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Process Queue : Data + Fit + Test\n",
      "--Confirm Resume Training!\n",
      "--Model_name is set to gruRES_day!\n",
      "Callback : ResetOptimizer(num_reset=2,trigger=40,recover_level=1.0,speedup2x=True) , reset optimizer on some epoch (can speedup scheduler)\n",
      "Callback : CallbackTimer(verbosity=2) , record time cost of callback hooks\n",
      "Callback : EarlyStoppage(patience=20) , stop fitting when validation score cease to improve\n",
      "Callback : ValidationConverge(patience=5,eps=1e-05) , stop fitting when valid_score converge\n",
      "Callback : EarlyExitRetrain(earliest=5,max_attempt=4,lr_multiplier=[1, 0.1, 10, 0.01, 100]) , retrain with new lr if fitting stopped too early\n",
      "Callback : NanLossRetrain(max_attempt=4) , retrain if fitting encounters nan loss\n",
      "Callback : BatchDisplay(verbosity=2) , display batch progress bar\n",
      "Callback : StatusDisplay(verbosity=2) , display epoch and event information\n",
      "{'random_seed': None,\n",
      " 'model_name': 'gruRES_day',\n",
      " 'model_module': 'gru',\n",
      " 'model_data_type': 'day',\n",
      " 'model_types': ['best', 'swalast', 'swabest'],\n",
      " 'labels': ['res_lag1_10'],\n",
      " 'beg_date': 20170103,\n",
      " 'end_date': 99991231,\n",
      " 'sample_method': 'train_shuffle',\n",
      " 'shuffle_option': 'epoch',\n",
      " 'lgbm_ensembler': False}\n",
      "{'hidden_dim': [32, 64],\n",
      " 'seqlens': [{'day': 30, '30m': 30, 'dms': 30}],\n",
      " 'tra_seqlens': [{'hist_loss': 40}],\n",
      " 'dropout': [0.1],\n",
      " 'enc_in': [True],\n",
      " 'enc_att': [False],\n",
      " 'rnn_type': ['lstm'],\n",
      " 'rnn_att': [False],\n",
      " 'rnn_layers': [2],\n",
      " 'dec_mlp_layers': [2],\n",
      " 'num_output': [1],\n",
      " 'kernel_size': [3],\n",
      " 'hidden_as_factor': [False],\n",
      " 'ordered_param_group': [False],\n",
      " 'tra_num_states': [5]}\n",
      "try using /home/mengkjin/Workspace/learndl/data/DataSet/day.20240605.pt , success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:36:34|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Data], Cost 2.0 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:36:34|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Fit] at Mon Jun 24 01:36:34 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mFirstBite Ep#  0 : loss  1.01252, train-0.01521, valid-0.03742, best-0.0374, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  5 : loss  0.91026, train 0.08135, valid 0.03185, best 0.0599, lr2.5e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 10 : loss  0.89291, train 0.09436, valid 0.04522, best 0.0599, lr1.9e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 15 : loss  0.87755, train 0.10648, valid 0.03959, best 0.0599, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 20 : loss  0.87426, train 0.10831, valid 0.03543, best 0.0599, lr9.4e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 21 : loss  0.87082, train 0.11088, valid 0.03980, best 0.0599, lr6.3e-04, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  0 : loss  0.99637, train 0.00462, valid 0.03106, best 0.0311, lr1.3e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  5 : loss  0.94196, train 0.05698, valid 0.03578, best 0.0560, lr2.5e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 10 : loss  0.92553, train 0.06750, valid 0.03080, best 0.0560, lr1.9e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 15 : loss  0.91653, train 0.07499, valid 0.03537, best 0.0560, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 20 : loss  0.91509, train 0.07561, valid 0.04185, best 0.0560, lr9.4e-05\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 21 : loss  0.91403, train 0.07721, valid 0.04641, best 0.0560, lr6.3e-05, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  0 : loss  1.00549, train-0.00683, valid-0.02416, best-0.0242, lr1.3e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  5 : loss  0.94359, train 0.04867, valid 0.02798, best 0.0514, lr2.5e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 10 : loss  0.93368, train 0.05600, valid 0.02787, best 0.0514, lr1.9e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 15 : loss  0.92716, train 0.06278, valid 0.03398, best 0.0514, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 20 : loss  0.92646, train 0.06384, valid 0.04303, best 0.0514, lr9.4e-03\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 21 : loss  0.92585, train 0.06408, valid 0.03492, best 0.0514, lr6.3e-03, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep#  0 : loss  1.01260, train-0.01493, valid-0.03974, best-0.0397, lr1.3e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep#  5 : loss  0.96876, train 0.02948, valid 0.04494, best 0.0477, lr2.5e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 10 : loss  0.96445, train 0.03233, valid 0.04554, best 0.0477, lr1.9e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 15 : loss  0.96098, train 0.03497, valid 0.04404, best 0.0477, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 20 : loss  0.96022, train 0.03574, valid 0.04354, best 0.0477, lr9.5e-06\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 21 : loss  0.95992, train 0.03628, valid 0.04487, best 0.0477, lr6.3e-06, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep#  0 : loss  0.99746, train 0.00225, valid-0.00306, best-0.0031, lr1.3e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep#  5 : loss  0.97511, train 0.02839, valid 0.01301, best 0.0537, lr2.5e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 10 : loss  0.96875, train 0.03070, valid 0.01638, best 0.0537, lr1.9e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 15 : loss  0.96160, train 0.03236, valid 0.03529, best 0.0537, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 20 : loss  0.96655, train 0.02830, valid 0.04237, best 0.0537, lr9.4e-02\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:43:22|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mgruRES_day #1 @20231201|Retrain#4 Ep#110 EarlyStop|Train 0.0293 Valid 0.0368 BestVal 0.0599|Cost  6.7Min,  3.6Sec/Ep\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  0 : loss  0.99752, train 0.00292, valid 0.02356, best 0.0236, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  5 : loss  0.92738, train 0.06719, valid 0.04180, best 0.0533, lr2.5e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 10 : loss  0.90904, train 0.07964, valid 0.02435, best 0.0533, lr1.9e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 15 : loss  0.89805, train 0.08672, valid 0.03391, best 0.0533, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 20 : loss  0.89733, train 0.08698, valid 0.03455, best 0.0533, lr9.4e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 21 : loss  0.89541, train 0.08806, valid 0.04139, best 0.0533, lr6.3e-04, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  0 : loss  1.00733, train-0.00926, valid-0.03680, best-0.0368, lr1.3e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep#  5 : loss  0.95510, train 0.04285, valid 0.05432, best 0.0549, lr2.5e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 10 : loss  0.94688, train 0.04934, valid 0.04339, best 0.0549, lr1.9e-04\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 15 : loss  0.93907, train 0.05436, valid 0.03791, best 0.0549, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 20 : loss  0.93641, train 0.05594, valid 0.03422, best 0.0549, lr9.4e-05\u001b[0m\n",
      "\u001b[32mRetrain#1 Ep# 22 : loss  0.93590, train 0.05702, valid 0.04172, best 0.0549, lr3.1e-05, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  0 : loss  0.99719, train 0.00375, valid 0.01564, best 0.0156, lr1.3e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep#  5 : loss  0.94177, train 0.04812, valid 0.03631, best 0.0465, lr2.5e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 10 : loss  0.93093, train 0.05774, valid 0.03864, best 0.0465, lr1.9e-02\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 15 : loss  0.92785, train 0.05940, valid 0.02965, best 0.0465, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 20 : loss  0.92459, train 0.06304, valid 0.03018, best 0.0465, lr9.4e-03\u001b[0m\n",
      "\u001b[32mRetrain#2 Ep# 22 : loss  0.92154, train 0.06476, valid 0.03223, best 0.0465, lr3.1e-03, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep#  0 : loss  0.99855, train 0.00161, valid 0.01776, best 0.0178, lr1.3e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep#  5 : loss  0.97299, train 0.02829, valid 0.05143, best 0.0514, lr2.5e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 10 : loss  0.96918, train 0.02884, valid 0.05178, best 0.0518, lr1.9e-05\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 15 : loss  0.96640, train 0.02942, valid 0.05233, best 0.0523, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 20 : loss  0.96524, train 0.02948, valid 0.05201, best 0.0523, lr9.5e-06\u001b[0m\n",
      "\u001b[32mRetrain#3 Ep# 22 : loss  0.96442, train 0.03008, valid 0.05196, best 0.0523, lr3.2e-06, Next attempt goes!\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep#  0 : loss  1.00164, train-0.00223, valid-0.02355, best-0.0236, lr1.3e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep#  5 : loss  0.97856, train 0.02428, valid 0.02481, best 0.0474, lr2.5e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 10 : loss  0.97707, train 0.02539, valid 0.04388, best 0.0474, lr1.9e-01\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 15 : loss  0.97920, train 0.02491, valid 0.01606, best 0.0474, lr1.0e-07\u001b[0m\n",
      "\u001b[32mRetrain#4 Ep# 20 : loss  0.97573, train 0.02385, valid 0.01877, best 0.0474, lr9.4e-02\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:48:54|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mgruRES_day #0 @20240604|Retrain#4 Ep#114 EarlyStop|Train 0.0265 Valid 0.0202 BestVal 0.0549|Cost  5.5Min,  2.9Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:56:07|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mgruRES_day #1 @20240604|Retrain#4 Ep#115 EarlyStop|Train 0.0274 Valid 0.0224 BestVal 0.0568|Cost  7.2Min,  3.7Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:56:07|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Fit], Cost 0.3 Hours, 6.5 Min/model, 3.5 Sec/Epoch\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:56:07|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Test] at Mon Jun 24 01:56:07 2024!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-06-24 01:56:07|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mEach Model Date Testing Mean Score(spearman):\u001b[0m\n",
      "\u001b[32mModels            0       0       0       1       1       1\u001b[0m\n",
      "\u001b[32mOutput         best swalast swabest    best swalast swabest\u001b[0m\n",
      "\u001b[32m20170103     0.1107  0.1119  0.1114  0.1060  0.1068  0.1081\u001b[0m\n",
      "\u001b[32m20170704     0.0937  0.0946  0.0972  0.0970  0.0989  0.0993\u001b[0m\n",
      "\u001b[32m20171226     0.0889  0.0892  0.0893  0.0901  0.0905  0.0905\u001b[0m\n",
      "\u001b[32m20180627     0.0713  0.0712  0.0713  0.0738  0.0715  0.0736\u001b[0m\n",
      "\u001b[32m20181220     0.0733  0.0742  0.0746  0.0740  0.0741  0.0728\u001b[0m\n",
      "\u001b[32m20190624     0.0702  0.0701  0.0703  0.0663  0.0672  0.0681\u001b[0m\n",
      "\u001b[32m20191217     0.0774  0.0745  0.0763  0.0789  0.0759  0.0750\u001b[0m\n",
      "\u001b[32m20200617     0.0555  0.0563  0.0570  0.0597  0.0579  0.0592\u001b[0m\n",
      "\u001b[32m20201214     0.0610  0.0605  0.0609  0.0619  0.0606  0.0642\u001b[0m\n",
      "\u001b[32m20210615     0.0406  0.0406  0.0438  0.0459  0.0475  0.0477\u001b[0m\n",
      "\u001b[32m20211209     0.0568  0.0572  0.0567  0.0561  0.0556  0.0573\u001b[0m\n",
      "\u001b[32m20220613     0.0457  0.0450  0.0465  0.0447  0.0461  0.0462\u001b[0m\n",
      "\u001b[32m20221206     0.0241  0.0235  0.0277  0.0287  0.0243  0.0296\u001b[0m\n",
      "\u001b[32m20230606     0.0589  0.0451  0.0425  0.0361  0.0324  0.0353\u001b[0m\n",
      "\u001b[32m20231201     0.0291  0.0323  0.0298  0.0140  0.0078  0.0160\u001b[0m\n",
      "\u001b[32m20240604    -0.0728 -0.0680 -0.0678 -0.0540  0.0016 -0.0326\u001b[0m\n",
      "\u001b[32mAllTimeAvg   0.0629  0.0622  0.0628  0.0614  0.0608  0.0622\u001b[0m\n",
      "\u001b[32mAllTimeSum   113.98  112.74  113.82  111.32  110.09  112.77\u001b[0m\n",
      "\u001b[32mStd          0.0537  0.0507  0.0500  0.0504  0.0493  0.0490\u001b[0m\n",
      "\u001b[32mTValue        49.87   52.28   53.42   51.92   52.51   54.01\u001b[0m\n",
      "\u001b[32mAnnIR        5.7394  6.0170  6.1485  5.9749  6.0436  6.2161\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:57:02|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Test], Cost 55.3 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-06-24 01:57:02|MOD:time        |\u001b[0m: \u001b[1m\u001b[31mMain Process Finished! Cost 20 Minutes 30.0 Seconds\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.api import Trainer\n",
    "Trainer.update_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
