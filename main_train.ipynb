{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False 2.2.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available() , torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[44m24-05-31 19:02:26|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mModel Specifics:\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-31 19:02:26|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Data] at Fri May 31 19:02:26 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device name: NVIDIA GeForce RTX 4090\n",
      "--Process Queue : Data + Fit + Test\n",
      "--Start Training New!\n",
      "--Model_name is set to tra_day.7!\n",
      "Callback : ResetOptimizer(num_reset=2,trigger=40,recover_level=1.0,speedup2x=True) , reset optimizer on some epoch (can speedup scheduler)\n",
      "Callback : CallbackTimer(verbosity=2) , record time cost of callback hooks\n",
      "Callback : EarlyStoppage(patience=20) , stop fitting when validation score cease to improve\n",
      "Callback : ValidationConverge(patience=5,eps=1e-05) , stop fitting when valid_score converge\n",
      "Callback : EarlyExitRetrain(earliest=10,max_attempt=4,lr_multiplier=[1, 0.1, 10, 0.01, 100, 1]) , retrain with new lr if fitting stopped too early\n",
      "Callback : NanLossRetrain(max_attempt=4) , retrain if fitting encounters nan loss\n",
      "Callback : BatchDisplay(verbosity=2) , display batch progress bar\n",
      "Callback : StatusDisplay(verbosity=2) , display epoch and event information\n",
      "Callback : SpecCB_TRA() , in TRA fill [y] [hist_loss] in batch_data.kwargs , update hist_loss in data.buffer\n",
      "{'random_seed': None,\n",
      " 'model_name': 'tra_day.7',\n",
      " 'model_module': 'tra',\n",
      " 'model_data_type': 'day',\n",
      " 'model_types': ['best', 'swalast', 'swabest'],\n",
      " 'labels': ['std_lag1_10', 'std_lag1_20'],\n",
      " 'beg_date': 20170103,\n",
      " 'end_date': 99991231,\n",
      " 'sample_method': 'sequential',\n",
      " 'shuffle_option': 'epoch',\n",
      " 'lgbm_ensembler': False}\n",
      "{'hidden_dim': [32],\n",
      " 'seqlens': [{'day': 30, '30m': 30, 'dms': 30}],\n",
      " 'hist_loss_seq_len': [60],\n",
      " 'hist_loss_horizon': [20],\n",
      " 'num_states': [3],\n",
      " 'dropout': [0.1],\n",
      " 'rnn_layers': [2],\n",
      " 'rnn_type': ['lstm']}\n",
      "try using /home/mengkjin/Workspace/learndl/data/DataSet/day.20240509.pt , success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-05-31 19:02:28|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Data], Cost 2.4 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-31 19:02:28|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Fit] at Fri May 31 19:02:28 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n",
      "score function of [spearman] calculated and success!\n",
      "loss function of [pearson] calculated and success!\n",
      "penalty function of [hidden_corr] calculated and success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mFirstBite Ep#  0 : loss  1.02299, train-0.01065, valid-0.00868, best-0.0087, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  5 : loss  0.92754, train 0.09928, valid 0.10419, best 0.1086, lr2.5e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 10 : loss  0.88970, train 0.12779, valid 0.13113, best 0.1317, lr1.9e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 15 : loss  0.87008, train 0.14366, valid 0.13444, best 0.1406, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 20 : loss  0.86823, train 0.14533, valid 0.15401, best 0.1540, lr9.4e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 25 : loss  0.85747, train 0.15575, valid 0.15092, best 0.1586, lr3.1e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 30 : loss  0.85603, train 0.15709, valid 0.14642, best 0.1586, lr1.6e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 35 : loss  0.85469, train 0.15853, valid 0.15316, best 0.1586, lr3.1e-04\u001b[0m\n",
      "\u001b[32mReset learn rate and scheduler at the end of epoch 39 , effective at epoch 40\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 40 : loss  0.85081, train 0.16193, valid 0.15298, best 0.1586, lr1.3e-03\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-31 19:06:53|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mtra_day.7 #0 @20170103|FirstBite Ep# 43 EarlyStop|Train 0.1467 Valid 0.1455 BestVal 0.1455|Cost  4.4Min,  5.9Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-31 19:13:52|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mtra_day.7 #0 @20170704|FirstBite Ep# 62 EarlyStop|Train 0.1658 Valid 0.1357 BestVal 0.1357|Cost  6.9Min,  6.6Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-31 19:25:15|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mtra_day.7 #0 @20171226|FirstBite Ep#101 EarlyStop|Train 0.1908 Valid 0.1407 BestVal 0.1407|Cost 11.3Min,  6.7Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-31 19:30:38|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mtra_day.7 #0 @20180627|FirstBite Ep# 47 EarlyStop|Train 0.1487 Valid 0.1341 BestVal 0.1341|Cost  5.3Min,  6.7Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-31 19:38:46|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mtra_day.7 #0 @20181220|FirstBite Ep# 71 EarlyStop|Train 0.1753 Valid 0.1353 BestVal 0.1353|Cost  8.1Min,  6.7Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-31 19:45:26|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mtra_day.7 #0 @20190624|FirstBite Ep# 58 EarlyStop|Train 0.1757 Valid 0.1373 BestVal 0.1373|Cost  6.6Min,  6.7Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-31 19:56:16|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mtra_day.7 #0 @20191217|FirstBite Ep# 94 EarlyStop|Train 0.1894 Valid 0.1230 BestVal 0.1230|Cost 10.8Min,  6.8Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-31 20:08:13|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mtra_day.7 #0 @20200617|FirstBite Ep#101 EarlyStop|Train 0.1678 Valid 0.1127 BestVal 0.1127|Cost 11.9Min,  7.0Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-31 20:13:10|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mtra_day.7 #0 @20201214|FirstBite Ep# 41 EarlyStop|Train 0.1515 Valid 0.0921 BestVal 0.0921|Cost  4.9Min,  7.0Sec/Ep\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src import API\n",
    "API.Trainer.main(stage = 0 , resume = 0 , checkname= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
       "         0.1000],\n",
       "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
       "         0.1000],\n",
       "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
       "         0.1000],\n",
       "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
       "         0.1000],\n",
       "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
       "         0.1000],\n",
       "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
       "         0.1000],\n",
       "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
       "         0.1000],\n",
       "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
       "         0.1000],\n",
       "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
       "         0.1000],\n",
       "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
       "         0.1000]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "Q = torch.zeros(10,10)\n",
    "def shoot_infs(inp_tensor):\n",
    "    \"\"\"Replaces inf by maximum of tensor\"\"\"\n",
    "    mask_inf = torch.isinf(inp_tensor)\n",
    "    ind_inf = torch.nonzero(mask_inf, as_tuple=False)\n",
    "    if len(ind_inf) > 0:\n",
    "        for ind in ind_inf:\n",
    "            if len(ind) == 2:\n",
    "                inp_tensor[ind[0], ind[1]] = 0\n",
    "            elif len(ind) == 1:\n",
    "                inp_tensor[ind[0]] = 0\n",
    "        m = torch.max(inp_tensor)\n",
    "        for ind in ind_inf:\n",
    "            if len(ind) == 2:\n",
    "                inp_tensor[ind[0], ind[1]] = m\n",
    "            elif len(ind) == 1:\n",
    "                inp_tensor[ind[0]] = m\n",
    "    return inp_tensor\n",
    "\n",
    "def sinkhorn(Q, n_iters=3, epsilon=0.01):\n",
    "    # epsilon should be adjusted according to logits value's scale\n",
    "    with torch.no_grad():\n",
    "        Q = shoot_infs(Q)\n",
    "        Q = torch.exp(Q / epsilon)\n",
    "        for i in range(n_iters):\n",
    "            Q /= Q.sum(dim=0, keepdim=True)\n",
    "            Q /= Q.sum(dim=1, keepdim=True)\n",
    "    return Q\n",
    "\n",
    "sinkhorn(Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import API\n",
    "API.DataAPI.reconstruct_train_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
