{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False 2.2.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available() , torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[44m24-05-14 22:10:21|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mModel Specifics:\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-14 22:10:21|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Data] at Tue May 14 22:10:21 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Process Queue : Data + Fit + Test\n",
      "--Model_name is set to gru_day_ShortTest!\n",
      "Callback : DynamicDataLink() , assign / unlink dynamic data in tra networks\n",
      "Callback : ResetOptimizer(num_reset=2,trigger=40,recover_level=1.0,speedup2x=True) , reset optimizer on some epoch (can speedup scheduler)\n",
      "Callback : CallbackTimer(verbosity=10) , record time cost of callback hooks\n",
      "Callback : EarlyStoppage(patience=20) , stop fitting when validation score cease to improve\n",
      "Callback : ValidationConverge(patience=5,eps=1e-05) , stop fitting when valid_score converge\n",
      "Callback : EarlyExitRetrain(earliest=20,max_attempt=4,lr_multiplier=[1, 0.1, 10, 0.01, 100, 1]) , retrain with new lr if fitting stopped too early\n",
      "Callback : NanLossRetrain(max_attempt=4) , retrain if fitting encounters nan loss\n",
      "Callback : BatchDisplay(verbosity=10) , display batch progress bar\n",
      "Callback : StatusDisplay(verbosity=10) , display epoch / event information\n",
      "{'random_seed': None,\n",
      " 'model_name': 'gru_day_ShortTest',\n",
      " 'model_module': 'gru',\n",
      " 'model_data_type': 'day',\n",
      " 'beg_date': 20170103,\n",
      " 'end_date': 20170228,\n",
      " 'sample_method': 'train_shuffle',\n",
      " 'shuffle_option': 'epoch'}\n",
      "{'hidden_dim': [32],\n",
      " 'seqlens': [{'day': 30, '30m': 30, 'dms': 30}],\n",
      " 'tra_seqlens': [{'hist_loss': 40}],\n",
      " 'dropout': [0.1],\n",
      " 'enc_in': [True],\n",
      " 'enc_att': [False],\n",
      " 'rnn_type': ['gru'],\n",
      " 'rnn_att': [False],\n",
      " 'rnn_layers': [2],\n",
      " 'dec_mlp_layers': [2],\n",
      " 'num_output': [1],\n",
      " 'kernel_size': [3],\n",
      " 'hidden_as_factor': [True],\n",
      " 'ordered_param_group': [False]}\n",
      "use d:\\Coding\\learndl\\learndl\\data\\torch_pack/day.20240315.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-05-14 22:10:22|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Data], Cost 1.7 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-14 22:10:22|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Fit] at Tue May 14 22:10:22 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score function of [spearman] calculated and success!\n",
      "loss function of [pearson] calculated and success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Ep#  0 loss : 1.00168: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Valid Ep#  0 score : 0.00971: 100%|██████████| 10/10 [00:01<00:00,  8.90it/s]\n",
      "\u001b[32mFirstBite Ep#  0 : loss  1.00168, train-0.00325, valid 0.00971, best 0.0097, lr1.3e-03\u001b[0m\n",
      "Train Ep#  1 loss : 0.98262: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Valid Ep#  1 score : 0.06187: 100%|██████████| 10/10 [00:01<00:00,  7.90it/s]\n",
      "\u001b[32mFirstBite Ep#  1 : loss  0.98262, train 0.02002, valid 0.06187, best 0.0619, lr2.5e-03\u001b[0m\n",
      "Train Ep#  2 loss : 0.95260: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Valid Ep#  2 score : 0.16437: 100%|██████████| 10/10 [00:01<00:00,  8.81it/s]\n",
      "\u001b[32mFirstBite Ep#  2 : loss  0.95260, train 0.04459, valid 0.16437, best 0.1644, lr3.8e-03\u001b[0m\n",
      "Train Ep#  3 loss : 0.92552: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Valid Ep#  3 score : 0.08263: 100%|██████████| 10/10 [00:01<00:00,  8.65it/s]\n",
      "\u001b[32mFirstBite Ep#  3 : loss  0.92552, train 0.08332, valid 0.08263, best 0.1644, lr5.0e-03\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-14 22:11:15|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mgru_day_ShortTest #0 @20170103|FirstBite Ep#  4 Max Epoch|Train 0.0833 Valid 0.0826 BestVal 0.1644|Cost  0.9Min, 10.3Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-14 22:11:15|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Fit], Cost 0.0 Hours, 0.9 Min/model, 13.3 Sec/Epoch\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-14 22:11:15|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Test] at Tue May 14 22:11:15 2024!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-05-14 22:11:15|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mEach Model Date Testing Mean Score(spearman):\u001b[0m\n",
      "\u001b[32mModels            0       0       0\u001b[0m\n",
      "\u001b[32mOutput         best swalast swabest\u001b[0m\n",
      "Test best 20170228 score : 0.01768: 100%|██████████| 35/35 [00:04<00:00,  7.24it/s]\n",
      "Test swalast 20170228 score : -0.01317: 100%|██████████| 35/35 [00:04<00:00,  7.47it/s]\n",
      "Test swabest 20170228 score : -0.01367: 100%|██████████| 35/35 [00:04<00:00,  7.57it/s]\n",
      "\u001b[32m20170103     0.0177 -0.0132 -0.0137\u001b[0m\n",
      "\u001b[32mAllTimeAvg   0.0177 -0.0132 -0.0137\u001b[0m\n",
      "\u001b[32mAllTimeSum     0.62   -0.46   -0.48\u001b[0m\n",
      "\u001b[32mStd          0.0250  0.0362  0.0201\u001b[0m\n",
      "\u001b[32mTValue         4.19   -2.15   -4.03\u001b[0m\n",
      "\u001b[32mAnnIR        3.4702 -1.7801 -3.3351\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-14 22:11:30|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Test], Cost 14.7 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-14 22:11:30|MOD:__init__    |\u001b[0m: \u001b[1m\u001b[31mMain Process Finished! Cost 1 Minutes 9.6 Seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    hook_name  num_calls  total_time  avg_time\n",
      "8              on_train_batch         40   37.774022  0.944351\n",
      "23              on_test_batch        105   13.883700  0.132226\n",
      "17           on_fit_model_end          1    9.022725  9.022725\n",
      "13        on_validation_batch         40    4.634479  0.115862\n",
      "4          on_fit_model_start          1    1.629283  1.629283\n",
      "20        on_test_model_start          1    0.558109  0.558109\n",
      "24          on_test_batch_end        105    0.163892  0.001561\n",
      "16           on_fit_epoch_end          4    0.029176  0.007294\n",
      "14    on_validation_batch_end         40    0.021450  0.000536\n",
      "9          on_train_batch_end         40    0.020072  0.000502\n",
      "27                on_test_end          1    0.013076  0.013076\n",
      "11  on_validation_epoch_start          4    0.011776  0.002944\n",
      "19              on_test_start          1    0.005514  0.005514\n",
      "21   on_test_model_type_start          3    0.003008  0.001003\n",
      "25     on_test_model_type_end          3    0.002893  0.000964\n",
      "10         on_train_epoch_end          4    0.002049  0.000512\n",
      "12  on_validation_batch_start         40    0.002020  0.000051\n",
      "28         on_summarize_model          1    0.001994  0.001994\n",
      "26          on_test_model_end          1    0.000996  0.000996\n",
      "18                 on_fit_end          1    0.000000  0.000000\n",
      "15    on_validation_epoch_end          4    0.000000  0.000000\n",
      "1               on_data_start          1    0.000000  0.000000\n",
      "7        on_train_batch_start         40    0.000000  0.000000\n",
      "22        on_test_batch_start        105    0.000000  0.000000\n",
      "6        on_train_epoch_start          4    0.000000  0.000000\n",
      "5          on_fit_epoch_start          4    0.000000  0.000000\n",
      "3                on_fit_start          1    0.000000  0.000000\n",
      "2                 on_data_end          1    0.000000  0.000000\n",
      "0          on_configure_model          1    0.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "# %% test a specific model\n",
    "from src.interface import ModelTrainer\n",
    "ModelTrainer.main(stage = 0 , resume = 0 , checkname= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.interface import ModelTrainer\n",
    "ModelTrainer.main(stage = 0 , resume = 0 , checkname= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "from src.interface import DataModule\n",
    "DataModule.prepare_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
