{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False 2.2.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available() , torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[44m24-05-28 23:04:21|MOD:display     |\u001b[0m: \u001b[1m\u001b[34mModel Specifics:\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-28 23:04:21|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Data] at Tue May 28 23:04:21 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Process Queue : Data + Fit + Test\n",
      "--Model_name is set to factor_vae_day_ShortTest!\n",
      "Callback : DynamicDataLink() , assign and unlink dynamic data in tra networks\n",
      "Callback : ResetOptimizer(num_reset=2,trigger=40,recover_level=1.0,speedup2x=True) , reset optimizer on some epoch (can speedup scheduler)\n",
      "Callback : CallbackTimer(verbosity=10) , record time cost of callback hooks\n",
      "Callback : EarlyStoppage(patience=20) , stop fitting when validation score cease to improve\n",
      "Callback : ValidationConverge(patience=5,eps=1e-05) , stop fitting when valid_score converge\n",
      "Callback : EarlyExitRetrain(earliest=10,max_attempt=4,lr_multiplier=[1, 0.1, 10, 0.01, 100, 1]) , retrain with new lr if fitting stopped too early\n",
      "Callback : NanLossRetrain(max_attempt=4) , retrain if fitting encounters nan loss\n",
      "Callback : BatchDisplay(verbosity=10) , display batch progress bar\n",
      "Callback : StatusDisplay(verbosity=10) , display epoch and event information\n",
      "Callback : SpecCB_factor_vae() , factor vae additional batch_data components (y and reparameterize noise)\n",
      "{'random_seed': None,\n",
      " 'model_name': 'factor_vae_day_ShortTest',\n",
      " 'model_module': 'factor_vae',\n",
      " 'model_data_type': 'day',\n",
      " 'model_types': ['best', 'swalast', 'swabest'],\n",
      " 'labels': ['std_lag1_10', 'std_lag1_20'],\n",
      " 'beg_date': 20170101,\n",
      " 'end_date': 20170228,\n",
      " 'sample_method': 'train_shuffle',\n",
      " 'shuffle_option': 'epoch',\n",
      " 'lgbm_ensembler': False}\n",
      "{'hidden_dim': [32],\n",
      " 'seqlens': [{'day': 30, '30m': 30, 'dms': 30}],\n",
      " 'factor_num': [64],\n",
      " 'gru_input_size': [16],\n",
      " 'portfolio_size': [100],\n",
      " 'encoder_h_size': [32],\n",
      " 'alpha_h_size': [64],\n",
      " 'predictor_h_size': [16],\n",
      " 'monte_carlo': [100],\n",
      " 'gamma': [1.0]}\n",
      "try using d:\\Coding\\learndl\\learndl\\data\\DataSet/day.20240315.pt , success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-05-28 23:04:23|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Data], Cost 2.0 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-28 23:04:23|MOD:display     |\u001b[0m: \u001b[1m\u001b[31mStart Process [Fit] at Tue May 28 23:04:23 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score function of [spearman] calculated and success!\n",
      "loss function of [pearson] calculated and success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Ep#  0 loss : 1997.70007: 100%|██████████| 10/10 [00:11<00:00,  1.18s/it]\n",
      "Valid Ep#  0 score : -0.04446: 100%|██████████| 10/10 [00:02<00:00,  3.59it/s]\n",
      "\u001b[32mFirstBite Ep#  0 : loss  2001.51941, train 0.02278, valid 0.00306, best 0.0031, lr1.3e-03\u001b[0m\n",
      "Train Ep#  1 loss : 1319.44067: 100%|██████████| 10/10 [00:11<00:00,  1.16s/it]\n",
      "Valid Ep#  1 score : -0.04355: 100%|██████████| 10/10 [00:03<00:00,  3.27it/s]\n",
      "\u001b[32mFirstBite Ep#  1 : loss  1709.85026, train-0.00546, valid 0.06125, best 0.0613, lr2.5e-03\u001b[0m\n",
      "Train Ep#  2 loss : 111.32858: 100%|██████████| 10/10 [00:13<00:00,  1.34s/it]\n",
      "Valid Ep#  2 score : -0.04894: 100%|██████████| 10/10 [00:03<00:00,  3.01it/s]\n",
      "\u001b[32mFirstBite Ep#  2 : loss  476.05406, train 0.02698, valid 0.11953, best 0.1195, lr3.8e-03\u001b[0m\n",
      "Train Ep#  3 loss : 30.22276: 100%|██████████| 10/10 [00:12<00:00,  1.25s/it]\n",
      "Valid Ep#  3 score : -0.05206: 100%|██████████| 10/10 [00:03<00:00,  2.85it/s]\n",
      "\u001b[32mFirstBite Ep#  3 : loss  73.22220, train 0.04199, valid 0.14900, best 0.1490, lr5.0e-03\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-05-28 23:05:27|MOD:time        |\u001b[0m: \u001b[1m\u001b[31mMain Process Finished! Cost 1 Minutes 6.2 Seconds\u001b[0m\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m API\n\u001b[1;32m----> 2\u001b[0m \u001b[43mAPI\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresume\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Coding\\learndl\\learndl\\src\\API\\trainer.py:52\u001b[0m, in \u001b[0;36mTrainer.main\u001b[1;34m(cls, stage, resume, checkname, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m app \u001b[38;5;241m=\u001b[39m use_trainer(stage \u001b[38;5;241m=\u001b[39m stage , resume \u001b[38;5;241m=\u001b[39m resume , checkname \u001b[38;5;241m=\u001b[39m checkname , \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m BigTimer(app\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mcritical , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMain Process\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 52\u001b[0m     \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Coding\\learndl\\learndl\\src\\classes\\mod.py:403\u001b[0m, in \u001b[0;36mBaseTrainer.main_process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_configure_model()\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage_queue: \n\u001b[1;32m--> 403\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstage_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_summarize_model()\n",
      "File \u001b[1;32md:\\Coding\\learndl\\learndl\\src\\classes\\mod.py:418\u001b[0m, in \u001b[0;36mBaseTrainer.stage_fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_fit_start()\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mmodel_date , \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mmodel_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_iter:\n\u001b[1;32m--> 418\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_fit_end()\n",
      "File \u001b[1;32md:\\Coding\\learndl\\learndl\\src\\API\\trainer.py:95\u001b[0m, in \u001b[0;36mNetTrainer.fit_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mfit_epoch_end()\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_fit_epoch_end()\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_fit_model_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Coding\\learndl\\learndl\\src\\classes\\mod.py:119\u001b[0m, in \u001b[0;36mBaseCB.hook_wrapper.<locals>.wrapper_with\u001b[1;34m()\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_with\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mat_enter(hook_name)\n\u001b[1;32m--> 119\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mat_exit(hook_name)\n",
      "File \u001b[1;32md:\\Coding\\learndl\\learndl\\src\\API\\trainer.py:113\u001b[0m, in \u001b[0;36mNetTrainer.on_fit_model_end\u001b[1;34m(self)\u001b[0m\n\u001b[1;32m--> 113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_fit_model_end\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Coding\\learndl\\learndl\\src\\API\\trainer.py:184\u001b[0m, in \u001b[0;36mNetTrainer.save_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m     [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeposition\u001b[38;5;241m.\u001b[39mdump_model(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_date , \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_num , model_type) \u001b[38;5;28;01mfor\u001b[39;00m model_type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_types]\n",
      "File \u001b[1;32md:\\Coding\\learndl\\learndl\\src\\API\\trainer.py:180\u001b[0m, in \u001b[0;36mNetTrainer.stack_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_before_save_model()\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_types:\n\u001b[1;32m--> 180\u001b[0m     model_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeposition\u001b[38;5;241m.\u001b[39mstack_model(model_dict , \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_date , \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_num , model_type)\n",
      "File \u001b[1;32md:\\Coding\\learndl\\learndl\\src\\util\\model\\manager.py:90\u001b[0m, in \u001b[0;36mNetManager.collect\u001b[1;34m(self, model_type, *args)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcollect\u001b[39m(\u001b[38;5;28mself\u001b[39m , model_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m'\u001b[39m , \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     89\u001b[0m     model_dict \u001b[38;5;241m=\u001b[39m ModelDict()\n\u001b[1;32m---> 90\u001b[0m     net \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet_ensemblers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m     model_dict\u001b[38;5;241m.\u001b[39mstate_dict \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mstate_dict()\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet_lgbm_head: model_dict\u001b[38;5;241m.\u001b[39mbooster_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet_lgbm_head\u001b[38;5;241m.\u001b[39mfit(net)\u001b[38;5;241m.\u001b[39mmodel_string\n",
      "File \u001b[1;32md:\\Coding\\learndl\\learndl\\src\\util\\model\\net.py:150\u001b[0m, in \u001b[0;36mEnsembleSWALast.collect\u001b[1;34m(self, net, data, device, *args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     swa\u001b[38;5;241m.\u001b[39mupdate_sd(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt\u001b[38;5;241m.\u001b[39mload_epoch(epoch))\n\u001b[0;32m    149\u001b[0m loader \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mtrain_dataloader()\n\u001b[1;32m--> 150\u001b[0m \u001b[43mswa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_bn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m swa\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mcpu()\n",
      "File \u001b[1;32md:\\Coding\\learndl\\learndl\\src\\util\\model\\net.py:44\u001b[0m, in \u001b[0;36mSWAModel.update_bn\u001b[1;34m(self, data_loader, device)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_bn\u001b[39m(\u001b[38;5;28mself\u001b[39m , data_loader , device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgmodel \u001b[38;5;241m=\u001b[39m device(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgmodel) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(device) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgmodel\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 44\u001b[0m     \u001b[43mupdate_bn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mavgmodel\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\jinmeng\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jinmeng\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\swa_utils.py:272\u001b[0m, in \u001b[0;36mupdate_bn\u001b[1;34m(loader, model, device)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m--> 272\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bn_module \u001b[38;5;129;01min\u001b[39;00m momenta\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    275\u001b[0m     bn_module\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;241m=\u001b[39m momenta[bn_module]\n",
      "File \u001b[1;32mc:\\Users\\jinmeng\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jinmeng\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jinmeng\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\swa_utils.py:178\u001b[0m, in \u001b[0;36mAveragedModel.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jinmeng\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jinmeng\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Coding\\learndl\\learndl\\src\\nn\\factorVAE.py:48\u001b[0m, in \u001b[0;36mFactorVAE.forward\u001b[1;34m(self, x, y, factor_noise, alpha_noise)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03min  : \u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    x : [bs x seq_len x input_dim]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m    in eval     : y_hat , \u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, y\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m factor_noise \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m factor_noise\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfactor_num , factor_noise\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m alpha_noise \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m alpha_noise\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mAssertionError\u001b[0m: None"
     ]
    }
   ],
   "source": [
    "from src import API\n",
    "API.Trainer.main(stage = 0 , resume = 0 , checkname= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0160)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([0.0102, 0.0219])\n",
    "v = torch.nanmean(a , dim = -1)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seqlens': [{'day': 30, '30m': 30, 'dms': 30}],\n",
       " 'objective': ['regression'],\n",
       " 'linear_tree': [True],\n",
       " 'learning_rate': [0.3],\n",
       " 'lambda_l2': ['1e-05'],\n",
       " 'alpha': ['1e-07'],\n",
       " 'num_leaves': [31],\n",
       " 'max_depth': [6],\n",
       " 'min_sum_hessian_in_leaf': [1],\n",
       " 'feature_fraction': [0.6],\n",
       " 'bagging_fraction': [0.75],\n",
       " 'force_col_wise': [True],\n",
       " 'monotone_constraints': [1]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.environ import PATH\n",
    "PATH.read_yaml('./configs/model_lgbm.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device name: NVIDIA GeForce RTX 4090\n",
      "predict is False , Data Processing start!\n",
      "4 datas :['y', 'day', '30m', 'risk']\n",
      "y blocks loading start!\n",
      " --> labels blocks reading [ret10_lag] DataBase...... finished! Cost 18.86 secs\n",
      " --> labels blocks reading [ret20_lag] DataBase...... finished! Cost 20.08 secs\n",
      " --> labels blocks merging (2)...... finished! Cost 2.88 secs\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 67.78 secs\n",
      "y blocks loading finished! Cost 120.52 secs\n",
      "y blocks process...... finished! Cost 45.61 secs\n",
      "y blocks masking...... finished! Cost 0.81 secs\n",
      "y blocks saving ...... finished! Cost 3.76 secs\n",
      "y blocks norming...... finished! Cost 0.00 secs\n",
      "y finished! Cost 170.98 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "day blocks loading start!\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 28.95 secs\n",
      "day blocks loading finished! Cost 28.98 secs\n",
      "day blocks process...... finished! Cost 3.27 secs\n",
      "day blocks masking...... finished! Cost 0.86 secs\n",
      "day blocks saving ...... finished! Cost 3.56 secs\n",
      "day blocks norming...... finished! Cost 7.99 secs\n",
      "day finished! Cost 44.82 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "30m blocks loading start!\n",
      " --> trade blocks reading [30min] DataBase...... finished! Cost 67.25 secs\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 24.67 secs\n",
      "30m blocks loading finished! Cost 92.86 secs\n",
      "30m blocks process...... finished! Cost 32.48 secs\n",
      "30m blocks masking...... finished! Cost 2.42 secs\n",
      "30m blocks saving ...... finished! Cost 40.51 secs\n",
      "30m blocks norming...... finished! Cost 3.77 secs\n",
      "30m finished! Cost 172.21 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "risk blocks loading start!\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 32.95 secs\n",
      "risk blocks loading finished! Cost 32.97 secs\n",
      "risk blocks process...... finished! Cost 0.00 secs\n",
      "risk blocks masking...... finished! Cost 0.89 secs\n",
      "risk blocks saving ...... finished! Cost 5.45 secs\n",
      "risk blocks norming...... finished! Cost 0.00 secs\n",
      "risk finished! Cost 39.42 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "Data Processing Finished! Cost 427.43 Seconds\n",
      "predict is True , Data Processing start!\n",
      "4 datas :['y', 'day', '30m', 'risk']\n",
      "y blocks loading start!\n",
      " --> labels blocks reading [ret10_lag] DataBase...... finished! Cost 0.71 secs\n",
      " --> labels blocks reading [ret20_lag] DataBase...... finished! Cost 0.66 secs\n",
      " --> labels blocks merging (2)...... finished! Cost 0.09 secs\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 2.77 secs\n",
      "y blocks loading finished! Cost 4.44 secs\n",
      "y blocks process...... finished! Cost 1.94 secs\n",
      "y blocks masking...... finished! Cost 0.07 secs\n",
      "y blocks saving ...... finished! Cost 0.13 secs\n",
      "y blocks norming...... finished! Cost 0.00 secs\n",
      "y finished! Cost 6.68 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "day blocks loading start!\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 1.09 secs\n",
      "day blocks loading finished! Cost 1.09 secs\n",
      "day blocks process...... finished! Cost 0.10 secs\n",
      "day blocks masking...... finished! Cost 0.07 secs\n",
      "day blocks saving ...... finished! Cost 0.28 secs\n",
      "day blocks norming...... finished! Cost 0.00 secs\n",
      "day finished! Cost 1.65 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "30m blocks loading start!\n",
      " --> trade blocks reading [30min] DataBase...... finished! Cost 4.47 secs\n",
      " --> trade blocks reading [day] DataBase...... finished! Cost 0.97 secs\n",
      "30m blocks loading finished! Cost 5.49 secs\n",
      "30m blocks process...... finished! Cost 1.39 secs\n",
      "30m blocks masking...... finished! Cost 0.12 secs\n",
      "30m blocks saving ...... finished! Cost 2.08 secs\n",
      "30m blocks norming...... finished! Cost 0.00 secs\n",
      "30m finished! Cost 9.20 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "risk blocks loading start!\n",
      " --> models blocks reading [risk_exp] DataBase...... finished! Cost 1.49 secs\n",
      "risk blocks loading finished! Cost 1.49 secs\n",
      "risk blocks process...... finished! Cost 0.00 secs\n",
      "risk blocks masking...... finished! Cost 0.08 secs\n",
      "risk blocks saving ...... finished! Cost 0.21 secs\n",
      "risk blocks norming...... finished! Cost 0.00 secs\n",
      "risk finished! Cost 1.88 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "Data Processing Finished! Cost 19.42 Seconds\n"
     ]
    }
   ],
   "source": [
    "from src import API\n",
    "API.DataAPI.reconstruct_train_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
