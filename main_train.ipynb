{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% test cuda\n",
    "import torch #type: ignore\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device name: NVIDIA GeForce RTX 4090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[44m24-04-22 22:57:29|MOD:ModelModule |\u001b[0m: \u001b[1m\u001b[34mModel Specifics:\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-04-22 22:57:29|MOD:ModelModule |\u001b[0m: \u001b[1m\u001b[31mStart Process [Data] at Mon Apr 22 22:57:29 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Process Queue : Data + Fit + Test\n",
      "--Start Training New!\n",
      "--Model_name is set to patch_tst_day.2!\n",
      "{'random_seed': None,\n",
      " 'model_name': 'patch_tst_day.2',\n",
      " 'model_module': 'patch_tst',\n",
      " 'model_data_type': 'day',\n",
      " 'model_data_prenorm': {'day': {'divlast': True, 'histnorm': True}},\n",
      " 'labels': ['std_lag1_10'],\n",
      " 'beg_date': 20170103,\n",
      " 'end_date': 99991231,\n",
      " 'interval': 120,\n",
      " 'input_step_day': 5,\n",
      " 'sample_method': 'train_shuffle',\n",
      " 'shuffle_option': 'epoch'}\n",
      "{'hidden_dim': [64],\n",
      " 'seqlens': [{'day': 30, '30m': 30, 'dms': 30}],\n",
      " 'seq_len': [30],\n",
      " 'dropout': [0.1],\n",
      " 'attn_dropout': [0.1],\n",
      " 'num_output': [1],\n",
      " 'shared_embedding': [True],\n",
      " 'shared_head': [False],\n",
      " 'revin': [True],\n",
      " 'act_type': ['gelu'],\n",
      " 'patch_len': [4, 5, 6],\n",
      " 'stride': [2, 2, 3],\n",
      " 'n_layers': [2],\n",
      " 'n_heads': [16],\n",
      " 'd_ff': [64]}\n",
      "use /home/mengkjin/Workspace/learndl/data/torch_pack/day.20240313.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-04-22 22:57:32|MOD:ModelModule |\u001b[0m: \u001b[1m\u001b[31mFinish Process [Data], Cost 3.4 Secs\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[41m24-04-22 22:57:32|MOD:pipeline    |\u001b[0m: \u001b[1m\u001b[31mStart Process [Fit] at Mon Apr 22 22:57:32 2024!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Norming method of [day] : {'divlast': True, 'histnorm': True}\n",
      "score function of [spearman] calculated and success!\n",
      "loss function of [pearson] calculated and success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mFirstBite Ep#  0 : loss  1.00699, train-0.01640, valid-0.03714, best-0.0371, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  5 : loss  0.91880, train 0.09936, valid 0.10605, best 0.1061, lr3.8e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 10 : loss  0.90317, train 0.11348, valid 0.11316, best 0.1145, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 15 : loss  0.88842, train 0.12828, valid 0.11636, best 0.1276, lr6.3e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 20 : loss  0.88110, train 0.13543, valid 0.12144, best 0.1276, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 25 : loss  0.86495, train 0.15123, valid 0.13509, best 0.1351, lr1.6e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 30 : loss  0.85906, train 0.15782, valid 0.12673, best 0.1351, lr3.1e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 35 : loss  0.85635, train 0.16081, valid 0.12477, best 0.1369, lr2.3e-04\u001b[0m\n",
      "\u001b[32mReset learn rate and scheduler at the end of epoch 39 , effective at epoch 40, and will speedup2x\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 40 : loss  0.85095, train 0.16764, valid 0.13439, best 0.1369, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 45 : loss  0.86066, train 0.15794, valid 0.11762, best 0.1369, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 50 : loss  0.84472, train 0.17455, valid 0.12163, best 0.1369, lr1.3e-03\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-04-22 23:13:21|MOD:ModelModule |\u001b[0m: \u001b[1m\u001b[34mpatch_tst_day.2 #0 @20170103|FirstBite Ep# 54 EarlyStop|Train 0.1826 Valid 0.1189 BestVal 0.1369|Cost 15.8Min, 17.2Sec/Ep\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  0 : loss  0.99937, train-0.00653, valid 0.01307, best 0.0131, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep#  5 : loss  0.91758, train 0.09763, valid 0.10781, best 0.1078, lr3.8e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 10 : loss  0.90042, train 0.11582, valid 0.09738, best 0.1078, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 15 : loss  0.88318, train 0.13293, valid 0.10585, best 0.1147, lr6.3e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 20 : loss  0.87594, train 0.14042, valid 0.12671, best 0.1267, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 25 : loss  0.86185, train 0.15495, valid 0.12100, best 0.1269, lr1.6e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 30 : loss  0.85512, train 0.16191, valid 0.12982, best 0.1298, lr3.1e-04\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 35 : loss  0.85208, train 0.16471, valid 0.13059, best 0.1306, lr2.3e-04\u001b[0m\n",
      "\u001b[32mReset learn rate and scheduler at the end of epoch 39 , effective at epoch 40, and will speedup2x\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 40 : loss  0.84740, train 0.17009, valid 0.12772, best 0.1306, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 45 : loss  0.85063, train 0.16682, valid 0.12062, best 0.1306, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 50 : loss  0.83805, train 0.18142, valid 0.11410, best 0.1314, lr1.3e-03\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 55 : loss  0.82723, train 0.19200, valid 0.12053, best 0.1314, lr3.1e-04\u001b[0m\n",
      "\u001b[32mReset learn rate and scheduler at the end of epoch 59 , effective at epoch 60, and will speedup2x\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 60 : loss  0.82287, train 0.19589, valid 0.12063, best 0.1314, lr1.0e-07\u001b[0m\n",
      "\u001b[32mFirstBite Ep# 65 : loss  0.82706, train 0.19318, valid 0.11657, best 0.1314, lr1.3e-03\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-04-22 23:31:19|MOD:ModelModule |\u001b[0m: \u001b[1m\u001b[34mpatch_tst_day.2 #1 @20170103|FirstBite Ep# 66 EarlyStop|Train 0.1929 Valid 0.1130 BestVal 0.1314|Cost 18.0Min, 16.1Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-04-22 23:39:18|MOD:ModelModule |\u001b[0m: \u001b[1m\u001b[34mpatch_tst_day.2 #2 @20170103|FirstBite Ep# 38 EarlyStop|Train 0.2016 Valid 0.1257 BestVal 0.1360|Cost  8.0Min, 12.3Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-04-22 23:57:50|MOD:ModelModule |\u001b[0m: \u001b[1m\u001b[34mpatch_tst_day.2 #0 @20170704|FirstBite Ep# 61 EarlyStop|Train 0.1762 Valid 0.1079 BestVal 0.1242|Cost 18.5Min, 17.9Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-04-23 00:09:22|MOD:ModelModule |\u001b[0m: \u001b[1m\u001b[34mpatch_tst_day.2 #1 @20170704|FirstBite Ep# 40 EarlyStop|Train 0.1326 Valid 0.1002 BestVal 0.1081|Cost 11.5Min, 16.9Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-04-23 00:18:19|MOD:ModelModule |\u001b[0m: \u001b[1m\u001b[34mpatch_tst_day.2 #2 @20170704|FirstBite Ep# 41 EarlyStop|Train 0.1463 Valid 0.1034 BestVal 0.1266|Cost  9.0Min, 12.8Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-04-23 00:28:39|MOD:ModelModule |\u001b[0m: \u001b[1m\u001b[34mpatch_tst_day.2 #0 @20171226|FirstBite Ep# 32 EarlyStop|Train 0.1612 Valid 0.1134 BestVal 0.1237|Cost 10.3Min, 18.7Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-04-23 00:52:54|MOD:ModelModule |\u001b[0m: \u001b[1m\u001b[34mpatch_tst_day.2 #1 @20171226|FirstBite Ep# 83 EarlyStop|Train 0.2253 Valid 0.1049 BestVal 0.1207|Cost 24.3Min, 17.3Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-04-23 01:03:56|MOD:ModelModule |\u001b[0m: \u001b[1m\u001b[34mpatch_tst_day.2 #2 @20171226|FirstBite Ep# 49 EarlyStop|Train 0.1851 Valid 0.1113 BestVal 0.1211|Cost 11.0Min, 13.2Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-04-23 01:22:57|MOD:ModelModule |\u001b[0m: \u001b[1m\u001b[34mpatch_tst_day.2 #0 @20180627|FirstBite Ep# 58 EarlyStop|Train 0.1947 Valid 0.1126 BestVal 0.1169|Cost 19.0Min, 19.3Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-04-23 01:42:49|MOD:ModelModule |\u001b[0m: \u001b[1m\u001b[34mpatch_tst_day.2 #1 @20180627|FirstBite Ep# 65 EarlyStop|Train 0.1833 Valid 0.1067 BestVal 0.1165|Cost 19.9Min, 18.1Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-04-23 01:49:57|MOD:ModelModule |\u001b[0m: \u001b[1m\u001b[34mpatch_tst_day.2 #2 @20180627|FirstBite Ep# 30 EarlyStop|Train 0.2004 Valid 0.1106 BestVal 0.1195|Cost  7.1Min, 13.8Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-04-23 02:17:16|MOD:ModelModule |\u001b[0m: \u001b[1m\u001b[34mpatch_tst_day.2 #0 @20181220|FirstBite Ep# 81 EarlyStop|Train 0.2506 Valid 0.0900 BestVal 0.1069|Cost 27.3Min, 20.0Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-04-23 02:40:04|MOD:ModelModule |\u001b[0m: \u001b[1m\u001b[34mpatch_tst_day.2 #1 @20181220|FirstBite Ep# 72 EarlyStop|Train 0.2258 Valid 0.0957 BestVal 0.1011|Cost 22.8Min, 18.7Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-04-23 02:53:24|MOD:ModelModule |\u001b[0m: \u001b[1m\u001b[34mpatch_tst_day.2 #2 @20181220|FirstBite Ep# 55 EarlyStop|Train 0.2222 Valid 0.1001 BestVal 0.1058|Cost 13.3Min, 14.3Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-04-23 03:14:55|MOD:ModelModule |\u001b[0m: \u001b[1m\u001b[34mpatch_tst_day.2 #0 @20190624|FirstBite Ep# 61 EarlyStop|Train 0.2009 Valid 0.0965 BestVal 0.1051|Cost 21.5Min, 20.8Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-04-23 03:28:36|MOD:ModelModule |\u001b[0m: \u001b[1m\u001b[34mpatch_tst_day.2 #1 @20190624|FirstBite Ep# 41 EarlyStop|Train 0.1891 Valid 0.1017 BestVal 0.1101|Cost 13.7Min, 19.6Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-04-23 03:39:17|MOD:ModelModule |\u001b[0m: \u001b[1m\u001b[34mpatch_tst_day.2 #2 @20190624|FirstBite Ep# 42 EarlyStop|Train 0.1721 Valid 0.1006 BestVal 0.1069|Cost 10.7Min, 14.9Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-04-23 03:51:42|MOD:ModelModule |\u001b[0m: \u001b[1m\u001b[34mpatch_tst_day.2 #0 @20191217|FirstBite Ep# 33 EarlyStop|Train 0.2287 Valid 0.0859 BestVal 0.1050|Cost 12.4Min, 21.8Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-04-23 04:03:37|MOD:ModelModule |\u001b[0m: \u001b[1m\u001b[34mpatch_tst_day.2 #1 @20191217|FirstBite Ep# 34 EarlyStop|Train 0.2144 Valid 0.0950 BestVal 0.1028|Cost 11.9Min, 20.4Sec/Ep\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[44m24-04-23 04:11:56|MOD:ModelModule |\u001b[0m: \u001b[1m\u001b[34mpatch_tst_day.2 #2 @20191217|FirstBite Ep# 31 EarlyStop|Train 0.2234 Valid 0.0874 BestVal 0.1047|Cost  8.3Min, 15.6Sec/Ep\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [<src.util.trainer.model.SWALast object at 0x78a1d28afc40>]\n",
      "1 [<src.util.trainer.model.SWALast object at 0x78a1d28afc40>]\n",
      "2 [<src.util.trainer.model.SWALast object at 0x78a1d28afc40>]\n",
      "3 [<src.util.trainer.model.SWALast object at 0x78a1d28afc40>]\n",
      "4 [<src.util.trainer.model.BestModel object at 0x78a196c5f670>, <src.util.trainer.model.SWALast object at 0x78a1d28afc40>, <src.util.trainer.model.SWABest object at 0x78a1d28ac100>]\n",
      "5 [<src.util.trainer.model.SWALast object at 0x78a1d28afc40>]\n",
      "6 [<src.util.trainer.model.SWALast object at 0x78a1d28afc40>]\n",
      "7 [<src.util.trainer.model.SWALast object at 0x78a1d28afc40>, <src.util.trainer.model.SWABest object at 0x78a1d28ac100>]\n",
      "8 [<src.util.trainer.model.SWALast object at 0x78a1d28afc40>]\n",
      "9 [<src.util.trainer.model.SWALast object at 0x78a1d28afc40>]\n",
      "10 [<src.util.trainer.model.SWALast object at 0x78a1d28afc40>]\n",
      "11 [<src.util.trainer.model.SWALast object at 0x78a1d28afc40>]\n",
      "12 [<src.util.trainer.model.SWALast object at 0x78a1d28afc40>]\n",
      "13 [<src.util.trainer.model.SWALast object at 0x78a1d28afc40>]\n",
      "14 [<src.util.trainer.model.SWALast object at 0x78a1d28afc40>]\n",
      "15 [<src.util.trainer.model.SWALast object at 0x78a1d28afc40>]\n",
      "16 [<src.util.trainer.model.SWALast object at 0x78a1d28afc40>]\n",
      "17 [<src.util.trainer.model.SWALast object at 0x78a1d28afc40>]\n",
      "18 [<src.util.trainer.model.SWALast object at 0x78a1d28afc40>, <src.util.trainer.model.SWABest object at 0x78a1d28ac100>]\n",
      "19 [<src.util.trainer.model.SWALast object at 0x78a1d28afc40>]\n",
      "20 [<src.util.trainer.model.SWALast object at 0x78a1d28afc40>, <src.util.trainer.model.SWABest object at 0x78a1d28ac100>]\n",
      "21 [<src.util.trainer.model.SWALast object at 0x78a1d28afc40>, <src.util.trainer.model.SWABest object at 0x78a1d28ac100>]\n",
      "22 [<src.util.trainer.model.SWALast object at 0x78a1d28afc40>]\n",
      "23 [<src.util.trainer.model.SWALast object at 0x78a1d28afc40>]\n",
      "24 [<src.util.trainer.model.SWALast object at 0x78a1d28afc40>]\n",
      "JOIN: Epoch 0, from <class 'src.util.trainer.model.BestModel'>(132635414623856), append list, state dict saved\n",
      "JOIN: Epoch 0, from <class 'src.util.trainer.model.SWALast'>(132636417391680), append list, no need to save\n",
      "JOIN: Epoch 0, from <class 'src.util.trainer.model.SWABest'>(132636417376512), append list, no need to save\n",
      "DISJOIN: Epoch 0, from <class 'src.util.trainer.model.BestModel'>(132635414623856), 2 reliance left\n",
      "JOIN: Epoch 1, from <class 'src.util.trainer.model.BestModel'>(132635414623856), append list, state dict saved\n",
      "JOIN: Epoch 1, from <class 'src.util.trainer.model.SWALast'>(132636417391680), append list, no need to save\n",
      "JOIN: Epoch 1, from <class 'src.util.trainer.model.SWABest'>(132636417376512), append list, no need to save\n",
      "DISJOIN: Epoch 1, from <class 'src.util.trainer.model.BestModel'>(132635414623856), 2 reliance left\n",
      "JOIN: Epoch 2, from <class 'src.util.trainer.model.BestModel'>(132635414623856), append list, state dict saved\n",
      "JOIN: Epoch 2, from <class 'src.util.trainer.model.SWALast'>(132636417391680), append list, no need to save\n",
      "JOIN: Epoch 2, from <class 'src.util.trainer.model.SWABest'>(132636417376512), append list, no need to save\n",
      "JOIN: Epoch 3, from <class 'src.util.trainer.model.SWALast'>(132636417391680), append list, state dict saved\n",
      "JOIN: Epoch 3, from <class 'src.util.trainer.model.SWABest'>(132636417376512), append list, no need to save\n",
      "DISJOIN: Epoch 2, from <class 'src.util.trainer.model.BestModel'>(132635414623856), 2 reliance left\n",
      "JOIN: Epoch 4, from <class 'src.util.trainer.model.BestModel'>(132635414623856), append list, state dict saved\n",
      "JOIN: Epoch 4, from <class 'src.util.trainer.model.SWALast'>(132636417391680), append list, no need to save\n",
      "JOIN: Epoch 4, from <class 'src.util.trainer.model.SWABest'>(132636417376512), append list, no need to save\n",
      "JOIN: Epoch 5, from <class 'src.util.trainer.model.SWALast'>(132636417391680), append list, state dict saved\n",
      "DISJOIN: Epoch 0, from <class 'src.util.trainer.model.SWABest'>(132636417376512), 1 reliance left\n",
      "JOIN: Epoch 5, from <class 'src.util.trainer.model.SWABest'>(132636417376512), append list, no need to save\n",
      "JOIN: Epoch 6, from <class 'src.util.trainer.model.SWALast'>(132636417391680), append list, state dict saved\n",
      "DISJOIN: Epoch 3, from <class 'src.util.trainer.model.SWABest'>(132636417376512), 1 reliance left\n",
      "JOIN: Epoch 6, from <class 'src.util.trainer.model.SWABest'>(132636417376512), append list, no need to save\n",
      "JOIN: Epoch 7, from <class 'src.util.trainer.model.SWALast'>(132636417391680), append list, state dict saved\n",
      "DISJOIN: Epoch 1, from <class 'src.util.trainer.model.SWABest'>(132636417376512), 1 reliance left\n",
      "JOIN: Epoch 7, from <class 'src.util.trainer.model.SWABest'>(132636417376512), append list, no need to save\n",
      "JOIN: Epoch 8, from <class 'src.util.trainer.model.SWALast'>(132636417391680), append list, state dict saved\n",
      "DISJOIN: Epoch 2, from <class 'src.util.trainer.model.SWABest'>(132636417376512), 1 reliance left\n",
      "JOIN: Epoch 8, from <class 'src.util.trainer.model.SWABest'>(132636417376512), append list, no need to save\n",
      "JOIN: Epoch 9, from <class 'src.util.trainer.model.SWALast'>(132636417391680), append list, state dict saved\n",
      "DISJOIN: Epoch 5, from <class 'src.util.trainer.model.SWABest'>(132636417376512), 1 reliance left\n",
      "JOIN: Epoch 9, from <class 'src.util.trainer.model.SWABest'>(132636417376512), append list, no need to save\n",
      "JOIN: Epoch 10, from <class 'src.util.trainer.model.SWALast'>(132636417391680), append list, state dict saved\n",
      "DISJOIN: Epoch 6, from <class 'src.util.trainer.model.SWABest'>(132636417376512), 1 reliance left\n",
      "JOIN: Epoch 10, from <class 'src.util.trainer.model.SWABest'>(132636417376512), append list, no need to save\n",
      "JOIN: Epoch 11, from <class 'src.util.trainer.model.SWALast'>(132636417391680), append list, state dict saved\n",
      "DISJOIN: Epoch 8, from <class 'src.util.trainer.model.SWABest'>(132636417376512), 1 reliance left\n",
      "JOIN: Epoch 11, from <class 'src.util.trainer.model.SWABest'>(132636417376512), append list, no need to save\n",
      "JOIN: Epoch 12, from <class 'src.util.trainer.model.SWALast'>(132636417391680), append list, state dict saved\n",
      "JOIN: Epoch 13, from <class 'src.util.trainer.model.SWALast'>(132636417391680), append list, state dict saved\n",
      "DISJOIN: Epoch 10, from <class 'src.util.trainer.model.SWABest'>(132636417376512), 1 reliance left\n",
      "JOIN: Epoch 13, from <class 'src.util.trainer.model.SWABest'>(132636417376512), append list, no need to save\n",
      "JOIN: Epoch 14, from <class 'src.util.trainer.model.SWALast'>(132636417391680), append list, state dict saved\n",
      "JOIN: Epoch 15, from <class 'src.util.trainer.model.SWALast'>(132636417391680), append list, state dict saved\n",
      "JOIN: Epoch 16, from <class 'src.util.trainer.model.SWALast'>(132636417391680), append list, state dict saved\n",
      "JOIN: Epoch 17, from <class 'src.util.trainer.model.SWALast'>(132636417391680), append list, state dict saved\n",
      "JOIN: Epoch 18, from <class 'src.util.trainer.model.SWALast'>(132636417391680), append list, state dict saved\n",
      "DISJOIN: Epoch 13, from <class 'src.util.trainer.model.SWABest'>(132636417376512), 1 reliance left\n",
      "JOIN: Epoch 18, from <class 'src.util.trainer.model.SWABest'>(132636417376512), append list, no need to save\n",
      "JOIN: Epoch 19, from <class 'src.util.trainer.model.SWALast'>(132636417391680), append list, state dict saved\n",
      "JOIN: Epoch 20, from <class 'src.util.trainer.model.SWALast'>(132636417391680), append list, state dict saved\n",
      "DISJOIN: Epoch 11, from <class 'src.util.trainer.model.SWABest'>(132636417376512), 1 reliance left\n",
      "JOIN: Epoch 20, from <class 'src.util.trainer.model.SWABest'>(132636417376512), append list, no need to save\n",
      "JOIN: Epoch 21, from <class 'src.util.trainer.model.SWALast'>(132636417391680), append list, state dict saved\n",
      "DISJOIN: Epoch 9, from <class 'src.util.trainer.model.SWABest'>(132636417376512), 1 reliance left\n",
      "JOIN: Epoch 21, from <class 'src.util.trainer.model.SWABest'>(132636417376512), append list, no need to save\n",
      "JOIN: Epoch 22, from <class 'src.util.trainer.model.SWALast'>(132636417391680), append list, state dict saved\n",
      "JOIN: Epoch 23, from <class 'src.util.trainer.model.SWALast'>(132636417391680), append list, state dict saved\n",
      "JOIN: Epoch 24, from <class 'src.util.trainer.model.SWALast'>(132636417391680), append list, state dict saved\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "no connection of epoch -2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# %% test a specific model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelTrainer\n\u001b[0;32m----> 3\u001b[0m \u001b[43mModelTrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresume\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/learndl/src/ModelModule.py:450\u001b[0m, in \u001b[0;36mModelTrainer.fit\u001b[0;34m(cls, stage, resume, checkname, timer, parser_args)\u001b[0m\n\u001b[1;32m    447\u001b[0m config\u001b[38;5;241m.\u001b[39mprint_out()\n\u001b[1;32m    449\u001b[0m app \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(timer \u001b[38;5;241m=\u001b[39m timer)\n\u001b[0;32m--> 450\u001b[0m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/learndl/src/ModelModule.py:190\u001b[0m, in \u001b[0;36mModelTrainer.main_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m'''Main stage of data & fit & test'''\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mstage_queue: \n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstage_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipe\u001b[38;5;241m.\u001b[39mdump_info()\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mptimer\u001b[38;5;241m.\u001b[39mprint()\n",
      "File \u001b[0;32m~/Workspace/learndl/src/ModelModule.py:205\u001b[0m, in \u001b[0;36mModelTrainer.stage_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_date , \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_iter():\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_fit_start()\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_fit_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_fit_end()\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage_fit_end()\n",
      "File \u001b[0;32m~/Workspace/learndl/src/ModelModule.py:256\u001b[0m, in \u001b[0;36mModelTrainer.model_fit_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_fit_loop_body()\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_fit_loop_assess()\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_fit_loop_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/learndl/src/ModelModule.py:291\u001b[0m, in \u001b[0;36mModelTrainer.model_fit_loop_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mptimer(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/loop_end\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipe\u001b[38;5;241m.\u001b[39mloop_status \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 291\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipe\u001b[38;5;241m.\u001b[39mloop_status \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattempt\u001b[39m\u001b[38;5;124m'\u001b[39m: \n\u001b[1;32m    293\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_attempt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Workspace/learndl/src/ModelModule.py:423\u001b[0m, in \u001b[0;36mModelTrainer.save_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_type , model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 423\u001b[0m     sd \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeposition\u001b[38;5;241m.\u001b[39msave_state_dict(sd , \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_date , model_type))\n",
      "File \u001b[0;32m~/Workspace/learndl/src/util/trainer/model.py:131\u001b[0m, in \u001b[0;36mSWALast.state_dict\u001b[0;34m(self, net, data_loader, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m swa \u001b[38;5;241m=\u001b[39m SWAModel(net)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcandidates: \n\u001b[0;32m--> 131\u001b[0m     swa\u001b[38;5;241m.\u001b[39mupdate_sd(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    132\u001b[0m swa\u001b[38;5;241m.\u001b[39mupdate_bn(data_loader , \u001b[38;5;28mgetattr\u001b[39m(data_loader , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m , \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m swa\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mstate_dict()\n",
      "File \u001b[0;32m~/Workspace/learndl/src/util/trainer/ckpt.py:57\u001b[0m, in \u001b[0;36mCheckpoint.load_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(rel) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28mprint\u001b[39m(i , rel)\n\u001b[1;32m     56\u001b[0m     [\u001b[38;5;28mprint\u001b[39m(record_str) \u001b[38;5;28;01mfor\u001b[39;00m record_str \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_record]\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno connection of epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_path(epoch))\n",
      "\u001b[0;31mException\u001b[0m: no connection of epoch -2"
     ]
    }
   ],
   "source": [
    "# %% test a specific model\n",
    "from src import ModelTrainer\n",
    "ModelTrainer.fit(stage = 0 , resume = 0 , checkname= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device name: NVIDIA GeForce RTX 4090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-03-31 09:52:11|MOD:data_preprocessing|\u001b[0m: \u001b[1m\u001b[31mif_train is False , Data Processing start!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[45m24-03-31 09:52:11|MOD:data_preprocessing|\u001b[0m: \u001b[1m\u001b[35m3 datas :['y', 'trade_day', 'trade_30m']\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar 31 09:52:11 2024 : y start ...\n",
      "labels blocks reading ret10_lag DataBase's ...... cost 0.39 secs\n",
      "labels blocks reading ret20_lag DataBase's ...... cost 0.33 secs\n",
      "labels blocks merging ...... cost 0.05 secs\n",
      "models blocks reading risk_exp DataBase's ...... cost 1.66 secs\n",
      "models blocks merging ...... cost 0.17 secs\n",
      "y blocks process ...... cost 0.88 secs\n",
      "y blocks masking ...... cost 0.05 secs\n",
      "y blocks saving  ...... cost 0.14 secs\n",
      "y blocks norming ...... cost 0.00 secs\n",
      "Sun Mar 31 09:52:14 2024 : y finished! Cost 3.67 Seconds\n",
      "Sun Mar 31 09:52:14 2024 : trade_day start ...\n",
      "trade blocks reading day DataBase's ...... cost 0.56 secs\n",
      "trade_day blocks merging ...... cost 0.00 secs\n",
      "trade_day blocks process ...... cost 0.03 secs\n",
      "trade_day blocks masking ...... cost 0.05 secs\n",
      "trade_day blocks saving  ...... cost 0.16 secs\n",
      "trade_day blocks norming ...... cost 0.00 secs\n",
      "Sun Mar 31 09:52:15 2024 : trade_day finished! Cost 0.81 Seconds\n",
      "Sun Mar 31 09:52:15 2024 : trade_30m start ...\n",
      "trade blocks reading 30min DataBase's ...... cost 2.51 secs\n",
      "trade_30m blocks merging ...... cost 0.00 secs\n",
      "trade blocks reading day DataBase's ...... cost 0.53 secs\n",
      "trade_day blocks merging ...... cost 0.02 secs\n",
      "trade_30m blocks process ...... cost 0.95 secs\n",
      "trade_30m blocks masking ...... cost 0.05 secs\n",
      "trade_30m blocks saving  ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-03-31 09:52:21|MOD:data_preprocessing|\u001b[0m: \u001b[1m\u001b[31mData Processing Finished! Cost 10.02 Seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... cost 1.13 secs\n",
      "trade_30m blocks norming ...... cost 0.00 secs\n",
      "Sun Mar 31 09:52:21 2024 : trade_30m finished! Cost 5.19 Seconds\n"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "from src import DataModule\n",
    "DataModule.prepare_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
