{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device name: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import time , argparse\n",
    "import scripts.util as U\n",
    "from datetime import datetime , timedelta\n",
    "from dataclasses import dataclass , field\n",
    "\n",
    "from scripts.util.basic import Timer\n",
    "from scripts.util.logger import get_logger\n",
    "from scripts.environ import DIR_data\n",
    "from scripts.util.data.ModelData import (\n",
    "    block_load_DB , block_process , block_mask , path_block_data , block_hist_norm , path_norm_data)\n",
    " \n",
    "logger = get_logger()\n",
    "\n",
    "DIR_block     = f'{DIR_data}/block_data'\n",
    "DIR_hist_norm = f'{DIR_data}/hist_norm'\n",
    "\n",
    "\n",
    "def today(offset = 0):\n",
    "    d = datetime.today() + timedelta(days=offset)\n",
    "    return int(d.strftime('%Y%m%d'))\n",
    "\n",
    "@dataclass\n",
    "class DataProcessConfig:\n",
    "    load_start_dt : int | None\n",
    "    load_end_dt   : int | None\n",
    "    save_start_dt : int | None\n",
    "    save_end_dt   : int | None\n",
    "    hist_start_dt : int | None\n",
    "    hist_end_dt   : int | None\n",
    "    mask : dict = field(default_factory=dict)\n",
    "    data : dict = field(default_factory=dict)\n",
    "\n",
    "Configs = DataProcessConfig(\n",
    "    load_start_dt = None ,\n",
    "    load_end_dt   = None ,\n",
    "    save_start_dt = 20070101 ,\n",
    "    save_end_dt   = None ,\n",
    "    hist_start_dt = None ,\n",
    "    hist_end_dt   = 20161231 ,  \n",
    "    mask          = {'list_dt':True}\n",
    ")\n",
    "Configs.data['y'] = {\n",
    "    'DB_source'  : {\n",
    "        'labels': {'inner_path' : ['10days/lag1' , '20days/lag1']} ,\n",
    "        'models': {'inner_path' : 'risk_model/exposure'} ,\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-03-24 16:46:30|MOD:1840015316  |\u001b[0m: \u001b[1m\u001b[31mData Processing start!\u001b[0m\n",
      "\u001b[1m\u001b[37m\u001b[45m24-03-24 16:46:30|MOD:1840015316  |\u001b[0m: \u001b[1m\u001b[35m1 datas :['y']\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar 24 16:46:30 2024 : y start ...\n",
      "labels blocks reading 10days/lag1 Data1D's ...... cost 0.18 secs\n",
      "labels blocks reading 20days/lag1 Data1D's ...... cost 0.15 secs\n",
      "labels blocks merging ...... cost 0.05 secs\n",
      "models blocks reading risk_model/exposure Data1D's ...... cost 1.17 secs\n",
      "models blocks merging ...... cost 0.00 secs\n",
      "2 blocks aligning ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m24-03-24 16:46:32|MOD:1840015316  |\u001b[0m: \u001b[1m\u001b[31mData Processing Finished! Cost 2.04 Seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... cost 0.39 secs\n",
      "Sun Mar 24 16:46:31 2024 : y finished! Cost 1.94 Seconds\n"
     ]
    }
   ],
   "source": [
    "if_train = False\n",
    "\n",
    "t1 = time.time()\n",
    "logger.critical('Data Processing start!')\n",
    "logger.error(f'{len(Configs.data)} datas :' + str(list(Configs.data.keys())))\n",
    "\n",
    "for key , param in Configs.data.items():\n",
    "    tt1 = time.time()\n",
    "    print(f'{time.ctime()} : {key} start ...')\n",
    "    \n",
    "    BlockDict = block_load_DB(\n",
    "        param['DB_source'] , \n",
    "        start_dt = Configs.load_start_dt if if_train else today(-181), \n",
    "        end_dt   = Configs.load_end_dt   if if_train else None)\n",
    "\n",
    "    '''\n",
    "    \n",
    "\n",
    "    with Timer(f'{key} blocks process'):\n",
    "        ThisBlock = block_process(BlockDict , key)\n",
    "\n",
    "    with Timer(f'{key} blocks masking'):   \n",
    "        ThisBlock = block_mask(\n",
    "            ThisBlock , \n",
    "            mask = Configs.mask)\n",
    "\n",
    "    with Timer(f'{key} blocks saving '):\n",
    "    ThisBlock.save(\n",
    "        path_block_data(key , if_train) , \n",
    "        start_dt = Configs.save_start_dt if if_train else None , \n",
    "        end_dt   = Configs.save_end_dt   if if_train else None)\n",
    "\n",
    "    '''\n",
    "\n",
    "    tt2 = time.time()\n",
    "    print(f'{time.ctime()} : {key} finished! Cost {tt2-tt1:.2f} Seconds')\n",
    "\n",
    "    #del ThisBlock\n",
    "    gc.collect()\n",
    "\n",
    "t2 = time.time()\n",
    "logger.critical('Data Processing Finished! Cost {:.2f} Seconds'.format(t2-t1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5112, 101, 1, 4), (5112, 101, 1, 48))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BlockDict['labels'].shape , BlockDict['models'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.function.primas import neutralize_2d , process_factor\n",
    "import torch\n",
    "\n",
    "x = torch.FloatTensor(BlockDict['models'].values[...,:BlockDict['models'].feature.tolist().index('size')+1]).permute(1,0,2,3).squeeze(2)\n",
    "for i_feat,lb_name in enumerate(BlockDict['labels'].feature):\n",
    "    if lb_name[:3] == 'rtn':\n",
    "        y_raw = torch.FloatTensor(BlockDict['labels'].values[...,i_feat]).permute(1,0,2).squeeze(2)\n",
    "        y_std = neutralize_2d(y_raw , x).permute(1,0).unsqueeze(2)\n",
    "        BlockDict['labels'].add_feature('std'+lb_name[3:],y_std)\n",
    "\n",
    "y_ts = torch.FloatTensor(BlockDict['labels'].values)[:,:,0]\n",
    "for i_feat,lb_name in enumerate(BlockDict['labels'].feature):\n",
    "    y_pro = process_factor(y_ts[...,i_feat], dim = 0)\n",
    "    if not isinstance(y_pro , torch.Tensor): continue\n",
    "    y_pro = y_pro.unsqueeze(-1).numpy()\n",
    "    BlockDict['labels'].values[...,i_feat] = y_pro"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
