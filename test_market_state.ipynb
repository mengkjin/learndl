{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py , time , traceback\n",
    "from scripts.data_utils.ModelData import save_block_data\n",
    "from scripts.data_utils.DataTank import DataTank\n",
    "from scripts.util.environ import get_logger,DEVICE,DIR_data\n",
    "from scripts.functional.func import *\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "logger = get_logger()\n",
    "path_port  = f'{DIR_data}/fund_stock_port.h5'\n",
    "path_trade = f'{DIR_data}/DB_trade_day.h5'\n",
    "path_info  = f'{DIR_data}/DB_information.h5'\n",
    "\n",
    "class matrix_factorization():\n",
    "    def __init__(self , m , learn_rates = [0.1,0.05,0.01,0.005,0.001]):\n",
    "        self.mat = m.to(DEVICE)\n",
    "        self.nrow = m.shape[0]\n",
    "        self.ncol = m.shape[1]\n",
    "        self.learn_rates = learn_rates\n",
    "    \n",
    "    def proceed(self , nfeat , ltheta = 0.01 , num_epochs = 200 , print_process = False):\n",
    "        self.mod = []\n",
    "        self.losses = []\n",
    "        for learn_rate in self.learn_rates:\n",
    "            mod = self.factor_module((self.nrow , self.ncol , nfeat)).to(DEVICE)\n",
    "            criterion = nn.MSELoss(reduction = 'sum')\n",
    "            optimizer = torch.optim.Adam(mod.parameters(), lr = learn_rate)\n",
    "\n",
    "            losses = []  \n",
    "            for epoch in range(num_epochs):\n",
    "                output , theta = mod()\n",
    "                loss = criterion(output, self.mat) + ltheta * theta\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                losses.append(loss.item())\n",
    "\n",
    "                # if (epoch) % 10 == 0: print('Epoch [{}/{}], Loss: {:.8f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "            \n",
    "            if print_process : print('Learn rate {:.5f}, Epoch [{}/{}], Loss: {:.8f}'.format(learn_rate, epoch+1, num_epochs, loss.item()))\n",
    "            self.mod.append(mod)\n",
    "            self.losses.append(losses)\n",
    "        \n",
    "        best_mod = np.argmin([l[-1] for l in self.losses])\n",
    "        if print_process:\n",
    "            plt.plot(range(num_epochs), self.losses[best_mod])\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title(f'Training Loss , Learn Rate: {self.learn_rates[best_mod]}')\n",
    "            plt.show()\n",
    "\n",
    "        self.Q = torch.cat((self.mod[best_mod].Q_bias.reshape(-1,1) , self.mod[best_mod].Q_weight) , dim = 1).detach().cpu().numpy()\n",
    "        self.m_pred = output\n",
    "        self.theta = theta\n",
    "    \n",
    "    class factor_module(nn.Module):\n",
    "        def __init__(self , ndim):\n",
    "            super().__init__()\n",
    "            self.nf , self.ns , self.nd = ndim\n",
    "            \"\"\"\n",
    "            P_weight = torch.rand(self.nf , self.nd - 1) / np.sqrt(self.nf)\n",
    "            P_bias   = torch.zeros(self.nf)\n",
    "            Q_weight = torch.rand(self.ns , self.nd - 1) / np.sqrt(self.ns)\n",
    "            Q_bias   = torch.zeros(self.ns)\n",
    "            bias0    = torch.zeros(1)\n",
    "\n",
    "            self.P_weight = torch.nn.Parameter(P_weight)\n",
    "            self.P_bias   = torch.nn.Parameter(P_bias)\n",
    "            self.Q_weight = torch.nn.Parameter(Q_weight)\n",
    "            self.Q_bias   = torch.nn.Parameter(Q_bias)\n",
    "            self.bias0    = torch.nn.Parameter(bias0)\n",
    "            \"\"\"\n",
    "            self.P_weight = torch.nn.Parameter(torch.rand(self.nf , self.nd - 1) / np.sqrt(self.nf))\n",
    "            self.P_bias   = torch.nn.Parameter(torch.zeros(self.nf))\n",
    "            self.Q_weight = torch.nn.Parameter(torch.rand(self.ns , self.nd - 1) / np.sqrt(self.ns))\n",
    "            self.Q_bias   = torch.nn.Parameter(torch.zeros(self.ns))\n",
    "            self.bias0    = torch.nn.Parameter(torch.zeros(1))\n",
    "\n",
    "        def forward(self):\n",
    "            # (bat_size, seq, features)\n",
    "            output = torch.matmul(self.P_weight , self.Q_weight.T) + self.Q_bias + self.P_bias.repeat_interleave(self.ns).reshape(-1,self.ns) + self.bias0\n",
    "            theta  = sum([p.square().sum() for p in [self.P_weight , self.P_bias , self.Q_weight , self.Q_bias]])\n",
    "            return output , theta\n",
    "        \n",
    "class fund_stock():\n",
    "    def __init__(self , nfeat = 32 , print_process = False , default_fund_id = None , default_secid = None , \n",
    "                 start_dt = None , end_dt = None):\n",
    "        self.port_file = path_port\n",
    "        with h5py.File(self.port_file , mode='r') as file:\n",
    "            self.port_date = np.array(list(file.keys())).astype(int)\n",
    "        if start_dt is not None: self.port_date = self.port_date[self.port_date >= start_dt]\n",
    "        if end_dt   is not None: self.port_date = self.port_date[self.port_date <= end_dt]\n",
    "        self.fund_id = default_fund_id\n",
    "        self.secid = default_secid\n",
    "        self.nfeat = nfeat\n",
    "        self.print_process = print_process\n",
    "\n",
    "    def load_port(self , date):\n",
    "        with h5py.File(self.port_file , mode='r') as file:\n",
    "            tb = pd.DataFrame(file[str(date)][:])\n",
    "\n",
    "        tb.columns = ['fund_id','secid','weight']\n",
    "        tb.fund_id = [self._IDconvert(s) for s in tb.fund_id]\n",
    "        tb.secid   = [self._IDconvert(s) for s in tb.secid]\n",
    "        return tb\n",
    "        \n",
    "    def calculate_factors(self , date):\n",
    "        tb = self.load_port(date)\n",
    "        if self.fund_id is None:\n",
    "            target_fund_id = sorted(tb.fund_id[tb.fund_id > 0].unique())  \n",
    "        else:\n",
    "            target_fund_id = np.array(self.fund_id)\n",
    "\n",
    "        if self.secid is None:\n",
    "            target_secid = sorted(tb.secid[tb.secid > 0].unique())\n",
    "            self.secid = target_secid\n",
    "        else:\n",
    "            target_secid = np.array(self.secid)\n",
    "        \n",
    "        tb = tb[tb.fund_id.isin(target_fund_id) & tb.secid.isin(target_secid)]\n",
    "        tb = pd.concat([pd.DataFrame({'fund_id':target_fund_id,'secid':target_secid[0],'weight':0.,}) ,\n",
    "                        pd.DataFrame({'fund_id':target_fund_id[0],'secid':target_secid,'weight':0.,}) , \n",
    "                        tb, ])\n",
    "        self.wide_table = tb.pivot_table('weight','fund_id','secid',aggfunc='sum',fill_value=0.\n",
    "                                         ).loc[target_fund_id,target_secid]\n",
    "        assert np.array_equal(self.wide_table.columns.tolist() , target_secid)\n",
    "        assert np.array_equal(self.wide_table.index.tolist() , target_fund_id)\n",
    "        self.factorize(self.nfeat , self.print_process)\n",
    "        \n",
    "    def factorize(self , nfeat = 32 , print_process = False):\n",
    "        mf = matrix_factorization(torch.tensor(self.wide_table.values , dtype = torch.float , requires_grad = False))\n",
    "        mf.proceed(nfeat = nfeat , print_process = print_process)\n",
    "        self.Factor = mf\n",
    "        self.Q = self.Factor.Q\n",
    "        \n",
    "    def _IDconvert(self , x):\n",
    "        try:\n",
    "            return int(x.decode('utf-8').split('.')[0].split('!')[0])\n",
    "        except ValueError:\n",
    "            return -1\n",
    "        \n",
    "class dynamic_market_state():\n",
    "    def __init__(self , start_dt = None , end_dt = None):\n",
    "        self.start_dt = 20140430 if start_dt is None else start_dt\n",
    "        self.end_dt   = 99991231 if end_dt   is None else end_dt\n",
    "        \n",
    "        self.port_factors = None\n",
    "        self.port_date = None\n",
    "        \n",
    "        self.StateSimilarity = None\n",
    "\n",
    "        self.load_day_yield()\n",
    "        self.update_top_sec()\n",
    "        \n",
    "    def load_day_yield(self , ipo_lag = 31):\n",
    "        __start_time__ = time.time()\n",
    "        dtank_info = DataTank(path_info , open = True , mode = 'r')\n",
    "        dtank_trade = DataTank(path_trade , open = True , mode = 'r')\n",
    "        try:\n",
    "            self.calendar   = dtank_info.read_dataframe('/basic/calendar')\n",
    "            self.stock_info = dtank_info.read_dataframe('/stock/description')\n",
    "\n",
    "            trade_calendar = self.calendar.loc[lambda x:(x.trade > 0)].calendar.to_numpy()\n",
    "            trade_calendar = trade_calendar[(trade_calendar >= self.start_dt) * (trade_calendar <= self.end_dt) > 0]\n",
    "\n",
    "            valid_date = np.array(list(dtank_trade.get_object('/day/trade').keys())).astype(int)\n",
    "            valid_date = np.intersect1d(valid_date , trade_calendar)\n",
    "            df_list = {str(date):dtank_trade.read_data1D(f'/day/trade/{date}',feature='pctchange'\n",
    "                                            ).to_dataframe().reset_index() for date in valid_date}\n",
    "            for date , df in df_list.items(): df.insert(0,'date',int(date))\n",
    "            df = pd.concat(df_list.values())\n",
    "            df['pctchange'] = df['pctchange'] / 100\n",
    "            df = df.pivot_table('pctchange','secid','date')\n",
    "            self.secid , self.trade_date = df.index.values.astype(int) , df.columns.values\n",
    "            self.stock_info = pd.concat([self.stock_info , \n",
    "                                         pd.DataFrame({'secid':np.setdiff1d(self.secid , self.stock_info.secid)})])\n",
    "\n",
    "            self.day_yield = df.values\n",
    "            list_dt = self.stock_info.set_index('secid').loc[self.secid,'list_dt'].fillna(21991231).astype(int).astype(str)\n",
    "            valid_date_func = lambda x:datetime.strftime(datetime.strptime(x,'%Y%m%d')+timedelta(days = ipo_lag),'%Y%m%d')\n",
    "            entry_pos = [(self.trade_date < d).sum() for d in np.vectorize(valid_date_func)(list_dt).astype(int)]\n",
    "            for i in range(len(self.secid)): self.day_yield[i,:entry_pos[i]] = np.nan\n",
    "            \n",
    "            assert self.day_yield.shape[:2] == (len(self.secid) , len(self.trade_date))\n",
    "            print(f'loading: {time.time() - __start_time__:.2f} secs')\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "        finally:\n",
    "            dtank_info.close() , dtank_trade.close()\n",
    "    \n",
    "    def update_top_sec(self , func = None):\n",
    "        self.top_sec = self._default_top_sec if func is None else func\n",
    "            \n",
    "    def _default_top_sec(self , x):\n",
    "        # return lambda x:(-x).argpartition((~np.isnan(x)).sum()//100)[:(~np.isnan(x)).sum()//100]\n",
    "        ns = max((~np.isnan(x)).sum()//100 , 10)\n",
    "        return (-x).argpartition(ns)[:ns]\n",
    "        \n",
    "    def update_factors(self , secid , port_date , port_factors):\n",
    "        if not isinstance(port_date,(list,tuple,np.ndarray)): port_date = [port_date]\n",
    "        secid , port_date = np.array(secid) , np.array(port_date)\n",
    "        assert port_factors.shape[:2] == (len(secid) , len(port_date))\n",
    "        _ , int_i0 , int_i1 = np.intersect1d(self.secid , secid , assume_unique=True , return_indices = True)\n",
    "        \n",
    "        new_port_date = port_date\n",
    "        new_port_factors = np.tile(np.nan , (len(self.secid) , *port_factors.shape[1:]))\n",
    "        new_port_factors[int_i0] = port_factors[int_i1]\n",
    "        \n",
    "        if (self.port_date is not None):\n",
    "            old_port_date = self.port_date[np.isin(self.port_date , port_date)]\n",
    "            old_port_factors = self.port_factors[:,np.isin(self.port_date , port_date)]\n",
    "            \n",
    "            new_port_date = np.append(old_port_date , new_port_date)\n",
    "            new_port_factors = np.concatenate((old_port_factors , new_port_factors) , axis=1)\n",
    "            \n",
    "        self.port_factors = new_port_factors[:,np.argsort(new_port_date)]\n",
    "        self.port_date = new_port_date[np.argsort(new_port_date)]\n",
    "        assert self.port_factors.shape[1] == len(self.port_date)\n",
    "    \n",
    "    def calculate_market_state(self , start_dt = None , end_dt = None):\n",
    "        date_range = self.trade_date\n",
    "        if start_dt is not None: date_range = date_range[date_range >= start_dt]\n",
    "        if end_dt   is not None: date_range = date_range[date_range <= end_dt]\n",
    "        \n",
    "        self.market_top_state = np.tile(np.nan , (len(date_range) , *self.port_factors.shape[2:]))\n",
    "        self.top_similarity = np.tile(np.nan , (len(self.secid) , len(date_range)))\n",
    "        for i , d in enumerate(date_range):\n",
    "            j1 , j2 = np.where(self.trade_date == d)[0] , np.where(self.port_date <= d)[0]\n",
    "            if len(j1) * len(j2) != 0:\n",
    "                top_sec = self.top_sec(self.day_yield[:,j1].flatten())\n",
    "                self.market_top_state[i] = np.nanmean(self.port_factors[top_sec][:,j2.max()],axis=0)\n",
    "                self.top_similarity[:,i] = (self.market_top_state[i] * self.port_factors[:,j2.max()]).sum(axis=1)\n",
    "        self.state_date = date_range\n",
    "\n",
    "def main(start_dt = None , end_dt = None):\n",
    "    t1 = time.time()\n",
    "    logger.critical('top_similarity Factor Calculating start!')\n",
    "\n",
    "    # DynamicStateSimilarity : top_similarity\n",
    "    fs  = fund_stock(nfeat = 32 , print_process = False , start_dt = start_dt , end_dt = end_dt)\n",
    "    start_dt = fs.port_date[0] if start_dt is None else max(fs.port_date[0] , start_dt)\n",
    "    dms = dynamic_market_state(start_dt=start_dt , end_dt = end_dt)\n",
    "    for port_date in fs.port_date:\n",
    "        fs.calculate_factors(port_date)\n",
    "        dms.update_factors(fs.secid , port_date , np.expand_dims(fs.Q,1))\n",
    "        print(f'{port_date} factor update done!')\n",
    "    dms.calculate_market_state(start_dt=start_dt , end_dt = end_dt)\n",
    "    save_path = f'{DIR_data}/block_data/X_top_similarity.npz'\n",
    "    values = dms.top_similarity if len(dms.top_similarity.shape) == 3 else dms.top_similarity[:,:,None]\n",
    "    index = {'secid':dms.secid,'date':dms.state_date,'feature':'top_similarity'}\n",
    "    save_block_data(save_path,values,index)\n",
    "    \n",
    "    t2 = time.time()\n",
    "    logger.critical('top_similarity Factor Calculating Finished! Cost {:.2f} Seconds'.format(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m\u001b[41m23-12-17 18:14:53|MOD:1296140737  |\u001b[0m: \u001b[1m\u001b[31mtop_similarity Factor Calculating start!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading: 10.16 secs\n",
      "20140430 factor update done!\n",
      "20140829 factor update done!\n",
      "20150430 factor update done!\n",
      "20150831 factor update done!\n",
      "20160429 factor update done!\n",
      "20160831 factor update done!\n",
      "20170428 factor update done!\n",
      "20170831 factor update done!\n",
      "20180427 factor update done!\n",
      "20180831 factor update done!\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
