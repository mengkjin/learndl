{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import jit , cuda\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from recreate import *\n",
    "\n",
    "def one_hot(x):\n",
    "    if not isinstance(x , torch.Tensor): x = torch.Tensor(x)\n",
    "    nan_index = x.isnan()\n",
    "    has_nan = nan_index.any()\n",
    "    x_ = torch.where(nan_index , x[~nan_index].max() + 1 , x) if has_nan else x\n",
    "    dummy = torch.nn.functional.one_hot(x_.to(torch.int64)).to(torch.float)\n",
    "    return dummy[...,:-1] if has_nan else dummy\n",
    "gp_params = gp_parameters(True)\n",
    "gp_params['device'] = torch.device(\"cuda\")\n",
    "def Ts(df):\n",
    "    if isinstance(df , torch.Tensor):\n",
    "        if gp_params.get('device') is not None: df = df.to(gp_params.get('device'))\n",
    "        # df.share_memory_() # 执行多进程时使用：将张量移入共享内存\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_indus_code = Ts(read_gp_data('cs_indus_code',gp_params['slice_date'])[0])\n",
    "size = Ts(read_gp_data('size',gp_params['slice_date'])[0])\n",
    "\n",
    "# torch.nn.functional.one_hot(cs_indus_code.to(torch.int64) , ).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _neutralize_yx(y , x_list = [] , x_group = None , no_intercept = True , index = None):\n",
    "    if isinstance(x_list , torch.Tensor): x_list = [x_list]\n",
    "    if len(x_list) == 0 and x_group is None: return y , None\n",
    "    elif x_group is None:\n",
    "        x = torch.stack(x_list,dim = -1)\n",
    "    elif len(x_list) == 0:\n",
    "        x = one_hot(x_group)[...,:-1]\n",
    "    else:\n",
    "        x = torch.stack(x_list,dim = -1)\n",
    "        x = torch.cat([x,one_hot(x_group)[...,:-1]],dim=-1)\n",
    "    if no_intercept: x = torch.nn.functional.pad(x , (1,0) , value = 1.)\n",
    "    y = y.unsqueeze(-1)\n",
    "    if index: y , x = y[index] , x[index]\n",
    "    return y , x\n",
    "\n",
    "a = _neutralize_yx(size,size,cs_indus_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0].shape , a[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_indus_code[~cs_indus_code.isnan()].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_indus_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y , x_list  , x_group = size,size,cs_indus_code \n",
    "no_intercept = True \n",
    "index = None\n",
    "if isinstance(x_list , torch.Tensor): x_list = [x_list]\n",
    "if len(x_list) == 0 and x_group is None: \n",
    "    print(y , None) \n",
    "elif x_group is None:\n",
    "    x = torch.stack(x_list,dim = -1)\n",
    "elif len(x_list) == 0:\n",
    "    x = one_hot(x_group)[...,:-1]\n",
    "else:\n",
    "    x0 = torch.stack(x_list,dim = -1)\n",
    "    x1 = one_hot(x_group)[...,:-1]\n",
    "    print(x0.shape , x1.shape)\n",
    "    x = torch.cat([x0,x1],dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
