{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gp_math_func as MF\n",
    "import gp_factor_func as FF\n",
    "n_time = 200\n",
    "n_stock = 100\n",
    "n_factor = 10\n",
    "x = torch.rand(n_time , n_stock , n_factor)\n",
    "y = torch.rand(n_time , n_stock , 1)\n",
    "nan = (y > 0.9) + (y < 0.1)\n",
    "y[nan] = torch.nan\n",
    "# mat = a.T.mm(a)\n",
    "\n",
    "gp_factor = x\n",
    "labels = y\n",
    "universe = ~nan.all(-1)\n",
    "insample = torch.arange(n_time) <160\n",
    "ir_window = 10\n",
    "roll_window = 10\n",
    "halflife  = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.1213,  0.1548,  0.0121,  ..., -0.1517,  0.0401,  0.1213]],\n",
       " \n",
       "         [[ 0.1111,  0.1502,  0.0764,  ..., -0.1110,  0.0440,  0.1088]],\n",
       " \n",
       "         [[ 0.1029,  0.1398,  0.0812,  ..., -0.0784,  0.0374,  0.1011]]]),\n",
       " tensor([[    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         ...,\n",
       "         [ 0.1011, -0.0541, -0.0419,  ...,  0.0592, -0.0906,  0.0121],\n",
       "         [ 0.0549, -0.0317,  0.1113,  ...,  0.0283, -0.0458, -0.1149],\n",
       "         [-0.0988, -0.1708, -0.1378,  ...,  0.1534, -0.0181,  0.0223]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_scheme = 'ir' # 'ic' , 'ir'\n",
    "window_type   = 'rolling' # 'rolling'\n",
    "weight_decay  = 'exp' # 'constant' , 'linear'\n",
    "\n",
    "class MultiFactor:\n",
    "    def __init__(self , weight_scheme = 'ir', window_type = 'rolling', weight_decay= 'exp' , \n",
    "                 ir_window = 10 , roll_window = 10 , halflife  = 5 , \n",
    "                 insample = None , universe = None , min_coverage = 0.1) -> None:\n",
    "        assert weight_scheme in ['ew' , 'ic' , 'ir']\n",
    "        assert window_type   in ['rolling' , 'insample']\n",
    "        assert weight_decay  in ['constant' , 'linear' , 'exp']\n",
    "        self.weight_scheme = weight_scheme\n",
    "        self.window_type   = window_type\n",
    "        self.weight_decay  = weight_decay\n",
    "        self.ir_window     = ir_window\n",
    "        self.roll_window   = roll_window\n",
    "        self.halflife      = halflife\n",
    "        self.insample      = insample\n",
    "        self.universe      = universe\n",
    "        self.min_coverage  = min_coverage\n",
    "\n",
    "    def ts_decay(self , max_len , weight_decay = None , halflife = None):\n",
    "        weight_decay = weight_decay if weight_decay else self.weight_decay\n",
    "        halflife     = halflife     if halflife     else self.halflife\n",
    "        return FF.decay_weight(weight_decay , max_len , exp_halflife=halflife)\n",
    "\n",
    "    @staticmethod\n",
    "    def static_decorator(func , relative_weight_cap = 5.):\n",
    "        def wrapper(data , time_slice = None):\n",
    "            if time_slice is not None:\n",
    "                if data is not None: data = data[time_slice]\n",
    "            w = func(data).nan_to_num(torch.nan,torch.nan,torch.nan).reshape(1,1,-1)\n",
    "            w /= w.abs().sum(-1,keepdim=True)\n",
    "            w[w > (relative_weight_cap / w.shape[-1])] = relative_weight_cap / w.shape[-1]\n",
    "            w /= w.abs().sum(-1,keepdim=True)\n",
    "            return w\n",
    "        return wrapper\n",
    "    \n",
    "    @staticmethod\n",
    "    def dynamic_decorator(func , relative_weight_cap = 5. , method = 0):\n",
    "        def wrapper(data , roll_window = 10):\n",
    "            if method == 1:\n",
    "                data = torch.nn.functional.pad(data,[0,0,roll_window-1,0],value=torch.nan).unfold(0,roll_window,1).permute(2,0,1)\n",
    "                w = func(data).nan_to_num(torch.nan,torch.nan,torch.nan).permute(1,0,2)\n",
    "            else:\n",
    "                w = data * 0.\n",
    "                for i in range(len(w)):\n",
    "                    w[i] = func(data[i-roll_window:i]).nan_to_num(torch.nan,torch.nan,torch.nan)\n",
    "                w = w.unsqueeze(1)\n",
    "            w /= w.abs().sum(-1,keepdim=True)\n",
    "            w[w > (relative_weight_cap / w.shape[-1])] = relative_weight_cap / w.shape[-1]\n",
    "            w /= w.abs().sum(-1,keepdim=True)\n",
    "            return w\n",
    "        return wrapper\n",
    "    \n",
    "    def multi_factor_weight(self , window_type = None , **kwargs):\n",
    "        window_type = window_type if window_type is not None else self.window_type\n",
    "        if window_type == 'insample':\n",
    "            weight_tensor = self.static_factor_weight(**kwargs)\n",
    "        else:\n",
    "            weight_tensor = self.dynamic_factor_weight(**kwargs)\n",
    "        return weight_tensor\n",
    "\n",
    "    def static_factor_weight(self , weight_scheme = None , weight_decay = None , insample = None , **kwargs):\n",
    "        weight_scheme = weight_scheme  if weight_scheme is not None else self.weight_scheme\n",
    "        weight_decay  = weight_decay   if weight_decay  is not None else self.weight_decay\n",
    "        insample      = insample       if insample      is not None else self.insample\n",
    "        assert weight_scheme in ['ew' , 'ic' , 'ir']\n",
    "        assert weight_decay  in ['constant' , 'linear' , 'exp']\n",
    "\n",
    "        if weight_scheme == 'ew': \n",
    "            func = self.weight_ew\n",
    "            data = kwargs['ic'] if 'ic' in kwargs.keys() else kwargs['ir']\n",
    "        else:\n",
    "            func = self.weight_icir\n",
    "            data = kwargs[weight_scheme]\n",
    "        func = self.static_decorator(func)\n",
    "        return func(data , time_slice = insample)\n",
    "    \n",
    "    def dynamic_factor_weight(self , weight_scheme = None , weight_decay = None , roll_window = None , **kwargs):\n",
    "        weight_scheme = weight_scheme  if weight_scheme is not None else self.weight_scheme\n",
    "        weight_decay  = weight_decay   if weight_decay  is not None else self.weight_decay\n",
    "        roll_window   = roll_window    if roll_window   is not None else self.roll_window\n",
    "        assert weight_scheme in ['ew' , 'ic' , 'ir']\n",
    "        assert weight_decay  in ['constant' , 'linear' , 'exp']\n",
    "\n",
    "        if weight_scheme == 'ew': \n",
    "            return self.static_factor_weight(weight_scheme , time_slice = self.insample, **kwargs)\n",
    "        else:\n",
    "            func = self.dynamic_decorator(self.weight_icir)\n",
    "            return func(kwargs[weight_scheme] , roll_window = roll_window)\n",
    "\n",
    "    def weight_ew(self , data):\n",
    "        return data.nanmean(0).sign()\n",
    "\n",
    "    def weight_icir(self, data):\n",
    "        ts_w = self.ts_decay(len(data)).reshape(1,-1)\n",
    "        fini = data.isfinite() * 1.\n",
    "        data = data.nan_to_num(0,0,0)\n",
    "        if data.dim() == 2:\n",
    "            return (ts_w @ data) / (ts_w @ fini)\n",
    "        elif data.dim() == 3:\n",
    "            return torch.einsum('ij,jkl->ikl' , ts_w , data) / torch.einsum('ij,jkl->ikl' , ts_w , fini)\n",
    "\n",
    "    def weighted_multi(self , singles , weight):\n",
    "        assert singles.shape == weight.shapes\n",
    "        weight = singles.isfinite() * weight\n",
    "        wsum = torch.nansum(singles * weight , dim = -1) \n",
    "        return MF.zscore_inplace(wsum,-1)\n",
    "    \n",
    "    def calculate_icir(self , factors , labels , ir_window = None , universe = None , min_coverage = None , **kwargs):\n",
    "        ir_window    = ir_window    if ir_window    is not None else self.ir_window\n",
    "        universe     = universe     if universe     is not None else self.universe\n",
    "        min_coverage = min_coverage if min_coverage is not None else self.min_coverage\n",
    "        if labels.dim() == factors.dim():\n",
    "            labels = labels.squeeze(-1)\n",
    "        rankic = torch.full((len(factors) , factors.shape[-1]) , fill_value=torch.nan).to(labels)\n",
    "        for i_factor in range(factors.shape[-1]):\n",
    "            rankic[:,i_factor] = MF.rankic_2d(factors[...,i_factor] , labels , dim = 1 , \n",
    "                                              universe = universe , min_coverage = min_coverage)\n",
    "        rankir = MF.ma(rankic , ir_window) / MF.ts_stddev(rankic , ir_window)\n",
    "        return rankic , rankir\n",
    "\n",
    "mfs = MultiFactor(weight_scheme = weight_scheme, window_type = window_type, weight_decay= weight_decay ,\n",
    "                  universe = universe , insample = insample ,\n",
    "                  ir_window = ir_window , roll_window = roll_window , halflife = halflife)\n",
    "#gp_factor , labels , universe , insample             \n",
    "rankic , rankir = mfs.calculate_icir(gp_factor , labels , universe = universe)\n",
    "\n",
    "weight_tensor = mfs.multi_factor_weight(ic=rankic , ir=rankir , \n",
    "                                        weight_scheme = weight_scheme, window_type = window_type, weight_decay= weight_decay ,\n",
    "                                        ir_window = ir_window , roll_window = roll_window , halflife  = halflife , \n",
    "                                        insample = insample , universe = universe)\n",
    "\n",
    "multi = (gp_factor * weight_tensor).nanmean(-1)\n",
    "multi = MF.zscore(multi , -1)\n",
    "weight_tensor , multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Job Directory is : \"./pop/bendi\"\n",
      "-------------------- Data --------------------\n",
      "  --> Directly load \"./data/package/gp_data_package_test.pt\"\n",
      "**Load Data Done, Cost 0.03 Secs\n",
      "  --> 2 factors, 2 raw data loaded!\n"
     ]
    }
   ],
   "source": [
    "# 给定因子表达式,得到全样本区间的因子值\n",
    "import torch\n",
    "from gp_main import gp_factor_generator\n",
    "import gp_factor_func as FF\n",
    "\n",
    "gp_space = gp_factor_generator(job_id = 'bendi')\n",
    "\n",
    "a = gp_space.compile('ts_rng_dif(CP,10,1)' , 'inf')\n",
    "b = gp_space.compile('ts_rank(turn,10)' , 'inf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "        ...,\n",
       "        [-0.0033, -0.0188,  0.0001,  ...,  0.0016, -0.0011,  0.0013],\n",
       "        [-0.0102, -0.0191,  0.0004,  ...,  0.0016, -0.0009,  0.0013],\n",
       "        [-0.0108, -0.0155,  0.0003,  ...,  0.0017, -0.0008,  0.0013]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 基于多个单因子,计算多因子\n",
    "multi_factor = FF.MultiFactor(\n",
    "    weight_scheme = 'ir', window_type = 'rolling', weight_decay= 'exp' ,\n",
    "    universe = gp_space.tensors.universe , insample = gp_space.tensors.insample ,\n",
    "    ir_window = 40 , roll_window = 40 , halflife = 20)\n",
    "\n",
    "factor = torch.stack([a,b] , dim = -1)\n",
    "labels = gp_space.tensors.labels_raw\n",
    "\n",
    "metrics = multi_factor.calculate_icir(factor , labels , universe = gp_space.tensors.universe) # namespace of ic,ir\n",
    "multi = multi_factor.multi_factor(factor , window_type='rolling',**metrics)\n",
    "multi.get('multi') # multi对象拥有multi,weight,inputs三个自变量,用multi.multi也行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([484, 5210, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi.inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multi': tensor([[    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         ...,\n",
       "         [-0.0033, -0.0188,  0.0001,  ...,  0.0016, -0.0011,  0.0013],\n",
       "         [-0.0102, -0.0191,  0.0004,  ...,  0.0016, -0.0009,  0.0013],\n",
       "         [-0.0108, -0.0155,  0.0003,  ...,  0.0017, -0.0008,  0.0013]]),\n",
       " 'weight': tensor([[[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan]],\n",
       " \n",
       "         [[-0.7659, -0.2341]],\n",
       " \n",
       "         [[-0.7579, -0.2421]],\n",
       " \n",
       "         [[-0.7493, -0.2507]],\n",
       " \n",
       "         [[-0.7424, -0.2576]],\n",
       " \n",
       "         [[-0.7386, -0.2614]],\n",
       " \n",
       "         [[-0.7347, -0.2653]],\n",
       " \n",
       "         [[-0.7376, -0.2624]],\n",
       " \n",
       "         [[-0.7397, -0.2603]],\n",
       " \n",
       "         [[-0.7400, -0.2600]],\n",
       " \n",
       "         [[-0.7400, -0.2600]],\n",
       " \n",
       "         [[-0.7409, -0.2591]],\n",
       " \n",
       "         [[-0.7416, -0.2584]],\n",
       " \n",
       "         [[-0.7409, -0.2591]],\n",
       " \n",
       "         [[-0.7372, -0.2628]],\n",
       " \n",
       "         [[-0.7354, -0.2646]],\n",
       " \n",
       "         [[-0.7364, -0.2636]],\n",
       " \n",
       "         [[-0.7331, -0.2669]],\n",
       " \n",
       "         [[-0.7314, -0.2686]],\n",
       " \n",
       "         [[-0.7307, -0.2693]],\n",
       " \n",
       "         [[-0.7325, -0.2675]],\n",
       " \n",
       "         [[-0.7377, -0.2623]],\n",
       " \n",
       "         [[-0.7426, -0.2574]],\n",
       " \n",
       "         [[-0.7482, -0.2518]],\n",
       " \n",
       "         [[-0.7568, -0.2432]],\n",
       " \n",
       "         [[-0.7672, -0.2328]],\n",
       " \n",
       "         [[-0.7758, -0.2242]],\n",
       " \n",
       "         [[-0.7824, -0.2176]],\n",
       " \n",
       "         [[-0.7880, -0.2120]],\n",
       " \n",
       "         [[-0.7933, -0.2067]],\n",
       " \n",
       "         [[-0.7971, -0.2029]],\n",
       " \n",
       "         [[-0.7991, -0.2009]],\n",
       " \n",
       "         [[-0.7979, -0.2021]],\n",
       " \n",
       "         [[-0.7967, -0.2033]],\n",
       " \n",
       "         [[-0.7941, -0.2059]],\n",
       " \n",
       "         [[-0.7919, -0.2081]],\n",
       " \n",
       "         [[-0.7905, -0.2095]],\n",
       " \n",
       "         [[-0.7892, -0.2108]],\n",
       " \n",
       "         [[-0.7874, -0.2126]],\n",
       " \n",
       "         [[-0.7850, -0.2150]],\n",
       " \n",
       "         [[-0.7818, -0.2182]],\n",
       " \n",
       "         [[-0.7780, -0.2220]],\n",
       " \n",
       "         [[-0.7738, -0.2262]],\n",
       " \n",
       "         [[-0.7703, -0.2297]],\n",
       " \n",
       "         [[-0.7670, -0.2330]],\n",
       " \n",
       "         [[-0.7627, -0.2373]],\n",
       " \n",
       "         [[-0.7598, -0.2402]],\n",
       " \n",
       "         [[-0.7521, -0.2479]],\n",
       " \n",
       "         [[-0.7448, -0.2552]],\n",
       " \n",
       "         [[-0.7394, -0.2606]],\n",
       " \n",
       "         [[-0.7361, -0.2639]],\n",
       " \n",
       "         [[-0.7336, -0.2664]],\n",
       " \n",
       "         [[-0.7329, -0.2671]],\n",
       " \n",
       "         [[-0.7335, -0.2665]],\n",
       " \n",
       "         [[-0.7324, -0.2676]],\n",
       " \n",
       "         [[-0.7264, -0.2736]],\n",
       " \n",
       "         [[-0.7138, -0.2862]],\n",
       " \n",
       "         [[-0.6982, -0.3018]],\n",
       " \n",
       "         [[-0.6756, -0.3244]],\n",
       " \n",
       "         [[-0.6457, -0.3543]],\n",
       " \n",
       "         [[-0.6107, -0.3893]],\n",
       " \n",
       "         [[-0.5674, -0.4326]],\n",
       " \n",
       "         [[-0.5128, -0.4872]],\n",
       " \n",
       "         [[-0.4468, -0.5532]],\n",
       " \n",
       "         [[-0.3681, -0.6319]],\n",
       " \n",
       "         [[-0.2846, -0.7154]],\n",
       " \n",
       "         [[-0.2069, -0.7931]],\n",
       " \n",
       "         [[-0.1372, -0.8628]],\n",
       " \n",
       "         [[-0.0772, -0.9228]],\n",
       " \n",
       "         [[-0.0246, -0.9754]],\n",
       " \n",
       "         [[ 0.0202, -0.9798]],\n",
       " \n",
       "         [[ 0.0517, -0.9483]],\n",
       " \n",
       "         [[ 0.0697, -0.9303]],\n",
       " \n",
       "         [[ 0.0740, -0.9260]],\n",
       " \n",
       "         [[ 0.0643, -0.9357]],\n",
       " \n",
       "         [[ 0.0440, -0.9560]],\n",
       " \n",
       "         [[ 0.0123, -0.9877]],\n",
       " \n",
       "         [[-0.0250, -0.9750]],\n",
       " \n",
       "         [[-0.0594, -0.9406]],\n",
       " \n",
       "         [[-0.0938, -0.9062]],\n",
       " \n",
       "         [[-0.1299, -0.8701]],\n",
       " \n",
       "         [[-0.1638, -0.8362]],\n",
       " \n",
       "         [[-0.1931, -0.8069]],\n",
       " \n",
       "         [[-0.2190, -0.7810]],\n",
       " \n",
       "         [[-0.2414, -0.7586]],\n",
       " \n",
       "         [[-0.2600, -0.7400]],\n",
       " \n",
       "         [[-0.2735, -0.7265]],\n",
       " \n",
       "         [[-0.2852, -0.7148]],\n",
       " \n",
       "         [[-0.2959, -0.7041]],\n",
       " \n",
       "         [[-0.3073, -0.6927]],\n",
       " \n",
       "         [[-0.3203, -0.6797]],\n",
       " \n",
       "         [[-0.3341, -0.6659]],\n",
       " \n",
       "         [[-0.3460, -0.6540]],\n",
       " \n",
       "         [[-0.3600, -0.6400]],\n",
       " \n",
       "         [[-0.3770, -0.6230]],\n",
       " \n",
       "         [[-0.3964, -0.6036]],\n",
       " \n",
       "         [[-0.4161, -0.5839]],\n",
       " \n",
       "         [[-0.4366, -0.5634]],\n",
       " \n",
       "         [[-0.4622, -0.5378]],\n",
       " \n",
       "         [[-0.4907, -0.5093]],\n",
       " \n",
       "         [[-0.5170, -0.4830]],\n",
       " \n",
       "         [[-0.5391, -0.4609]],\n",
       " \n",
       "         [[-0.5596, -0.4404]],\n",
       " \n",
       "         [[-0.5799, -0.4201]],\n",
       " \n",
       "         [[-0.5999, -0.4001]],\n",
       " \n",
       "         [[-0.6192, -0.3808]],\n",
       " \n",
       "         [[-0.6364, -0.3636]],\n",
       " \n",
       "         [[-0.6502, -0.3498]],\n",
       " \n",
       "         [[-0.6618, -0.3382]],\n",
       " \n",
       "         [[-0.6723, -0.3277]],\n",
       " \n",
       "         [[-0.6840, -0.3160]],\n",
       " \n",
       "         [[-0.6946, -0.3054]],\n",
       " \n",
       "         [[-0.7044, -0.2956]],\n",
       " \n",
       "         [[-0.7125, -0.2875]],\n",
       " \n",
       "         [[-0.7196, -0.2804]],\n",
       " \n",
       "         [[-0.7280, -0.2720]],\n",
       " \n",
       "         [[-0.7354, -0.2646]],\n",
       " \n",
       "         [[-0.7442, -0.2558]],\n",
       " \n",
       "         [[-0.7548, -0.2452]],\n",
       " \n",
       "         [[-0.7655, -0.2345]],\n",
       " \n",
       "         [[-0.7777, -0.2223]],\n",
       " \n",
       "         [[-0.7908, -0.2092]],\n",
       " \n",
       "         [[-0.8045, -0.1955]],\n",
       " \n",
       "         [[-0.8180, -0.1820]],\n",
       " \n",
       "         [[-0.8306, -0.1694]],\n",
       " \n",
       "         [[-0.8445, -0.1555]],\n",
       " \n",
       "         [[-0.8586, -0.1414]],\n",
       " \n",
       "         [[-0.8720, -0.1280]],\n",
       " \n",
       "         [[-0.8840, -0.1160]],\n",
       " \n",
       "         [[-0.8945, -0.1055]],\n",
       " \n",
       "         [[-0.9023, -0.0977]],\n",
       " \n",
       "         [[-0.9065, -0.0935]],\n",
       " \n",
       "         [[-0.9118, -0.0882]],\n",
       " \n",
       "         [[-0.9170, -0.0830]],\n",
       " \n",
       "         [[-0.9205, -0.0795]],\n",
       " \n",
       "         [[-0.9224, -0.0776]],\n",
       " \n",
       "         [[-0.9245, -0.0755]],\n",
       " \n",
       "         [[-0.9255, -0.0745]],\n",
       " \n",
       "         [[-0.9241, -0.0759]],\n",
       " \n",
       "         [[-0.9214, -0.0786]],\n",
       " \n",
       "         [[-0.9191, -0.0809]],\n",
       " \n",
       "         [[-0.9167, -0.0833]],\n",
       " \n",
       "         [[-0.9153, -0.0847]],\n",
       " \n",
       "         [[-0.9146, -0.0854]],\n",
       " \n",
       "         [[-0.9136, -0.0864]],\n",
       " \n",
       "         [[-0.9135, -0.0865]],\n",
       " \n",
       "         [[-0.9159, -0.0841]],\n",
       " \n",
       "         [[-0.9204, -0.0796]],\n",
       " \n",
       "         [[-0.9228, -0.0772]],\n",
       " \n",
       "         [[-0.9247, -0.0753]],\n",
       " \n",
       "         [[-0.9225, -0.0775]],\n",
       " \n",
       "         [[-0.9193, -0.0807]],\n",
       " \n",
       "         [[-0.9181, -0.0819]],\n",
       " \n",
       "         [[-0.9163, -0.0837]],\n",
       " \n",
       "         [[-0.9144, -0.0856]],\n",
       " \n",
       "         [[-0.9095, -0.0905]],\n",
       " \n",
       "         [[-0.9046, -0.0954]],\n",
       " \n",
       "         [[-0.8986, -0.1014]],\n",
       " \n",
       "         [[-0.8937, -0.1063]],\n",
       " \n",
       "         [[-0.8870, -0.1130]],\n",
       " \n",
       "         [[-0.8774, -0.1226]],\n",
       " \n",
       "         [[-0.8659, -0.1341]],\n",
       " \n",
       "         [[-0.8499, -0.1501]],\n",
       " \n",
       "         [[-0.8318, -0.1682]],\n",
       " \n",
       "         [[-0.8168, -0.1832]],\n",
       " \n",
       "         [[-0.8009, -0.1991]],\n",
       " \n",
       "         [[-0.7856, -0.2144]],\n",
       " \n",
       "         [[-0.7711, -0.2289]],\n",
       " \n",
       "         [[-0.7608, -0.2392]],\n",
       " \n",
       "         [[-0.7566, -0.2434]],\n",
       " \n",
       "         [[-0.7524, -0.2476]],\n",
       " \n",
       "         [[-0.7512, -0.2488]],\n",
       " \n",
       "         [[-0.7483, -0.2517]],\n",
       " \n",
       "         [[-0.7434, -0.2566]],\n",
       " \n",
       "         [[-0.7375, -0.2625]],\n",
       " \n",
       "         [[-0.7328, -0.2672]],\n",
       " \n",
       "         [[-0.7288, -0.2712]],\n",
       " \n",
       "         [[-0.7257, -0.2743]],\n",
       " \n",
       "         [[-0.7210, -0.2790]],\n",
       " \n",
       "         [[-0.7176, -0.2824]],\n",
       " \n",
       "         [[-0.7183, -0.2817]],\n",
       " \n",
       "         [[-0.7195, -0.2805]],\n",
       " \n",
       "         [[-0.7219, -0.2781]],\n",
       " \n",
       "         [[-0.7244, -0.2756]],\n",
       " \n",
       "         [[-0.7288, -0.2712]],\n",
       " \n",
       "         [[-0.7345, -0.2655]],\n",
       " \n",
       "         [[-0.7397, -0.2603]],\n",
       " \n",
       "         [[-0.7437, -0.2563]],\n",
       " \n",
       "         [[-0.7474, -0.2526]],\n",
       " \n",
       "         [[-0.7480, -0.2520]],\n",
       " \n",
       "         [[-0.7479, -0.2521]],\n",
       " \n",
       "         [[-0.7471, -0.2529]],\n",
       " \n",
       "         [[-0.7436, -0.2564]],\n",
       " \n",
       "         [[-0.7413, -0.2587]],\n",
       " \n",
       "         [[-0.7406, -0.2594]],\n",
       " \n",
       "         [[-0.7402, -0.2598]],\n",
       " \n",
       "         [[-0.7404, -0.2596]],\n",
       " \n",
       "         [[-0.7399, -0.2601]],\n",
       " \n",
       "         [[-0.7378, -0.2622]],\n",
       " \n",
       "         [[-0.7380, -0.2620]],\n",
       " \n",
       "         [[-0.7377, -0.2623]],\n",
       " \n",
       "         [[-0.7370, -0.2630]],\n",
       " \n",
       "         [[-0.7358, -0.2642]],\n",
       " \n",
       "         [[-0.7338, -0.2662]],\n",
       " \n",
       "         [[-0.7350, -0.2650]],\n",
       " \n",
       "         [[-0.7391, -0.2609]],\n",
       " \n",
       "         [[-0.7475, -0.2525]],\n",
       " \n",
       "         [[-0.7600, -0.2400]],\n",
       " \n",
       "         [[-0.7716, -0.2284]],\n",
       " \n",
       "         [[-0.7803, -0.2197]],\n",
       " \n",
       "         [[-0.7897, -0.2103]],\n",
       " \n",
       "         [[-0.8012, -0.1988]],\n",
       " \n",
       "         [[-0.8144, -0.1856]],\n",
       " \n",
       "         [[-0.8283, -0.1717]],\n",
       " \n",
       "         [[-0.8440, -0.1560]],\n",
       " \n",
       "         [[-0.8604, -0.1396]],\n",
       " \n",
       "         [[-0.8795, -0.1205]],\n",
       " \n",
       "         [[-0.9053, -0.0947]],\n",
       " \n",
       "         [[-0.9401, -0.0599]],\n",
       " \n",
       "         [[-0.9771, -0.0229]],\n",
       " \n",
       "         [[-0.9857,  0.0143]],\n",
       " \n",
       "         [[-0.9493,  0.0507]],\n",
       " \n",
       "         [[-0.9150,  0.0850]],\n",
       " \n",
       "         [[-0.8816,  0.1184]],\n",
       " \n",
       "         [[-0.8529,  0.1471]],\n",
       " \n",
       "         [[-0.8333,  0.1667]],\n",
       " \n",
       "         [[-0.8168,  0.1832]],\n",
       " \n",
       "         [[-0.7996,  0.2004]],\n",
       " \n",
       "         [[-0.7815,  0.2185]],\n",
       " \n",
       "         [[-0.7652,  0.2348]],\n",
       " \n",
       "         [[-0.7519,  0.2481]],\n",
       " \n",
       "         [[-0.7335,  0.2665]],\n",
       " \n",
       "         [[-0.7132,  0.2868]],\n",
       " \n",
       "         [[-0.6943,  0.3057]],\n",
       " \n",
       "         [[-0.6810,  0.3190]],\n",
       " \n",
       "         [[-0.6764,  0.3236]],\n",
       " \n",
       "         [[-0.6795,  0.3205]],\n",
       " \n",
       "         [[-0.6902,  0.3098]],\n",
       " \n",
       "         [[-0.7040,  0.2960]],\n",
       " \n",
       "         [[-0.7193,  0.2807]],\n",
       " \n",
       "         [[-0.7349,  0.2651]],\n",
       " \n",
       "         [[-0.7504,  0.2496]],\n",
       " \n",
       "         [[-0.7646,  0.2354]],\n",
       " \n",
       "         [[-0.7810,  0.2190]],\n",
       " \n",
       "         [[-0.7977,  0.2023]],\n",
       " \n",
       "         [[-0.8150,  0.1850]],\n",
       " \n",
       "         [[-0.8326,  0.1674]],\n",
       " \n",
       "         [[-0.8487,  0.1513]],\n",
       " \n",
       "         [[-0.8628,  0.1372]],\n",
       " \n",
       "         [[-0.8740,  0.1260]],\n",
       " \n",
       "         [[-0.8839,  0.1161]],\n",
       " \n",
       "         [[-0.8930,  0.1070]],\n",
       " \n",
       "         [[-0.9012,  0.0988]],\n",
       " \n",
       "         [[-0.9098,  0.0902]],\n",
       " \n",
       "         [[-0.9181,  0.0819]],\n",
       " \n",
       "         [[-0.9258,  0.0742]],\n",
       " \n",
       "         [[-0.9335,  0.0665]],\n",
       " \n",
       "         [[-0.9427,  0.0573]],\n",
       " \n",
       "         [[-0.9535,  0.0465]],\n",
       " \n",
       "         [[-0.9660,  0.0340]],\n",
       " \n",
       "         [[-0.9805,  0.0195]],\n",
       " \n",
       "         [[-0.9964,  0.0036]],\n",
       " \n",
       "         [[-0.9859, -0.0141]],\n",
       " \n",
       "         [[-0.9686, -0.0314]],\n",
       " \n",
       "         [[-0.9512, -0.0488]],\n",
       " \n",
       "         [[-0.9353, -0.0647]],\n",
       " \n",
       "         [[-0.9188, -0.0812]],\n",
       " \n",
       "         [[-0.9029, -0.0971]],\n",
       " \n",
       "         [[-0.8864, -0.1136]],\n",
       " \n",
       "         [[-0.8696, -0.1304]],\n",
       " \n",
       "         [[-0.8525, -0.1475]],\n",
       " \n",
       "         [[-0.8337, -0.1663]],\n",
       " \n",
       "         [[-0.8162, -0.1838]],\n",
       " \n",
       "         [[-0.7990, -0.2010]],\n",
       " \n",
       "         [[-0.7830, -0.2170]],\n",
       " \n",
       "         [[-0.7683, -0.2317]],\n",
       " \n",
       "         [[-0.7575, -0.2425]],\n",
       " \n",
       "         [[-0.7491, -0.2509]],\n",
       " \n",
       "         [[-0.7413, -0.2587]],\n",
       " \n",
       "         [[-0.7318, -0.2682]],\n",
       " \n",
       "         [[-0.7202, -0.2798]],\n",
       " \n",
       "         [[-0.7091, -0.2909]],\n",
       " \n",
       "         [[-0.6967, -0.3033]],\n",
       " \n",
       "         [[-0.6850, -0.3150]],\n",
       " \n",
       "         [[-0.6690, -0.3310]],\n",
       " \n",
       "         [[-0.6530, -0.3470]],\n",
       " \n",
       "         [[-0.6370, -0.3630]],\n",
       " \n",
       "         [[-0.6200, -0.3800]],\n",
       " \n",
       "         [[-0.6032, -0.3968]],\n",
       " \n",
       "         [[-0.5860, -0.4140]],\n",
       " \n",
       "         [[-0.5698, -0.4302]],\n",
       " \n",
       "         [[-0.5548, -0.4452]],\n",
       " \n",
       "         [[-0.5417, -0.4583]],\n",
       " \n",
       "         [[-0.5292, -0.4708]],\n",
       " \n",
       "         [[-0.5178, -0.4822]],\n",
       " \n",
       "         [[-0.5078, -0.4922]],\n",
       " \n",
       "         [[-0.4993, -0.5007]],\n",
       " \n",
       "         [[-0.4921, -0.5079]],\n",
       " \n",
       "         [[-0.4860, -0.5140]],\n",
       " \n",
       "         [[-0.4811, -0.5189]],\n",
       " \n",
       "         [[-0.4776, -0.5224]],\n",
       " \n",
       "         [[-0.4743, -0.5257]],\n",
       " \n",
       "         [[-0.4705, -0.5295]],\n",
       " \n",
       "         [[-0.4653, -0.5347]],\n",
       " \n",
       "         [[-0.4588, -0.5412]],\n",
       " \n",
       "         [[-0.4519, -0.5481]],\n",
       " \n",
       "         [[-0.4447, -0.5553]],\n",
       " \n",
       "         [[-0.4356, -0.5644]],\n",
       " \n",
       "         [[-0.4254, -0.5746]],\n",
       " \n",
       "         [[-0.4155, -0.5845]],\n",
       " \n",
       "         [[-0.4057, -0.5943]],\n",
       " \n",
       "         [[-0.3960, -0.6040]],\n",
       " \n",
       "         [[-0.3861, -0.6139]],\n",
       " \n",
       "         [[-0.3766, -0.6234]],\n",
       " \n",
       "         [[-0.3674, -0.6326]],\n",
       " \n",
       "         [[-0.3592, -0.6408]],\n",
       " \n",
       "         [[-0.3496, -0.6504]],\n",
       " \n",
       "         [[-0.3423, -0.6577]],\n",
       " \n",
       "         [[-0.3353, -0.6647]],\n",
       " \n",
       "         [[-0.3288, -0.6712]],\n",
       " \n",
       "         [[-0.3221, -0.6779]],\n",
       " \n",
       "         [[-0.3154, -0.6846]],\n",
       " \n",
       "         [[-0.3099, -0.6901]],\n",
       " \n",
       "         [[-0.3072, -0.6928]],\n",
       " \n",
       "         [[-0.3075, -0.6925]],\n",
       " \n",
       "         [[-0.3103, -0.6897]],\n",
       " \n",
       "         [[-0.3161, -0.6839]],\n",
       " \n",
       "         [[-0.3238, -0.6762]],\n",
       " \n",
       "         [[-0.3331, -0.6669]],\n",
       " \n",
       "         [[-0.3447, -0.6553]],\n",
       " \n",
       "         [[-0.3579, -0.6421]],\n",
       " \n",
       "         [[-0.3722, -0.6278]],\n",
       " \n",
       "         [[-0.3877, -0.6123]],\n",
       " \n",
       "         [[-0.4043, -0.5957]],\n",
       " \n",
       "         [[-0.4222, -0.5778]],\n",
       " \n",
       "         [[-0.4429, -0.5571]],\n",
       " \n",
       "         [[-0.4653, -0.5347]],\n",
       " \n",
       "         [[-0.4889, -0.5111]],\n",
       " \n",
       "         [[-0.5137, -0.4863]],\n",
       " \n",
       "         [[-0.5387, -0.4613]],\n",
       " \n",
       "         [[-0.5623, -0.4377]],\n",
       " \n",
       "         [[-0.5850, -0.4150]],\n",
       " \n",
       "         [[-0.6067, -0.3933]],\n",
       " \n",
       "         [[-0.6285, -0.3715]],\n",
       " \n",
       "         [[-0.6505, -0.3495]],\n",
       " \n",
       "         [[-0.6719, -0.3281]],\n",
       " \n",
       "         [[-0.6926, -0.3074]],\n",
       " \n",
       "         [[-0.7136, -0.2864]],\n",
       " \n",
       "         [[-0.7336, -0.2664]],\n",
       " \n",
       "         [[-0.7519, -0.2481]],\n",
       " \n",
       "         [[-0.7687, -0.2313]],\n",
       " \n",
       "         [[-0.7834, -0.2166]],\n",
       " \n",
       "         [[-0.7944, -0.2056]],\n",
       " \n",
       "         [[-0.8023, -0.1977]],\n",
       " \n",
       "         [[-0.8086, -0.1914]],\n",
       " \n",
       "         [[-0.8149, -0.1851]],\n",
       " \n",
       "         [[-0.8199, -0.1801]],\n",
       " \n",
       "         [[-0.8233, -0.1767]],\n",
       " \n",
       "         [[-0.8260, -0.1740]],\n",
       " \n",
       "         [[-0.8283, -0.1717]],\n",
       " \n",
       "         [[-0.8295, -0.1705]],\n",
       " \n",
       "         [[-0.8293, -0.1707]],\n",
       " \n",
       "         [[-0.8291, -0.1709]],\n",
       " \n",
       "         [[-0.8280, -0.1720]],\n",
       " \n",
       "         [[-0.8270, -0.1730]],\n",
       " \n",
       "         [[-0.8269, -0.1731]],\n",
       " \n",
       "         [[-0.8272, -0.1728]],\n",
       " \n",
       "         [[-0.8295, -0.1705]],\n",
       " \n",
       "         [[-0.8307, -0.1693]],\n",
       " \n",
       "         [[-0.8297, -0.1703]],\n",
       " \n",
       "         [[-0.8267, -0.1733]],\n",
       " \n",
       "         [[-0.8232, -0.1768]],\n",
       " \n",
       "         [[-0.8182, -0.1818]],\n",
       " \n",
       "         [[-0.8123, -0.1877]],\n",
       " \n",
       "         [[-0.8060, -0.1940]],\n",
       " \n",
       "         [[-0.7971, -0.2029]],\n",
       " \n",
       "         [[-0.7843, -0.2157]],\n",
       " \n",
       "         [[-0.7686, -0.2314]],\n",
       " \n",
       "         [[-0.7488, -0.2512]],\n",
       " \n",
       "         [[-0.7275, -0.2725]],\n",
       " \n",
       "         [[-0.7079, -0.2921]],\n",
       " \n",
       "         [[-0.6901, -0.3099]],\n",
       " \n",
       "         [[-0.6739, -0.3261]],\n",
       " \n",
       "         [[-0.6593, -0.3407]],\n",
       " \n",
       "         [[-0.6462, -0.3538]],\n",
       " \n",
       "         [[-0.6351, -0.3649]],\n",
       " \n",
       "         [[-0.6289, -0.3711]],\n",
       " \n",
       "         [[-0.6247, -0.3753]],\n",
       " \n",
       "         [[-0.6217, -0.3783]],\n",
       " \n",
       "         [[-0.6196, -0.3804]],\n",
       " \n",
       "         [[-0.6194, -0.3806]],\n",
       " \n",
       "         [[-0.6208, -0.3792]],\n",
       " \n",
       "         [[-0.6238, -0.3762]],\n",
       " \n",
       "         [[-0.6287, -0.3713]],\n",
       " \n",
       "         [[-0.6350, -0.3650]],\n",
       " \n",
       "         [[-0.6407, -0.3593]],\n",
       " \n",
       "         [[-0.6457, -0.3543]],\n",
       " \n",
       "         [[-0.6485, -0.3515]],\n",
       " \n",
       "         [[-0.6493, -0.3507]],\n",
       " \n",
       "         [[-0.6502, -0.3498]],\n",
       " \n",
       "         [[-0.6520, -0.3480]],\n",
       " \n",
       "         [[-0.6550, -0.3450]],\n",
       " \n",
       "         [[-0.6561, -0.3439]],\n",
       " \n",
       "         [[-0.6557, -0.3443]],\n",
       " \n",
       "         [[-0.6539, -0.3461]],\n",
       " \n",
       "         [[-0.6507, -0.3493]],\n",
       " \n",
       "         [[-0.6461, -0.3539]],\n",
       " \n",
       "         [[-0.6393, -0.3607]],\n",
       " \n",
       "         [[-0.6331, -0.3669]],\n",
       " \n",
       "         [[-0.6278, -0.3722]],\n",
       " \n",
       "         [[-0.6232, -0.3768]],\n",
       " \n",
       "         [[-0.6219, -0.3781]],\n",
       " \n",
       "         [[-0.6219, -0.3781]],\n",
       " \n",
       "         [[-0.6222, -0.3778]],\n",
       " \n",
       "         [[-0.6221, -0.3779]],\n",
       " \n",
       "         [[-0.6222, -0.3778]],\n",
       " \n",
       "         [[-0.6256, -0.3744]],\n",
       " \n",
       "         [[-0.6313, -0.3687]],\n",
       " \n",
       "         [[-0.6392, -0.3608]],\n",
       " \n",
       "         [[-0.6474, -0.3526]],\n",
       " \n",
       "         [[-0.6554, -0.3446]],\n",
       " \n",
       "         [[-0.6640, -0.3360]],\n",
       " \n",
       "         [[-0.6741, -0.3259]],\n",
       " \n",
       "         [[-0.6862, -0.3138]],\n",
       " \n",
       "         [[-0.6996, -0.3004]],\n",
       " \n",
       "         [[-0.7152, -0.2848]],\n",
       " \n",
       "         [[-0.7296, -0.2704]],\n",
       " \n",
       "         [[-0.7408, -0.2592]],\n",
       " \n",
       "         [[-0.7524, -0.2476]],\n",
       " \n",
       "         [[-0.7636, -0.2364]],\n",
       " \n",
       "         [[-0.7743, -0.2257]],\n",
       " \n",
       "         [[-0.7881, -0.2119]],\n",
       " \n",
       "         [[-0.8009, -0.1991]],\n",
       " \n",
       "         [[-0.8112, -0.1888]],\n",
       " \n",
       "         [[-0.8186, -0.1814]],\n",
       " \n",
       "         [[-0.8242, -0.1758]],\n",
       " \n",
       "         [[-0.8290, -0.1710]],\n",
       " \n",
       "         [[-0.8344, -0.1656]],\n",
       " \n",
       "         [[-0.8404, -0.1596]],\n",
       " \n",
       "         [[-0.8462, -0.1538]],\n",
       " \n",
       "         [[-0.8507, -0.1493]],\n",
       " \n",
       "         [[-0.8540, -0.1460]],\n",
       " \n",
       "         [[-0.8581, -0.1419]],\n",
       " \n",
       "         [[-0.8650, -0.1350]],\n",
       " \n",
       "         [[-0.8721, -0.1279]]]),\n",
       " 'inputs': tensor([[[    nan,     nan],\n",
       "          [    nan,     nan],\n",
       "          [    nan,     nan],\n",
       "          ...,\n",
       "          [    nan,     nan],\n",
       "          [    nan,     nan],\n",
       "          [    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan],\n",
       "          [    nan,     nan],\n",
       "          [    nan,     nan],\n",
       "          ...,\n",
       "          [    nan,     nan],\n",
       "          [    nan,     nan],\n",
       "          [    nan,     nan]],\n",
       " \n",
       "         [[    nan,     nan],\n",
       "          [    nan,     nan],\n",
       "          [    nan,     nan],\n",
       "          ...,\n",
       "          [    nan,     nan],\n",
       "          [    nan,     nan],\n",
       "          [    nan,     nan]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[21.0083,  0.3000],\n",
       "          [85.4008,  0.2000],\n",
       "          [ 6.7866,  0.5000],\n",
       "          ...,\n",
       "          [ 0.8473,  0.1000],\n",
       "          [11.7130,  0.5000],\n",
       "          [ 2.0658,  0.1000]],\n",
       " \n",
       "         [[49.0193,  1.0000],\n",
       "          [85.4008,  0.9000],\n",
       "          [ 5.9332,  0.6000],\n",
       "          ...,\n",
       "          [ 0.8473,  0.2000],\n",
       "          [11.0535,  0.2000],\n",
       "          [ 2.0658,  0.2000]],\n",
       " \n",
       "         [[49.0193,  0.7000],\n",
       "          [67.2305,  0.8000],\n",
       "          [ 5.9332,  0.6000],\n",
       "          ...,\n",
       "          [ 0.8473,  0.1000],\n",
       "          [10.3654,  0.1000],\n",
       "          [ 2.0658,  0.5000]]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'gpContainer' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-6127f08ed509>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'gpContainer' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "class gpContainer(Namespace):\n",
    "    __reserved_names__ = ['get' , 'set' , 'update' , 'delete' , 'subset' , 'keys' , 'values' , 'items' , 'copy' , 'apply' , 'map']\n",
    "    def __init__(self , inherit_from = None , **kwargs) -> None:\n",
    "        if inherit_from is not None: \n",
    "            for k , v in inherit_from.items(): self.set(k , v)\n",
    "        for k , v in kwargs.items(): self.set(k , v)\n",
    "    def get(self , key , default = None , require = False):\n",
    "        return getattr(self , key) if hasattr(self , key) else default\n",
    "    def update(self , **kwargs):\n",
    "        for k , v in kwargs.items(): self.set(k , v)\n",
    "        return self\n",
    "    def set(self , key  , v):\n",
    "        assert key not in type(self).__reserved_names__ , key\n",
    "        setattr(self , key , v)\n",
    "        return self\n",
    "    def delete(self , key):\n",
    "        assert key not in type(self).__reserved_names__ , key\n",
    "        if hasattr(self , key): delattr(self, key)\n",
    "        return self\n",
    "    def subset(self , keys , require = False):\n",
    "        return {key:self.get(key , require = require) for key in keys}\n",
    "    def keys(self): \n",
    "        return self.__dict__.keys()\n",
    "    def values(self): \n",
    "        return self.__dict__.values()\n",
    "    def items(self): \n",
    "        return self.__dict__.items()\n",
    "    def __repr__(self) -> str:\n",
    "        return self.__dict__.__repr__()\n",
    "    def __add__(self , another):\n",
    "        new = type(self)()\n",
    "        for k , v in self.items(): new.set(k , v)\n",
    "        for k , v in another.items(): new.set(k , v)\n",
    "        return new\n",
    "    def __getitem__(self , key):\n",
    "        return self.__dict__.__getitem__(key)\n",
    "\n",
    "\n",
    "    \n",
    "a = gpContainer(a = 1 , b=2)\n",
    "def f(a,b):\n",
    "    return a*b\n",
    "f(**a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
