{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--process PROCESS] [--rawname RAWNAME]\n",
      "                             [--resume RESUME] [--anchoring ANCHORING]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=c:\\Users\\jinmeng\\AppData\\Roaming\\jupyter\\runtime\\kernel-v2-18492CwSBtrcuOHON.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--What process would you want to run? 0: all, 1: train only (default), 2: test only , 3: copy to instance\n",
      "--Process Queue : Data + Train + Test + Instance\n",
      "--Multiple model path of LSTM_day_SHORTTEST exists, input [yes] to resume training, or start a new one!\n",
      "--Confirm Resume Training!\n",
      "--Model_name is set to LSTM_day_SHORTTEST!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time : ${2023-6-27} ${21:05}\n",
    "# @Author : Mathew Jin\n",
    "# @File : ${run_model.py}\n",
    "# chmod +x run_model.py\n",
    "# python3 scripts/run_model3.py --process=0 --rawname=1 --resume=0 --anchoring=0\n",
    "'''\n",
    "1.TRA\n",
    "https://arxiv.org/pdf/2106.12950.pdf\n",
    "https://github.com/microsoft/qlib/blob/main/examples/benchmarks/TRA/src/model.py\n",
    "1.1 HIST\n",
    "https://arxiv.org/pdf/2110.13716.pdf\n",
    "https://github.com/Wentao-Xu/HIST\n",
    "2.Lightgbm\n",
    "https://github.com/microsoft/LightGBM/blob/master/examples/python-guide/plot_example.py\n",
    "https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.plot_tree.html\n",
    "3.other factors\n",
    "'''\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import itertools , random , os, shutil , gc , time , h5py , yaml\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from torch.optim.swa_utils import AveragedModel , update_bn\n",
    "from scripts.util.environ import get_logger\n",
    "from scripts.util.basic import process_timer , FilteredIterator , lr_cosine_scheduler , versatile_storage\n",
    "from scripts.util.multiloss import multiloss_calculator \n",
    "from scripts.data_util.ModelData import ModelData\n",
    "from scripts.trainer.config import *\n",
    "from scripts.function.basic import *\n",
    "from scripts.nn.My import *\n",
    "# from audtorch.metrics.functional import *\n",
    "\n",
    "try:\n",
    "    parser = trainer_parser().parse_args()\n",
    "except:\n",
    "    parser = trainer_parser().parse_args(args=[])\n",
    "\n",
    "logger = get_logger()\n",
    "config = train_config(parser = parser , do_process=True)\n",
    "set_trainer_configs(config)\n",
    "time_recorder = process_timer(True)\n",
    "storage_model = versatile_storage(config.storage_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function scripts.function.basic.list_converge(l, n=None, eps=None)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 'ccc',\n",
       " 'score': 'pearson',\n",
       " 'penalty': {'hidden_orthogonality': {'lamb': 0.001},\n",
       "  'tra_ot_penalty': {'lamb': 0.01, 'rho': 0.999}}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.train_params['criterion']['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sun Jan 28 10:20:14 2024'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "a = time.ctime()\n",
    "time.time() - time.mktime(time.strptime(a))\n",
    "b = time.time()\n",
    "time.ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "1 0 1\n",
      "2 1 0\n",
      "3 1 1\n",
      "4 2 0\n",
      "5 2 1\n",
      "0 (0, 1)\n",
      "1 (1, 0)\n",
      "2 (1, 1)\n",
      "3 (2, 0)\n",
      "4 (2, 1)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "class FilteredIterator:\n",
    "    def __init__(self, iterable, condition):\n",
    "        self.iterable  = iter(iterable)\n",
    "        if callable(condition):\n",
    "            self.condition = condition\n",
    "        else:\n",
    "            self.condition = iter(condition)\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        while True:\n",
    "            item = next(self.iterable)\n",
    "            cond = self.condition(item) if callable(self.condition) else next(self.condition)\n",
    "            if cond: return item\n",
    "model_iter = list(itertools.product(range(3) , range(2)))\n",
    "models_trained = np.array([True,False,False,False,False,False])\n",
    "for i,(model_date,model_num) in enumerate(model_iter):\n",
    "    print(i,model_date,model_num)\n",
    "model_iter = FilteredIterator(model_iter, models_trained == 0)\n",
    "for i,x in enumerate(model_iter):\n",
    "    print(i,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 0), (0, 1), (1, 0), (1, 1), (2, 0), (2, 1)],\n",
       " array([False,  True,  True,  True,  True,  True]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.product(range(3) , range(2))) , models_trained == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0), (0, 1), (1, 0), (1, 1), (2, 0), (2, 1)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.product(range(3) , range(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataloader': {'random_seed': None,\n",
       "  'random_tv_split': True,\n",
       "  'sample_method': 'train_shuffle',\n",
       "  'train_ratio': 0.8},\n",
       " 'trainer': {'optimizer': {'name': 'Adam', 'param': {}},\n",
       "  'scheduler': {'name': 'cycle',\n",
       "   'param': {'base_lr': 1e-07, 'step_size_up': 4}},\n",
       "  'learn_rate': {'base': 0.005,\n",
       "   'ratio': {'attempt': [1, 0.1, 10, 0.01, 100],\n",
       "    'round': [1.0],\n",
       "    'transfer': 0.1},\n",
       "   'reset': {'num_reset': 2,\n",
       "    'trigger': 40,\n",
       "    'recover_level': 1.0,\n",
       "    'speedup2x': True}},\n",
       "  'nanloss': {'retry': 2},\n",
       "  'gradient': {'clip_value': 10.0},\n",
       "  'retrain': {'attempts': 4, 'min_epoch': 20, 'min_epoch_round': 10}},\n",
       " 'criterion': {'loss': 'ccc',\n",
       "  'score': 'pearson',\n",
       "  'penalty': {'hidden_orthogonality': {'lamb': 0.001},\n",
       "   'tra_ot_penalty': {'lamb': 0.01, 'rho': 0.999}}},\n",
       " 'transfer': False,\n",
       " 'output_types': ['best', 'swalast', 'swabest'],\n",
       " 'multitask': {'type': 'hybrid',\n",
       "  'param_dict': {'dwa': {'tau': 2},\n",
       "   'ruw': {'phi': None},\n",
       "   'ewa': {},\n",
       "   'gls': {},\n",
       "   'rws': {},\n",
       "   'hybrid': {'phi': None, 'tau': 2}}},\n",
       " 'terminate': {'overall': {'early_stop': 20,\n",
       "   'max_epoch': 200,\n",
       "   'valid_converge': {'min_epoch': 5, 'eps': 1e-05}},\n",
       "  'round': {'early_stop': 10,\n",
       "   'max_epoch': 100,\n",
       "   'valid_converge': {'min_epoch': 5, 'eps': 1e-05}}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(config , 'TRAIN_PARAM' , None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "use_device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "class Device:\n",
    "    def __init__(self , device = use_device) -> None:\n",
    "        self.device = device\n",
    "    def __call__(self, *args: Any, **kwds: Any) -> Any:\n",
    "        args = self.to_device(args)\n",
    "        kwds = self.to_device(kwds)\n",
    "        return args , kwds\n",
    "    def _to(self , x):\n",
    "        if isinstance(x , (list,tuple)):\n",
    "            return type(x)(self._to(v) for v in x)\n",
    "        elif isinstance(x , (dict)):\n",
    "            return {k:self._to(v) for k,v in x.items()}\n",
    "        else:\n",
    "            return x.to(self.device) if x is not None else None\n",
    "    def torch_nans(self,*args,**kwargs):\n",
    "        return torch.ones(*args , device = self.device , **kwargs).fill_(torch.nan)\n",
    "    def torch_zeros(self,*args , **kwargs):\n",
    "        return torch.zeros(*args , device = self.device , **kwargs)\n",
    "    def torch_ones(self,*args,**kwargs):\n",
    "        return torch.ones(*args , device = self.device , **kwargs)\n",
    "    def torch_arange(self,*args,**kwargs):\n",
    "        return torch.arange(*args , device = self.device , **kwargs)\n",
    "    def print_cuda_memory(self):\n",
    "        print(f'Allocated {torch.cuda.memory_allocated(self.device) / 1024**3:.1f}G, '+\\\n",
    "              f'Reserved {torch.cuda.memory_reserved(self.device) / 1024**3:.1f}G')\n",
    "        \n",
    "d = Device()\n",
    "d.arange(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
