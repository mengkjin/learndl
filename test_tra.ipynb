{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 'scripts/my_utils.py'\n",
    "%run 'scripts/gen_data.py' --confirm 'no'\n",
    "%run 'scripts/dataset.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import gc , random\n",
    "import numpy as np\n",
    "from scripts import environ\n",
    "from scripts import my_utils as my_utils\n",
    "from scripts.function import *\n",
    "from scripts.environ import get_config\n",
    "from scripts.dataset import ModelData\n",
    "config = get_config()\n",
    "\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "storage_loader = my_utils.versatile_storage(config['STORAGE_TYPE'])\n",
    "process_name = 'train'\n",
    "num_states = 3\n",
    "\n",
    "class container():\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "data = ModelData('day' , config)\n",
    "ShareNames = container()\n",
    "ShareNames.model_date_list = data.model_date_list\n",
    "ShareNames.test_full_dates = data.test_full_dates\n",
    "data2 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scripts.special.TRA as TRA\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['TRA_switch'] = True #affect 1.buffer includes hist_loss 2.seqlen includes labels of a big number\n",
    "tra_num_states = 3 if config['TRA_switch'] else 1\n",
    "data = data2\n",
    "data2.buffer_functions(init = TRA.buffer_init(tra_num_states) , process = TRA.buffer_process(tra_num_states))\n",
    "data2.create_dataloader('train' , 'train' , ShareNames.model_date_list[0] , config['MODEL_PARAM']['seqlens'][0])\n",
    "\n",
    "net = TRA.TRA(nn.LSTM(6,16,1,batch_first=True),16,tra_num_states).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0018562273901291003 -5.481716361828148e-05\n",
      "0.0116781241951095 0.02863265248015523\n",
      "0.029439556947280024 0.03618217743933201\n",
      "0.035790456572195165 0.04031315818428993\n",
      "0.038990421732730304 0.04690311327576637\n",
      "0.040948511220867165 0.040868749283254145\n",
      "0.04401870260669573 0.049782258458435535\n",
      "0.04882481971101181 0.05145879816263914\n",
      "0.05129135420193543 0.05217417702078819\n",
      "0.05393777334609547 0.05445307847112417\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "loss_train , loss_valid , ic_train , ic_valid = [] , [] , [] , []\n",
    "iter_train , iter_valid = data2.dataloaders['train'] , data2.dataloaders['valid']\n",
    "\n",
    "net.train()\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "modifier = {\n",
    "    'inputs': lambda inputs,batch,data:inputs,\n",
    "    'metric': lambda metric,batch,data:metric,\n",
    "    'update': lambda batch,data:None\n",
    "}\n",
    "if config['TRA_switch']:\n",
    "    modifier['inputs'] = lambda inputs,batch,data:net.modifier_inputs(inputs,batch,data)\n",
    "    modifier['metric'] = lambda metric,batch,data:net.modifier_metric(metric,batch,data)\n",
    "    modifier['update'] = lambda batch,data:net.modifier_update(batch,data)\n",
    "\n",
    "k = 'hist_loss'\n",
    "a_train , a_valid = [] , []\n",
    "\n",
    "for ii in range(10):\n",
    "    l_train , l_valid = [] , []\n",
    "    net.train()   \n",
    "    for _ , batch_data in enumerate(iter_train):\n",
    "        x , y , w , i = tuple([batch_data[k] for k in ['x','y','w','i']])\n",
    "        # d , rw = data2.buffer[k] , data2.seqs[k]\n",
    "        inputs = modifier['inputs'](x , batch_data , data2)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred , hidden = net(inputs)\n",
    "        metric = {'loss':-pearson(pred , y) , 'score':pearson(pred , y).item()}\n",
    "        metric = modifier['metric'](metric , batch_data , data2)\n",
    "        \n",
    "        metric['loss'].backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        modifier['update'](batch_data , data2)\n",
    "\n",
    "        l_train.append(metric['loss'].item())\n",
    "\n",
    "    net.eval()     \n",
    "    for i , batch_data in enumerate(iter_valid):\n",
    "        x , y , w , i = tuple([batch_data[k] for k in ['x','y','w','i']])\n",
    "        inputs = modifier['inputs'](x , batch_data , data2)\n",
    "        pred , _ = net(inputs)\n",
    "        metric = {'loss':-pearson(pred , y) , 'score':pearson(pred , y).item()}\n",
    "        metric = modifier['metric'](metric , batch_data , data2)\n",
    "        modifier['update'](batch_data , data2)\n",
    "        l_valid.append(metric['score'])\n",
    "\n",
    "    print(-np.mean(l_train) , np.mean(l_valid))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
