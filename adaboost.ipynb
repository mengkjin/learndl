{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os , torch\n",
    "\n",
    "fctCombTrain = pd.read_feather('CombStdByZXMkt_All_TrainLabel.feather') # 训练集，带Label\n",
    "del fctCombTrain['ZX'], fctCombTrain['mktVal'], fctCombTrain['nextRtnM'], fctCombTrain['mktValRank']\n",
    "fctCombTrain['date'] = pd.to_datetime(fctCombTrain['date'])\n",
    "fctCombTrain = fctCombTrain.sort_values(['date', 'StockID']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "训练区间：2005-02-28 00:00:00 - 2007-01-31 00:00:00\n",
      "Round: 1, Estimator Error: 0.4941096007823944, feature_idx: 129\n",
      "Round: 6, Estimator Error: 0.49925777316093445, feature_idx: 135\n",
      "Round: 11, Estimator Error: 0.49936383962631226, feature_idx: 5\n",
      "Round: 16, Estimator Error: 0.4994628131389618, feature_idx: 33\n",
      "Round: 21, Estimator Error: 0.49956050515174866, feature_idx: 7\n",
      "Round: 26, Estimator Error: 0.49958834052085876, feature_idx: 90\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RealAdaBoost(n_booster=30,n_bins=20)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "class WeakBooster:\n",
    "    EPS = 1e-6\n",
    "    def __init__(self, n_bins : int): \n",
    "        self.n_bins = n_bins\n",
    "    def __repr__(self) -> str: \n",
    "        return  f'{self.__class__.__name__}(n_bins={self.n_bins})'\n",
    "\n",
    "    def fit(self, X : Tensor , y : Tensor , weight : Tensor | None = None):\n",
    "        if weight is None: weight = torch.ones_like(y) / len(y)\n",
    "        assert isinstance(X , Tensor) and isinstance(y , Tensor) and isinstance(weight , Tensor) , (X , y , weight)\n",
    "        assert torch.all(X < self.n_bins) , X.max()\n",
    "        assert not torch.is_floating_point(X) , X.dtype\n",
    "        self.n_feat = X.shape[-1]\n",
    "\n",
    "        pos_wgt , neg_wgt = (weight * (y == 1))[:,None] , (weight * (y == -1))[:,None]\n",
    "        pos_imp , neg_imp = torch.zeros(self.n_feat , self.n_bins) , torch.zeros(self.n_feat , self.n_bins)\n",
    "\n",
    "        for ibin in range(self.n_bins):\n",
    "            where = X == ibin\n",
    "            pos_imp[:,ibin] = (pos_wgt * where).sum(dim = 0)\n",
    "            neg_imp[:,ibin] = (neg_wgt * where).sum(dim = 0)\n",
    "        \n",
    "        feat_imp = (pos_imp + neg_imp).sum(-1,keepdim=True)\n",
    "        pos_imp , neg_imp = pos_imp / feat_imp , neg_imp / feat_imp\n",
    "        \n",
    "        self.feat_losses = torch.sqrt(pos_imp * neg_imp).sum(1)\n",
    "        self.feat_idx = self.feat_losses.argmin()\n",
    "        self.bin_predictions = 0.5 * torch.log((pos_imp[self.feat_idx] + self.EPS) / (neg_imp[self.feat_idx] + self.EPS))\n",
    "        return self\n",
    "    \n",
    "    @property\n",
    "    def min_feat_loss(self): return self.feat_losses[self.feat_idx]\n",
    "\n",
    "    def predict(self, X : Tensor):\n",
    "        assert X.shape[-1] == self.n_feat , (X.shape , self.n_feat)\n",
    "        assert isinstance(X , Tensor) , X\n",
    "        assert not torch.is_floating_point(X) , X.dtype\n",
    "        group = X[:, self.feat_idx]\n",
    "        return torch.where(group >= 0 , self.bin_predictions[group] , torch.nan)\n",
    "    \n",
    "class RealAdaBoost:\n",
    "    def __init__(self, n_booster = 30, n_bins = 20):\n",
    "        self.n_booster , self.n_bins = n_booster , n_bins\n",
    "        self.boosters = [WeakBooster(n_bins) for _ in range(n_booster)]\n",
    "\n",
    "    def __repr__(self) -> str: return f'{self.__class__.__name__}(n_booster={self.n_booster},n_bins={self.n_bins})'\n",
    "    def __getitem__(self , i): return self.boosters[i]\n",
    "    \n",
    "    def update_weight(self , weight : Tensor , y : Tensor , y_pred : Tensor):\n",
    "        weight = torch.exp(-y * y_pred.nan_to_num(0)) * weight\n",
    "        return weight / weight.sum()\n",
    "\n",
    "    def fit(self, X : Tensor , y : Tensor , init_weight : Tensor | None = None):\n",
    "        weight = self.init_weight(y) if init_weight is None else init_weight\n",
    "        weight = weight.to(y.device)\n",
    "        for i , booster in enumerate(self.boosters):  # 使用 tqdm 显示进度条\n",
    "            y_pred = booster.fit(X , y , weight).predict(X)\n",
    "            weight = self.update_weight(weight , y , y_pred)\n",
    "            if i % 5 == 0: print(f'Round: {i+1}, Estimator Error: {booster.min_feat_loss}, feature_idx: {booster.feat_idx}')\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return torch.stack([booster.predict(X) for booster in self.boosters] , dim = -1)\n",
    "    \n",
    "    @property\n",
    "    def feat_idx(self): return [booster.feat_idx for booster in self.boosters]\n",
    "    @property\n",
    "    def feat_err(self): return [booster.min_feat_loss for booster in self.boosters]\n",
    "\n",
    "    @staticmethod\n",
    "    def inputX(x : pd.DataFrame , n_bins : int = 20 , date_colname = 'date'):\n",
    "        X = torch.tensor(x.groupby(date_colname).rank(pct = True).values) * n_bins\n",
    "        X[X >= n_bins] = n_bins - 1\n",
    "        return X.nan_to_num(-1).to(torch.int32)\n",
    "    \n",
    "    @staticmethod\n",
    "    def inputY(y : pd.DataFrame): return torch.tensor(y.values.squeeze())\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weight(y , top_weight = False , date_weight = False , component_weight = None , \n",
    "                    date_colname = 'date' , secid_colname = 'StockID' , halflife = 12): \n",
    "        wgt : Any = pd.DataFrame({'weight':1},index=y.index) if isinstance(y , pd.DataFrame) else torch.ones_like(y)\n",
    "\n",
    "        if top_weight: \n",
    "            where = (y > 0).values if isinstance(y , pd.DataFrame) else y > 0\n",
    "            wgt[where] = wgt[where] * 2\n",
    "\n",
    "        if date_weight:\n",
    "            assert isinstance(wgt , pd.DataFrame) and date_colname in wgt.index.names , wgt\n",
    "            dates = wgt.index.get_level_values(date_colname).unique()\n",
    "            d_wgt = np.exp(np.log(0.5) * np.flip(np.arange(len(dates))) / halflife)\n",
    "            date_wgt = pd.DataFrame({date_colname:dates,'weight':d_wgt}).set_index(date_colname)\n",
    "            wgt = wgt * date_wgt\n",
    "\n",
    "        if component_weight is not None:\n",
    "            assert isinstance(wgt , pd.DataFrame) and secid_colname in wgt.index.names , wgt\n",
    "            where = wgt.index.get_level_values(secid_colname).isin(component_weight)\n",
    "            wgt[where] = wgt[where] * 2\n",
    "\n",
    "        if isinstance(wgt , pd.DataFrame):\n",
    "            wgt = torch.tensor(wgt.values.squeeze())\n",
    "        return wgt / wgt.sum()\n",
    "    \n",
    "windowsLen = 24 # 回望过去的月数\n",
    "MDTs = fctCombTrain['date'].unique()   # 测试集日期-完整\n",
    "idx = 24\n",
    "\n",
    "resDetails = dict()\n",
    "resFct = pd.DataFrame()\n",
    "\n",
    "idtEnd = MDTs[idx]\n",
    "idtStart = MDTs[idx - windowsLen+1]\n",
    "idtPredict = MDTs[idx + 1]\n",
    "# if pd.to_datetime(idtPredict) < pd.to_datetime('2014-12-31'):\n",
    "#     continue\n",
    "print(f'\\n训练区间：{idtStart} - {idtEnd}')\n",
    "fctCombTrainIdt = fctCombTrain[(fctCombTrain['date'] >= idtStart) & (fctCombTrain['date'] <= idtEnd)]\n",
    "fctCombTrainIdt = fctCombTrainIdt.set_index(['date', 'StockID']).dropna(subset=['nextRtnM_Label'])\n",
    "fctCombTrainIdt = fctCombTrainIdt[fctCombTrainIdt['nextRtnM_Label']!=0]\n",
    "\n",
    "missingSeries = fctCombTrainIdt.isnull().sum() / len(fctCombTrainIdt)\n",
    "if missingSeries['nextRtnM_Label'] > 0.2: print('Error: nextRtnM_Label 缺失值比例大于0.2')\n",
    "\n",
    "fctCombTrainIdt = fctCombTrainIdt.loc[:, missingSeries[missingSeries < 0.2].index] # .fillna(0.0)\n",
    "assert isinstance(fctCombTrainIdt , pd.DataFrame)\n",
    "\n",
    "trainX = RealAdaBoost.inputX(fctCombTrainIdt.iloc[:,:-1])\n",
    "trainY = RealAdaBoost.inputY(fctCombTrainIdt.iloc[:,-1:])\n",
    "init_weight = RealAdaBoost.init_weight(fctCombTrainIdt.iloc[:,-1:])\n",
    "\n",
    "model = RealAdaBoost(n_booster = 30, n_bins = 20)\n",
    "model.fit(trainX, trainY , init_weight=init_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fctCombTrain = pd.read_feather(os.path.join('input_data', '因子值CombStdByZXMkt_All_TrainLabel.feather')) # 训练集，带Label\n",
    "del fctCombTrain['ZX'], fctCombTrain['mktVal'], fctCombTrain['nextRtnM'], fctCombTrain['mktValRank']\n",
    "fctCombTrain['date'] = pd.to_datetime(fctCombTrain['date'])\n",
    "fctCombTrain = fctCombTrain.sort_values(['date', 'StockID']).reset_index(drop=True)\n",
    "\n",
    "fctCombTest = pd.read_feather(os.path.join('input_data', '因子值CombStdByZXMkt_All.feather')) # 测试集，不带Label\n",
    "fctCombTest['date'] = pd.to_datetime(fctCombTest['date'])\n",
    "del fctCombTest['ZX'], fctCombTest['mktVal'], fctCombTest['nextRtnM']\n",
    "fctCombTest = fctCombTest.sort_values(['date', 'StockID']).reset_index(drop=True)\n",
    "\n",
    "MDTs = fctCombTest['date'].unique()   # 测试集日期-完整\n",
    "IDs = fctCombTest['StockID'].unique() # 测试集股票代码-完整\n",
    "\n",
    "\n",
    "# %% 训练1-滚动训练\n",
    "\n",
    "windowsLen = 24 # 回望过去的月数\n",
    "idx = len(MDTs)-2\n",
    "\n",
    "resDetails = dict()\n",
    "resFct = pd.DataFrame()\n",
    "for idx in tqdm(range(windowsLen-1, len(MDTs)-1)):\n",
    "    idtEnd = MDTs[idx]\n",
    "    idtStart = MDTs[idx - windowsLen+1]\n",
    "    idtPredict = MDTs[idx + 1]\n",
    "    # if pd.to_datetime(idtPredict) < pd.to_datetime('2014-12-31'):\n",
    "    #     continue\n",
    "    print(f'\\n训练区间：{idtStart} - {idtEnd}')\n",
    "    fctCombTrainIdt = fctCombTrain[(fctCombTrain['date'] >= idtStart) & (fctCombTrain['date'] <= idtEnd)]\n",
    "    fctCombTrainIdt = fctCombTrainIdt.set_index(['date', 'StockID']).dropna(subset=['nextRtnM_Label'])\n",
    "    fctCombTrainIdt = fctCombTrainIdt[fctCombTrainIdt['nextRtnM_Label']!=0]\n",
    "    # 每列计算缺失值比例\n",
    "    missingSeries = fctCombTrainIdt.isnull().sum() / len(fctCombTrainIdt)\n",
    "    if missingSeries['nextRtnM_Label'] > 0.2:\n",
    "        print('Error: nextRtnM_Label 缺失值比例大于0.2')\n",
    "        break\n",
    "    # 剔除缺失值占比大于0.2的列\n",
    "    fctCombTrainIdt = fctCombTrainIdt.loc[:, missingSeries[missingSeries < 0.2].index].fillna(0.0)\n",
    "    # 训练集\n",
    "    trainX = fctCombTrainIdt.iloc[:, :-1].values\n",
    "    trainY = fctCombTrainIdt.iloc[:, -1].values\n",
    "    # 训练模型\n",
    "    model = RealAdaBoost(n_classifier = 30, n_bins = 20)\n",
    "    model.fit(trainX, trainY)\n",
    "\n",
    "    # 预测\n",
    "    idtPredict = MDTs[idx+1]\n",
    "    print(f'预测区间：{idtPredict}')\n",
    "    fctCombTestIdtPredict = fctCombTest[fctCombTest['date']==idtPredict]\n",
    "    fctCombTestIdtPredict = fctCombTestIdtPredict.set_index(['date', 'StockID'])\n",
    "    # 设置和前面一样的列顺序，同时不带nextRtnM_Label\n",
    "    feature_list = missingSeries[missingSeries < 0.2].index.drop('nextRtnM_Label')\n",
    "    fctCombTestIdtPredict = fctCombTestIdtPredict.loc[:, feature_list]\n",
    "    # fctCombTestIdtPredict = fctCombTestIdtPredict.fillna(0.0)\n",
    "    # 确定测试集的股票代码\n",
    "    IDs = fctCombTestIdtPredict.index.get_level_values(1).tolist()\n",
    "    # 测试集数据\n",
    "    testX = fctCombTestIdtPredict.values\n",
    "    feature_list, predictions_matrix = model.predict(testX)\n",
    "\n",
    "    # 保存details\n",
    "    feature_names = fctCombTestIdtPredict.columns[feature_list]\n",
    "    resDetails[idtPredict] = {'feature_names': feature_names, 'predictions_matrix': predictions_matrix}\n",
    "    y_predict = np.sum(predictions_matrix, axis=1)\n",
    "    y_predict[y_predict == 0.0] = np.nan\n",
    "    resFctTmp = pd.DataFrame(y_predict, index=IDs, columns=[idtPredict])\n",
    "    resFct = resFct.merge(resFctTmp, left_index=True, right_index=True, how='outer')\n",
    "\n",
    "resFctQS = resFct.T\n",
    "resFctQS.to_csv(os.path.join('output_data', 'RealAdaBoost-原始训练.csv'), encoding='utf-8-sig')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
